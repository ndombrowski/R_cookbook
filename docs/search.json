[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R cookbook",
    "section": "",
    "text": "Preface\nThis is a cookbook for key R commands.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "code/1_intro.html",
    "href": "code/1_intro.html",
    "title": "1  Introduction into R",
    "section": "",
    "text": "1.1 Good practices for coding\nR is a statistical programming language and environment and free, open source and in active development. This tutorial will introduce into the basic concepts of R.\nThis tutorial will work with example data for two datasets:\n1. Growth data\nWe have two data files that work with a similar experimental setup:\n1.1. Growth_Data.txt\nDuring this experiments, we are doing plant growth experiments and treated our plants with different microbes wondering if any microbe affects plant growth in a positive way.\nThis file contains measurements of root length and shoot fresh weight for plants grown under control treatments (=MgCL) or when treating with 4 different bacteria. For simplicity only 1 biological experiment with 7-10 individual measurements per treatment were included.\n1.2. Timecourse.txt\nWe found positive effects for some of the strains tested above and now we want to know how long it takes for this effect to appear. To answer this, we measured root length of our plants when adding our microbe and compared it to control treatments at 5 different time points. Something unique with this dataframe is that we have empty cells (=NAs) and we need to deal with them as some R functions don’t like empty cells.\nThese practices are useful regardless of the computational language you use.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#good-practices-for-coding",
    "href": "code/1_intro.html#good-practices-for-coding",
    "title": "1  Introduction into R",
    "section": "",
    "text": "Record what program versions you used\nFor each project, document who wrote the code, when you did it and why\nPut dependencies in the beginning (ie packages)\nRecord the working directory (wdir)\nDocument ALL your code and comment it (using the # symbol)\nComment code in detail, so that you can still understand it after 5 years\nBreak code into smaller pieces for better readability\nTest each line of code and build in control steps\nIf you work with random numbers, report the seed\nUse sessionInfo() at the end of the script, which documents all the packages used within R for the current project\nFor larger files: save objects not workspaces (for space reasons)\nHave descriptive names for objects, short and simple but easy enough to understand what they mean",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#the-example-data",
    "href": "code/1_intro.html#the-example-data",
    "title": "1  Introduction into R",
    "section": "1.2 The example data",
    "text": "1.2 The example data\nLet’s have a look at the data structure for our first dataframe:\n\n\n\n  \n\n\n\nWe can see that we test our bacteria under different nutrient conditions (noP and P, which equals to normal phosphorous and low phosphorus concentrations added) and different treatments (=conditions), which are control treatments (MgCl) and different strains of microbes (Strain 101, Strain28, etc.). For each of these treatment we measured the shoot fresh weight in mg and the root length (in cm).\nThe timecourse data looks similar, we just have an extra column for the different timepoints and we only have measurements for the root length.\n2. Annotation data\nThis file is specific to the output of the Spang_team annotation pipeline but this workflow can be used for any type of categorical data one wants to summarize.\nUsing this workflow, we generated the file UAP2_Annotation_table_u.txt, which includes annotations for a set of 46 DPANN genomes. This includes annotations across several databases (arCOG, KO, PFAM, …) for each individual protein found across all these 46 genomes.\nSpecifically, we want to learn how to:\n\nMake a count table for each genome\nMake a count table for clusters of interest\nMake a heatmap for genes of interest\nMerge our results with some pre-sorted tables\n\nFor this to work we have some additional files to make our job easier:\n\nmapping.txt = a list that defines to what cluster (i.e. grouping based on a phylogenetic tree) or bins belong to\nGenes_of_interest = a list of genes we are interested in and that we want to plot in a heatmap\nar14_arCOGdef19.txt = metadata for the arCOG annotations\nMetabolism_Table_KO_Apr2020.txt = metadata for KOs and sorted by pathways\n\nThe annotation table looks like this:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\naccession\nBinID\nTaxString\nNewContigID\nOldContigId\nContigIdMerge\nContigNewLength\nGC\nProteinID\nProteinGC\nProteinLength\nProkka\narcogs\narcogs_geneID\narcogs_Description\nPathway\narcogs_evalue\nKO_hmm\ne_value\nbit_score\nbit_score_cutoff\nDefinition\nconfidence\nPFAM_hmm\nPFAM_description\nPfam_Evalue\nTIRGR\nTIGR_description\nEC\nTIGR_Evalue\nCAZy\nCAZy_evalue\nDescription\nTDBD_ID\nTPDB_evalue\nHydDB\nDescription.1\nHydDB_evalue\nPFAM\nPFAMdescription\nIPR\nIPRdescription\nTopHit\nE_value\nPecID\nTaxID\nTaxString.1\n\n\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00010\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_1\nNIOZ119_sc1610046_1\nNIOZ119_mb_b5_2_contig_1\n2539\n0.432\nPJFDGLDN_00010\n0.094\n350\nDigeranylgeranylglycerophospholipid reductase\narCOG00570\n-\n“Geranylgeranyl_reductase,_flavoprotein”\nI\n2.80E-75\nK17830\n2.10E-69\n243.3\n246.87\ndigeranylgeranylglycerophospholipid_reductase_[EC:1.3.1.101_1.3.7.11]\n-\nPF01494\nFAD_binding_domain\n5.90E-09\nTIGR02032\ngeranylgeranyl_reductase_family\n1.3.1.-\n1.40E-49\n-\n-\n-\n-\n-\n-\n-\n-\nIPR036188;_IPR002938\nFAD/NAD(P)-binding_domain_superfamily;_FAD-binding_domain\nPF01494\nFAD_binding_domain\nKYK22416.1_hypothetical_protein_AYK24_02275_[Thermoplasmatales_archaeon_SG8-52-4]\n2.80E-58\n36.5\n1803819\n“Archaea,Euryarchaeota,Thermoplasmata,Thermoplasmatales,none,none,Thermoplasmatales_archaeon_SG8-52-4”\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00020\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_1\nNIOZ119_sc1610046_1\nNIOZ119_mb_b5_2_contig_1\n2539\n0.432\nPJFDGLDN_00020\n0.057\n105\nhypothetical protein\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00030\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_1\nNIOZ119_sc1610046_1\nNIOZ119_mb_b5_2_contig_1\n2539\n0.432\nPJFDGLDN_00030\n0.092\n304\ntRNA-2-methylthio-N(6)-dimethylallyladenosine synthase\narCOG01358\nMiaB\n2-methylthioadenine_synthetase\nJ\n5.80E-90\nK15865\n1.20E-109\n375.8\n343.7\nthreonylcarbamoyladenosine_tRNA_methylthiotransferase_CDKAL1_[EC:2.8.4.5]\nhigh_score\nPF04055\nRadical_SAM_superfamily\n2.60E-21\nTIGR01578\n“MiaB-like_tRNA_modifying_enzyme,_archaeal-type”\n-\n1.70E-104\n-\n-\n-\n-\n-\n-\n-\n-\nIPR005839;_IPR002792;_IPR006466;_IPR006638;_IPR007197;_IPR020612;_IPR023404\n“Methylthiotransferase;_TRAM_domain;_MiaB-like_tRNA_modifying_enzyme,_archaeal-type;_Elp3/MiaB/NifB;_Radical_SAM;_Methylthiotransferase,_conserved_site;_Radical_SAM,_alpha/beta_horseshoe”\nPF01938;_PF04055\nTRAM_domain;_Radical_SAM_superfamily\nOIO63284.1_hypothetical_protein_AUJ83_01460_[Candidatus_Woesearchaeota_archaeon_CG1_02_33_12]\n8.20E-91\n55.6\n1805422\n“Archaea,Candidatus_Woesearchaeota,none,none,none,none,Candidatus_Woesearchaeota_archaeon_CG1_02_33_12”\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00040\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_2\nNIOZ119_sc560284_1\nNIOZ119_mb_b5_2_contig_2\n4191\n0.456\nPJFDGLDN_00040\n0.065\n92\nEnolase\narCOG01169\nEno\nEnolase\nG\n4.00E-26\nK01689\n5.10E-20\n81\n48.73\nenolase_[EC:4.2.1.11]\nhigh_score\nPF00113\n“Enolase,_C-terminal_TIM_barrel_domain”\n1.20E-20\nTIGR01060\nphosphopyruvate_hydratase\n4.2.1.11\n1.10E-25\n-\n-\n-\n-\n-\n-\n-\n-\nIPR020810;_IPR036849;_IPR000941;_IPR020809\n“Enolase,_C-terminal_TIM_barrel_domain;_Enolase-like,_C-terminal_domain_superfamily;_Enolase;_Enolase,_conserved_site”\nPF00113\n“Enolase,_C-terminal_TIM_barrel_domain”\nBAW30993.1_2-phosphoglycerate_dehydratase_[Methanothermobacter_sp._MT-2]\n3.80E-23\n70.7\n1898379\n“Archaea,Euryarchaeota,Methanobacteria,Methanobacteriales,Methanobacteriaceae,Methanothermobacter,Methanothermobacter_sp._MT-2”\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00050\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_2\nNIOZ119_sc560284_1\nNIOZ119_mb_b5_2_contig_2\n4191\n0.456\nPJFDGLDN_00050\n0.059\n218\n30S ribosomal protein S2\narCOG04245\nRpsB\nRibosomal_protein_S2\nJ\n8.90E-64\nK02998\n1.60E-46\n167.8\n210.97\nsmall_subunit_ribosomal_protein_SAe\n-\nPF00318\nRibosomal_protein_S2\n7.00E-24\nTIGR01012\nribosomal_protein_uS2\n-\n1.00E-72\n-\n-\n-\n-\n-\n-\n-\n-\nIPR005707;_IPR023454;_IPR023591;_IPR018130;_IPR001865\n“Ribosomal_protein_S2,_eukaryotic/archaeal;_Ribosomal_protein_S2,_archaeal;_Ribosomal_protein_S2,_flavodoxin-like_domain_superfamily;_Ribosomal_protein_S2,_conserved_site;_Ribosomal_protein_S2”\nPF00318\nRibosomal_protein_S2\nA0B6E5.1_RecName:_Full=30S_ribosomal_protein_S2\n1.20E-56\n52.8\n349307\n“Archaea,Euryarchaeota,Methanomicrobia,Methanosarcinales,Methanotrichaceae,Methanothrix,Methanothrix_thermoacetophila”\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00060\nNIOZ119_mb_b5_2\nUAP2\nPJFDGLDN_2\nNIOZ119_sc560284_1\nNIOZ119_mb_b5_2_contig_2\n4191\n0.456\nPJFDGLDN_00060\n0.100\n280\nhypothetical protein\narCOG01728\nMho1\n“Predicted_class_III_extradiol_dioxygenase,_MEMO1_family”\nR\n8.80E-74\nK06990\n1.40E-72\n253.3\n47\nMEMO1_family_protein\nhigh_score\nPF01875\nMemo-like_protein\n4.50E-77\nTIGR04336\nAmmeMemoRadiSam_system_protein_B\n-\n5.30E-91\n-\n-\n-\n-\n-\n-\n-\n-\nIPR002737\nMEMO1_family\nPF01875\nMemo-like_protein\nOYT50994.1_AmmeMemoRadiSam_system_protein_B_[Candidatus_Bathyarchaeota_archaeon_ex4484_135]\n1.30E-66\n47\n2012509\n“Archaea,Candidatus_Bathyarchaeota,none,none,none,none,Candidatus_Bathyarchaeota_archaeon_ex4484_135”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#working-in-r",
    "href": "code/1_intro.html#working-in-r",
    "title": "1  Introduction into R",
    "section": "1.3 Working in R",
    "text": "1.3 Working in R\n\n1.3.1 Opening R via the terminal\nIf you work with linux or want to start R from the terminal then open your terminal, change your directory to the R_exercises folder and then just type R.\nThen, you should see something like this:\n\n\n\nTo check your R version, start and quit R you can type the following in your terminal:\n\n#Ask what R version we have\nR.version\n\n#start R\nR\n\n#exit R\nq()\n\n\n\n1.3.2 RStudio (everything in one place):\nR is command-line only while RStudio is a GUI ((graphical user interface)) version of R. Therefore, working in RStudio makes everything a bit more interactive.\nRStudio includes the following:\n\nScript separate from command-line (left-hand screen)\nLists your variables (upper, right-hand corner)\nManual and an extensive help function\nEasy install of new packages\nPlots are shown within RStudio",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#documenting-code",
    "href": "code/1_intro.html#documenting-code",
    "title": "1  Introduction into R",
    "section": "1.4 Documenting code",
    "text": "1.4 Documenting code\n\n1.4.1 Markdown\nMarkdown is a lightweight markup language that you can use to add formatting elements to plain text text documents.\nSome examples:\n\nHeadings are defined with ‘#’, or ‘##’, or ‘###’ for first, second and third level.\nLists are created by using ’*’ for (bullets) and ‘1’, ‘2’, … for numbered lists.\n\nBut why should we bother to write with Markdown when you can press buttons in an interface to format your text?\n\nIts used for a lot of things, including code documentation or building websites\nFiles containing Markdown-formatted text can be opened a lot application making it extremely portable\nYou can work with Markdown on different operating systems\nIts used by a lot of tools, such as github, jupyter or RStudio.\n\nIts not the goal of this tutorial to introduce into markdown, but there is some good material online:\n\nA step-by-step tutorial\nA cheatsheet\n\n\n\n1.4.2 R code in Markdown\n\nThe R-code is embedded in between the\n```{r} and ``` symbols.\n\nIn Rstudio, on the top-right position of such a section you will find three symbols. Pressing the middle one will run all code chunks above, while the right symbol will run the current R-chunk.\n\n\n\nAn important menu-button is the Knit or Render button at the top, left-hand corner of RStudio. Pressing this button will create the final, rendered document (i.e. a HTML or PDF)\n\n\n1.4.3 Software\n\n1.4.3.1 Rmarkdown\nOne nice way to commend code is combine R-code with informative text in R markdown format (rmd).\nR Markdown supports dozens of static and dynamic output formats including: HTML, PDF, MS Word, Beamer, HTML5 slides, Tufte-style handouts, books, dashboards, shiny applications, scientific articles, websites, and more.\nThe R markdown file specifies code chunks which will be executed in R (or python or bash) and plain text which will be written to the report as is. A report is created by rendering the file in R, then the R-code is executed and the results are merged in a pdf or html output.\nHow you create a Rmarkdown document in R:\n\nOpen RStudio\npress File/new File/R markdown\n\nThis will create an R markdown file that already contains some R code and text. You can also open this document (the rmd file) in RStudio and see how the code looks.\nYou can also open a new file in any text editor and save it with the .rmd extension.\n\n\n1.4.3.2 Quarto\nQuarto is the predecessor of RMarkdown and is an open-source scientific and technical publishing system built on Pandoc and allows to:\n\nCreate dynamic content with Python, R, Julia, and Observable.\nAuthor documents as plain text markdown or Jupyter notebooks.\nPublish high-quality articles, reports, presentations, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more.\nAuthor with scientific markdown, including equations, citations, crossrefs, figure panels, callouts, advanced layout, and more.\n\nIf you installed the newest version of RStudio, Quarto is already installed and we can create a quarto document with\n\nOpen RStudio\npress File/New File/Quarto document\n\nSame as with RMarkdown, we document with Markdown (and HTML if we want), so knowing some basics is very useful.\n\n\n\n1.4.4 Execution options\nThere are a wide variety of options available for customizing output from executed code\n\ninclude = FALSE — prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks.\necho = FALSE — prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures.\nmessage = FALSE — prevents messages that are generated by code from appearing in the finished file.\nwarning = FALSE — prevents warnings that are generated by code from appearing in the finished.\nfig.cap = \"...\" — adds a caption to graphical results.\n\nFor setting these options inside a quarto document, see more here.\n\n\n1.4.5 Using languages other than R\nR Markdown/Quarto support several languages, such as bash and python, and you can call them in the same way as R code.\nThis is useful if you for example modify a dataframe in bash but then want continue to work on the data R. With proper documenting you can document the code in the same file.\nBelow is just an example, we see that we only need to “tell” R to use bash instead of R inside the top of the code chunk.\n\n#run echo to print something to the screen\necho 'hello world'\n\nhello world\n\n\n\n#run echo and follow with a sed to modify text\necho 'a b c' | sed 's/ /\\|/g'\n\na|b|c\n\n\n\n#list qmd files we have in our directory\nls  *qmd\n\n1_intro.qmd\n2_misc.qmd\nbasic_operations.qmd\ncontrol_structures.qmd\ndata_transformations.qmd\ndata_types.qmd\nparsing_output_from_annotations.qmd\nplotting_basics.qmd\nstats.qmd\ntest.qmd\n\n\n\n#show whats in our data\nhead ../data/Growth_Data.txt \n\nSampleID    Nutrient    Condition   FW_shoot_mg     Rootlength\nnoP noP MgCl    10.26   5.931015152\nnoP noP MgCl    6.52    5.74344697\nnoP noP MgCl    12.17   6.834719697\nnoP noP MgCl    11.37   6.742734848\nnoP noP MgCl    9.8 6.736886364\nnoP noP MgCl    3.75    4.236348485\nnoP noP MgCl    5.38    4.753484848\nnoP noP MgCl    4.53    5.532333333\nnoP noP MgCl    7.75    5.484363636\n\n\nA general introduction into bash and awk is provided in separate tutorials that are also available on github.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#getting-help",
    "href": "code/1_intro.html#getting-help",
    "title": "1  Introduction into R",
    "section": "1.5 Getting help",
    "text": "1.5 Getting help\n\nSome good places to check for things online are:\n\n\nwww.r-project.org\nstack overflow\nmany more\n\n\nInside of R, we can get help on functions and other things by typing either of the following:\n\n\nhelp(mean)\n?mean",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#what-is-a-workspace",
    "href": "code/1_intro.html#what-is-a-workspace",
    "title": "1  Introduction into R",
    "section": "1.6 What is a workspace?",
    "text": "1.6 What is a workspace?\nThe workspace is your current R working environment and includes any user-defined objects (i.e. vectors, matrices, data frames, lists, functions).\nAt the end of an R session, the user can save an image of the current workspace that is automatically reloaded the next time R is started.\nWe can check our workspace as follows:\n\n#print the current working directory\ngetwd() \n\n[1] \"/Users/ninadombrowski/Desktop/WorkingDir/Notebooks/Code_snippets/R/code\"\n\n#list the objects in the current workspace\nls()   \n\n[1] \"annotation_data\" \"growth_data\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#the-working-directory",
    "href": "code/1_intro.html#the-working-directory",
    "title": "1  Introduction into R",
    "section": "1.7 The working directory",
    "text": "1.7 The working directory\nThe directory from which you work is usually first set from where you start R or where the script resides (the latter is the case for this example). But it can be re-set to find your data more easily. Ideally, you make one wdir per project and define the path in the script (see later below). It is recommended to have a similar format for these project folders, i.e. consider to create subfolders for input and output files. From the wdir you set you can load files using absolute and relative paths.\nAn example would be something with a structure like this:\n\n\n\nIn this example you see that we have 4 projects, and in each folder we have the R_script and folders for the required input and required output files. Also useful to have is a text file with the session info and if you plan to share this with others it is also good to have a README file that provides some background on the analysis done.\nOptions to see the working dir and set the working directory in R are:\n\n#print your wdir\ngetwd()\n\n#setting your wdir\nsetwd(getwd())",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#packages",
    "href": "code/1_intro.html#packages",
    "title": "1  Introduction into R",
    "section": "1.8 Packages",
    "text": "1.8 Packages\nPackages are a collection of functions and tools that can be added to R that are often contributed by the community.\n\nThere might be incompatibilities and packages are updated frequently but updating can break dependencies.\nYou need to install packages and load them EVERY TIME you want to use them. Therefore, ideally add them at the beginning of your scripts.\n\n\n1.8.1 Installing packages\nWe have two ways to install packages:\n\nVia the console by typing:\n\ninstall.packages(\"package-name\")\nThis will download a package from one of the CRAN mirrors assuming that a binary is available for your operating system. If you have not set a preferred CRAN mirror in your options(), then a menu will pop up asking you to choose a location.\n\nUsing R studio:\n\nGo to the lower right hand-side window and click on packages and then install. Find the packages your are interested in.\nNotice: If libraries come with their own data (i.e. example tables), then the data needs to be loaded separately. I.e. via data(cars) to load the cars data from the cars package.\n\n\n1.8.2 Updating packages\n\nUse old.packages() to list all your locally installed packages that are now out of date.\nupdate.packages() will update all packages in the known libraries interactively. This can take a while if you haven not done it recently. To update everything without any user intervention, use the ask = FALSE argument.\n\n\n\n1.8.3 Loading packages into your current R session\nR will not remember what libraries you have loaded after you closed R. Therefore, you need to load libraries every time you re-open R. Here, we will load some libraries that are usually quite helpful and it is recommended to make the libraries you load part of each of your scripts. For example like this:\n\n#some example packages needed for Rmarkdown\nlibrary(knitr)\nlibrary(kableExtra)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#the-assignment-operator--",
    "href": "code/1_intro.html#the-assignment-operator--",
    "title": "1  Introduction into R",
    "section": "1.9 The assignment operator <-",
    "text": "1.9 The assignment operator &lt;-\nThe &lt;- symbol assigns a value to a variable,\nGeneral rules for the syntax R uses:\n\nR is case sensitive\nIf a variable exists, it will overwrite it with a new variable without asking\nIf you work with characters, i.e. words like ‘hello’, then this needs to be written with quotes around it: “hello” (this will become clearer below)\nls() shows all the variables that are known by the system at the moment\nyou can remove individual objects with rm() and remove all objects rm(list=ls())\n\nWe can store more or less everything in a variable and use it later. For example, we can store numbers and do some math with them:\n\n#store some numbers\nx &lt;- 1\ny &lt;-4\n\n#do some simple math with the numbers we have stored\nx+y\n\n[1] 5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#use-build-in-functions",
    "href": "code/1_intro.html#use-build-in-functions",
    "title": "1  Introduction into R",
    "section": "1.10 Use build in functions",
    "text": "1.10 Use build in functions\nFunctions are build in code that we can use to make our life easier, i.e. we can calculate lengths of vectors, do math or do statistical analyses.\nBase R already knows many useful functions but loading new packages greatly increases our repertoire.\nA list of most used functions can be found here\nA function consists of:\n\nFunction name\nArguments (optional, some might be set with a default) = control how exactly the function behaves\nBody of the function = defines what the function does\n\nAs an example lets test some simple functions: print and log:\n\n#use the print function\nprint(3+5)\n\n[1] 8\n\n#use the log function\nlog(10)\n\n[1] 2.302585\n\n\n\n1.10.1 Call the default values of a function\nEvery function comes with a set of arguments that you can set but that usually also have some default values. In R Studio you can easily access all those details with the help function.\n\n? allows us to first of all check exactly what a function is doing. If you scroll down to the bottom of the help page you also get some examples on how to use a function.\nMore specifically the help function also allows us to get details on the arguments of a function.\nFor example, if we check the help page of read.table we see that by default this function does not read in a header and if we want to provide a header we have to change that argument.\n\n\n#let's check what **log** is doing\n?log\n\n#lets check the default arguments of a function\n?read.table\n\nOther useful functions:\n\n\n\n\n\nName\nFunction\n\n\n\n\nls()\nList objects in your current workspace\n\n\nrm(object)\nRemove object from your current workspace\n\n\nrm(list = ls())\nRemove all objects from your current workspace",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#read-data-into-r",
    "href": "code/1_intro.html#read-data-into-r",
    "title": "1  Introduction into R",
    "section": "1.11 Read data into R",
    "text": "1.11 Read data into R\nTo work with any kind of data we need to first read the data into R to be able to work with it.\nFor tables, there are some things to be aware of:\n\nIt matters what separator our table uses to specify individual columns. I.e. some programs store data using commas while others use tab as default delimiter. By default R assume we use a tab, but we can change this behavior when we read in the table.\nDo not have any hash symbols (#) in your table. R will read this as a commented cell and not read the table from that point onward\nAvoid empty cells, as these sometimes can mess up your data.\n\nFor now, let’s read in the table with our growth data and store it under the variable name growth_data. To read in this file we need to direct it to the correct path as we do not have the file in the working directory but in a subdirectory namd data.\nOptions that are good to keep in mind when reading in a table:\n\nsep = define that our field separator is a tab. A tab is written like this /t. If your data is using a space or comma, you can change that here.\nheader = tell R that our data comes with a custom header (the first row in your dataframe)\nquote = deals with some annoying issue with data formatting in excel files\n\nGeneral notice:\n\nTo view data, the head() command is extremely practical, use it always when you modify data to check if everything went alright\ndim() is another useful function that displays the dimensions of a table, i.e. how many rows and columns we have. Again, this is useful to verify our data after we have transformed it to check if everything went alright.\ncolnames() allows to only we the column names\nrownames() allows to only we the row names. Usually these are numbers, but we can also add anything else into the rows.\n\n\n#read in data\ntimecourse &lt;- read.table(\"../data/Timecourse.txt\", sep=\"\\t\", header=T,  quote = \"\")\ngrowth_data &lt;- read.table(\"../data/Growth_Data.txt\", sep=\"\\t\", header=T,  quote = \"\")\n\n#check the first few lines of our data\nhead(growth_data)\n\n\n  \n\n\n\n\n#check the dimensions of our data\ndim(growth_data)\n\n[1] 105   5\n\n\n\n#check the column names\ncolnames(growth_data)\n\n[1] \"SampleID\"    \"Nutrient\"    \"Condition\"   \"FW_shoot_mg\" \"Rootlength\" \n\n\n\n#check the row names\nrownames(growth_data)\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\"\n\n\nUseful comments:\nSometimes we have to deal with really large data that take long to load with read.table. The function fread() from the data.table package is a very nice alternative.\nThis script sometimes uses kable for making tables visually attractive in html. Whenever you see a function using kable simply replace it with the head() function, i.e. write head(growth_data)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#write-data-into-a-text-file",
    "href": "code/1_intro.html#write-data-into-a-text-file",
    "title": "1  Introduction into R",
    "section": "1.12 Write data into a text file",
    "text": "1.12 Write data into a text file\nNow, if we would have modified the table we might want to store it on your computer. We can do this using write.table() and below we use a different output directory. Notice, we always start from the location we set as working directory.\n\nwrite.table(growth_data, \"../output_examples/growth_data_changed.txt\",  sep = \"\\t\", row.names = T, quote =F)\n\nArguments:\n\nsep –&gt; we define what delimiter we want to use\nrow.names = T –&gt; we want to include whatever is in the rownames\nquote = F –&gt; we do not want R to add any quotes around our columns.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#useful-functions-in-r",
    "href": "code/1_intro.html#useful-functions-in-r",
    "title": "1  Introduction into R",
    "section": "1.13 Useful functions in R",
    "text": "1.13 Useful functions in R\n\n1.13.1 Base functions\nR comes with the base package. This package contains the basic functions which let R function as a language: arithmetic, input/output, basic programming support, etc. Its contents are available through inheritance from any environment.\nFor a complete list of functions, use library(help = “base”).\nApart from the elementary operations, common arithmetic functions are available: log, exp, sin, cos, tan, sqrt, etc. Other useful functions one can use on vectors are:\n\n\n\n\n\nName\nFunction\n\n\n\n\nmax\nselect smallest element\n\n\nmin\nselect largest element\n\n\nlength\ngives the number of elements\n\n\nsum\nsums all elements\n\n\nmean\nobtains the mean value\n\n\nvar\nunbiased sample variance\n\n\nsort\nsee exercise 2c\n\n\n\n\n\n\n\n1.13.2 The unique command\nunique() allows to determine duplicate rows and allows us to subset our data for certain categories. For example, for very large dataframes we often can simplify things.\nHere, if we have a lot of treatments and did the experiment a long time ago, we might want to ask for a table that lists the treatments.\n\n#make unique contig list that still contains info of our bin ID\nmapping_file &lt;- unique(growth_data[,c(\"SampleID\", \"Nutrient\", \"Condition\")])\n\n#view data\nhead(mapping_file)\n\n\n  \n\n\n\n\n\n1.13.3 The merge command\nWe can also add additional metadata to our growth data.\nOne way to do this is the cbind() or rbind() functions. However, these functions require the two dataframes to have the exact number of columns or rows, which we do not have.\nHere, the merge() function of the data.table package is very useful to merge data with different dimensions as long as they have a common pattern (i.e. the SampleID).\nFirst lets build an artificial mapping file that incldues the number of days we grew our plants:\n\n#make mapping that contains our basic sample info\nmapping_file &lt;- unique(growth_data[,c(\"SampleID\", \"Nutrient\", \"Condition\")])\n\n#add a new column, where we list our experiment ID\nmapping_file$Comment &lt;- \"FirstExperiment\"\n\n#view data\nhead(mapping_file)\n\n\n  \n\n\n\nNow we can use this mapping file and merge it with our growth data as follows:\n\n#load our package\nlibrary(plyr)\n\n#merge our mapping file with our growth data\nnew_data_frame &lt;- merge(growth_data, mapping_file, by = \"SampleID\")\n\n#view data\nhead(new_data_frame)\n\n\n  \n\n\n\nThis now is a good example to check that all went fine and that the new dataframes has the same number of rows (=measurements) compared to the original dataframe.\n\n#control that all went fine\ndim(growth_data)\n\n[1] 105   5\n\ndim(new_data_frame)\n\n[1] 105   8\n\n\nWith dim we see that we still have 105 rows (i.e. measurements) and that we now added 3 new columns.\n\n#if there is no match between dataframe 1 and dataframe 2 columns will by default be deleted. If you want to keep all columns do:\n#new_data_frame &lt;- merge(growth_data, mapping_file, by = \"SampleID\". all.x = T)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/1_intro.html#combine-commands-into-one-line",
    "href": "code/1_intro.html#combine-commands-into-one-line",
    "title": "1  Introduction into R",
    "section": "1.14 Combine commands into one line",
    "text": "1.14 Combine commands into one line\nWhile this gets more difficult to read, sometimes it might be useful to combine several commands into one go to condense code Generally, it is easier to just write line by line especially if you read your code months later.\nWhat we want to do:\n\nin the example above we duplicate the columns for Nutrient and Condition and before merging we might first subset the mapping file to only include the info we want to merge.\nSo our two steps are:\n\ntrim the mapping file\nmerge\n\n\nTo do this, we use these two lines of code:\n\n#make mapping file more simple\nmapping_reduced &lt;- mapping_file[,c(\"SampleID\", \"Comment\")]\n\n#merge\nnew_data_frame &lt;- merge(growth_data, mapping_reduced, by = \"SampleID\")\nhead(new_data_frame)\n\n\n  \n\n\n\nNow, this worked fine but requires a bit more code and we need to create one more object.\nWe could also combine these two lines of code into one line by subsetting our mapping file INSIDE the merge function as follows:\n\n#clean mapping file and merge\nnew_data_frame &lt;- merge(growth_data, mapping_file[,c(\"SampleID\", \"Comment\")], by = \"SampleID\")\n\n#view data\nhead(new_data_frame)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction into R</span>"
    ]
  },
  {
    "objectID": "code/data_types.html",
    "href": "code/data_types.html",
    "title": "2  Data objects",
    "section": "",
    "text": "2.1 Data types\nIn R, all types of data are treated as objects. As such objects are units that we work with, i.e. data and functions.\nRoughly we distinguish between:\nEverything that exists is an object.\nEverything that happens is a function call.\nBelow, we introduce all these different types of objects.\nWhen programming, data,values,etc. are stored in different ways:\nR has 6 atomic classes. Below you can find each class with an example\nHere, is a quick example, how we can find out some things about our objects using:\n#create some objects\ncharacter_object &lt;- \"dataset\"\nnumber_object &lt;- c(1,4,5)\n\n#asking with what type we work\nclass(character_object)\n\n[1] \"character\"\n\nclass(number_object)\n\n[1] \"numeric\"\n#ask how long our objects are\nlength(character_object)\n\n[1] 1\n\nlength(number_object)\n\n[1] 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data objects</span>"
    ]
  },
  {
    "objectID": "code/data_types.html#data-types",
    "href": "code/data_types.html#data-types",
    "title": "2  Data objects",
    "section": "",
    "text": "character = “hello”\nnumeric (real or decimal) = 3, 14, ….\nlogical = TRUE\ncomplex = 1+4i\ninteger = 2 (Must add a L at end to denote integer)\ndouble = a number class, like the integer but with double precision floating points\n\n\n\n\nc()= a function that will create a vector (a one dimensional array) and in our case store 3 numbers. We need to use this every time we deal with more than one number, character, etc….\n\nclass() = what class is our data?\nlength() = how long is our data?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data objects</span>"
    ]
  },
  {
    "objectID": "code/data_types.html#data-structures",
    "href": "code/data_types.html#data-structures",
    "title": "2  Data objects",
    "section": "2.2 Data structures",
    "text": "2.2 Data structures\nThere are many types of data structures, the most frequently used ones being:\n\nVectors\nFactors\nMatrices\nLists\nData frames\n\nCertain operations only work on certain kind of structures, therefore, it is important to know what kind of data we are working with.\nIn R, you do not need to specify the type of data a variable will receive beforehand. You simply do the assignment, R will create a so called R-Object and assign a data type automatically.\n\n2.2.1 Vectors\nA vector is a collection of items of the same type (i.e characters, numbers). You can read in numbers and characters into the same vector, however, the number will be then seen as a character if you mix different classes.\n\n#lets create a random vector\na_vector &lt;- c(2, 3, 5, 7, 1) \n\n#show the vector we just created\na_vector\n\n[1] 2 3 5 7 1\n\n\n\n#asking how long your vector is\nlength(a_vector)\n\n[1] 5\n\n\n\n2.2.1.1 Vector indexing\nIf we want to only retrieve part of the data stored in a vector we can create a subset using the index as shown below.\n\nsquare brackets [] = allow us to retrieve certain elements of a vector, i.e. [3] retrieves the 3rd element\nwe can combine c() and [] if we want to retrieve several elements of a vector.\n\n\n#retrieve the third element stored in a vector\na_vector[3]\n\n[1] 5\n\n\n\n#retrieve the 1st and 3rd element by combining ``c()`` and []\na_vector[c(1,3)]\n\n[1] 2 5\n\n\n\n#retrieve the 1-3rd element\na_vector[c(1:3)]\n\n[1] 2 3 5\n\n\n\n#we can also add vectors of the same length together\nx &lt;- c(1,2,3,4)\ny &lt;- c(1,2,3,4)\n\n#and now we can combine our vectors\nx + y\n\n[1] 2 4 6 8\n\n\nBeware: If we add two vectors of different length, the shorter vector is duplicated. This only works if the shorter vector is proportional to the longer one\n\n#adding vectors of different lengths\nx &lt;- c(1,2)\ny &lt;- c(1,2,3,4)\n\n#and now we can combine our vectors\nx + y\n\n[1] 2 4 4 6\n\n\nAnother way to extend vectors is:\n\nappend() –&gt; Add elements to a vector.\n\n\n#add another datapoint to our vector\na_vector &lt;- append(a_vector, 13)\na_vector\n\n[1]  2  3  5  7  1 13\n\n\n\n#add +1 to all our four numbers\na_vector &lt;- a_vector + 1\na_vector\n\n[1]  3  4  6  8  2 14\n\n\n\n#remove the first element of our vector\na_vector &lt;- a_vector[-1]\na_vector\n\n[1]  4  6  8  2 14\n\n\nWe not only can extract the nth element but if we have header names then we can also use these to retrieve data:\n\n#create a vector and give it names (i.e. for counts from some microbes)\nx &lt;- c(300, 410, 531)\nnames(x) &lt;- c(\"Ecoli\",\"Archaeoglobus\",\"Ignicoccus\")\n\n#check how our data looks\nx\n\n        Ecoli Archaeoglobus    Ignicoccus \n          300           410           531 \n\n\n\n#now we can retrieve part of the vector using the names\nx[c(\"Ecoli\",\"Ignicoccus\")]\n\n     Ecoli Ignicoccus \n       300        531 \n\n\n\n\n2.2.1.2 Changing vectors\nWe can also change elements in our vector:\n\n#create a vector\nx &lt;- 1:10\n\n#change the second last positions to 5 and 9\nx[9:10] &lt;- c(5,9)\n\n#check if this worked\nx\n\n [1] 1 2 3 4 5 6 7 8 5 9\n\n\n\n#we can not only add things, we can also remove this using the minus symbol\n#i.e. lets remove the third element in our vector\nx[-3]\n\n[1] 1 2 4 5 6 7 8 5 9\n\n#if we want to remove more than one thing we can use the **c()**\n#lets remove elements 4 until (and including) 9\nx[-c(4:9)]\n\n[1] 1 2 3 9\n\n\n\n\n\n2.2.2 Matrix\nMatrices are the R objects in which the elements are arranged in a two-dimensional rectangular layout. They contain elements of the same type. Although you can construct matrices with characters or logicals, matrices are generally used to store numeric data.\nThe basic syntax for creating a matrix is:\nmatrix(data, nrow, ncol, byrow, dimnames)\n\ndata: input vector whose components become the data elements from the matrix.\nnrow: number of rows to be created.\nncol: number of columns to be created.\nbyrow: logical. If FALSE,(the default) the matrix is filled by columns, otherwise the matrix is filled by rows.\ndimnames: A ‘dimnames’&lt;80&gt;&lt;99&gt;’ attribute for the matrix: NULL or a list of length 2 giving the row and column names respectively.\n\nIn contrast in a data frame (see below) the columns contain different types of data, while in a matrix all the elements are the same type of data. A matrix in R is like a mathematical matrix, containing all the same type of thing (usually numbers). R often but not always can use dataframes and a matrix used interchangeably.\n\nIndividual elements in a matrix can be printed using [row,column]. For example [2,3] would pull out the value in the 2nd ROW and third COLUMN.\ndim() is extremely useful to control whether our data was transformed correctly during different operations. For example, after we merge two files we would like to know that they still have the same number of rows as when we started the analysis. Same if we remove for example 10 samples, then we want to make sure that this is indeed what happened.\nhead() is another useful function to check the first rows of a larger matrix (or dataframe)\ntail() same as head but showing the last rows\n\nLet’s start with creating a matrix with 3 columns and 4 rows (so including 12 data points)\n\n#define our row and column names\nrow.names = c(\"row1\", \"row2\", \"row3\", \"row4\")\ncol.names = c(\"col1\", \"col2\", \"col3\")\n\n#create our matrix (check the help function to see what is happening)\nmatrix_A &lt;- matrix(c(1:12), nrow = 4, byrow = T, dimnames = list(row.names,col.names))\n\n#check how our matrix looks like\nmatrix_A\n\n     col1 col2 col3\nrow1    1    2    3\nrow2    4    5    6\nrow3    7    8    9\nrow4   10   11   12\n\n\n\n#print the value in the 2row and 3rd column\nmatrix_A[2,3]\n\n[1] 6\n\n\n\n#print the values in the 3rd column\nmatrix_A[,3]\n\nrow1 row2 row3 row4 \n   3    6    9   12 \n\n\n\n#print everything except the 1st row\nmatrix_A[-1,]\n\n     col1 col2 col3\nrow2    4    5    6\nrow3    7    8    9\nrow4   10   11   12\n\n\n\n#print everything except the 2nd column\nmatrix_A[,-2]\n\n     col1 col3\nrow1    1    3\nrow2    4    6\nrow3    7    9\nrow4   10   12\n\n\n\n#see the dimensions of matrix, i.e. the nr of rows and columns\ndim(matrix_A)\n\n[1] 4 3\n\n\n\n#check the first rows of our matrix, since our data is small, everything is shown\nhead(matrix_A)\n\n     col1 col2 col3\nrow1    1    2    3\nrow2    4    5    6\nrow3    7    8    9\nrow4   10   11   12\n\n\n\n\n2.2.3 Lists\nSometimes you need to store data of different types. For example, if you are collecting cell counts, you might want to have cell counts (numeric), the microbes investigated (character), their status (logical, with TRUE for alive and FALSE for dead, …. This kind of data can be stored in lists. Lists are the R objects which contain elements of different types (numeric, strings, vectors, even another list, or a matrix).\nA list is created using the list() function.\nFor example, the following variable x is a list containing copies of three vectors n, s, b.\n\n#define our vectors\nn = c(20, 30, 50) \ns = c(\"Ecoli\", \"Archaeoglobus\", \"Bacillus\") \nb = c(TRUE, FALSE, TRUE) \n\n#combine the vectors in a list\nour_list = list(counts=n, strain=s, status=b) \n\n#show our list\nour_list\n\n$counts\n[1] 20 30 50\n\n$strain\n[1] \"Ecoli\"         \"Archaeoglobus\" \"Bacillus\"     \n\n$status\n[1]  TRUE FALSE  TRUE\n\n\n\n#sublist the second element in a list\nour_list[2]\n\n$strain\n[1] \"Ecoli\"         \"Archaeoglobus\" \"Bacillus\"     \n\n\n\n#retrieve the 2nd and 3rd member of our list\nour_list[c(2, 3)] \n\n$strain\n[1] \"Ecoli\"         \"Archaeoglobus\" \"Bacillus\"     \n\n$status\n[1]  TRUE FALSE  TRUE\n\n\n\n#we can also retrieve elements of a list if we know the name using two different ways:\nour_list$strain\n\n[1] \"Ecoli\"         \"Archaeoglobus\" \"Bacillus\"     \n\nour_list[[\"strain\"]]\n\n[1] \"Ecoli\"         \"Archaeoglobus\" \"Bacillus\"     \n\n\nIn the last example we use the $ dollar symbol to extract data, i.e. to extract variables in a dataset (a matrix, list, dataframe). I.e. above the data we want to access is ‘our_list’ and the variable we want to extract is the strain.\n\n\n2.2.4 Dataframes\nDataframes are tables in which each column contains values of one variable type and each row contains one set of values from each column. You can think of a data frame as a list of vectors of equal length. Most of our data very likely will be stored as dataframes.\nA Dataframe usually follows these rules:\n\nThe top line of the table, called the header, contains the column names.\nColumn names (i.e. the header of our data) should be non-empty (if they are, R provides the object with default values).\nRow names should be unique\nEach column should contain the same number of data items\nEach horizontal line after the header is a data row, which begins with the name of the row, and then followed by the actual data.\nEach data member of a row is called a cell.\n\nImportantly, most of the things we have learned before, i.e. how to subset data, apply here too.\nThe growth data that we have read into R will be used to explain how dataframes work.\n\n2.2.4.1 Viewing data Dataframes\n\nWe can use the brackets as before to extract certain rows or columns.\nWe can use the dollar sign to again extract information as long as we know the column names. I.e. now we want to access the shoot fresh weight (FW_shoot_mg) in our ‘growth_data’ dataframe.\ncolnames() allows us to access the column names, i.e. the headers\nrownames() allows us to access the rownames of our data (usually these are numbered if not specified otherwise while reading the table)\ndim() allows us to check the dimensions (i.e. the number of rows and columns). This is useful to regullary check, especially if we modified our data somehow.\nhead() shows the first rows of our dataframe\n\n\n#view our table\nhead(growth_data)\n\n\n  \n\n\n\n\n#check how many rows and columns our data has\ndim(growth_data)\n\n[1] 105   5\n\n\n\n#extract the data from the 2nd row\ngrowth_data[2,]\n\n\n  \n\n\n\n\n#extract the first three columns\nhead(growth_data[,1:3])\n\n\n  \n\n\n\n\n#extract a column of our data using the column name\n#combine it with the unique function, to remove duplicates\nunique(growth_data$Condition)\n\n[1] \"MgCl\"      \"Strain101\" \"Strain230\" \"Strain28\" \n\n\n\n#print our headers\ncolnames(growth_data)\n\n[1] \"SampleID\"    \"Nutrient\"    \"Condition\"   \"FW_shoot_mg\" \"Rootlength\" \n\n\n\n#print the rownames\nrownames(growth_data)\n\n  [1] \"1\"   \"2\"   \"3\"   \"4\"   \"5\"   \"6\"   \"7\"   \"8\"   \"9\"   \"10\"  \"11\"  \"12\" \n [13] \"13\"  \"14\"  \"15\"  \"16\"  \"17\"  \"18\"  \"19\"  \"20\"  \"21\"  \"22\"  \"23\"  \"24\" \n [25] \"25\"  \"26\"  \"27\"  \"28\"  \"29\"  \"30\"  \"31\"  \"32\"  \"33\"  \"34\"  \"35\"  \"36\" \n [37] \"37\"  \"38\"  \"39\"  \"40\"  \"41\"  \"42\"  \"43\"  \"44\"  \"45\"  \"46\"  \"47\"  \"48\" \n [49] \"49\"  \"50\"  \"51\"  \"52\"  \"53\"  \"54\"  \"55\"  \"56\"  \"57\"  \"58\"  \"59\"  \"60\" \n [61] \"61\"  \"62\"  \"63\"  \"64\"  \"65\"  \"66\"  \"67\"  \"68\"  \"69\"  \"70\"  \"71\"  \"72\" \n [73] \"73\"  \"74\"  \"75\"  \"76\"  \"77\"  \"78\"  \"79\"  \"80\"  \"81\"  \"82\"  \"83\"  \"84\" \n [85] \"85\"  \"86\"  \"87\"  \"88\"  \"89\"  \"90\"  \"91\"  \"92\"  \"93\"  \"94\"  \"95\"  \"96\" \n [97] \"97\"  \"98\"  \"99\"  \"100\" \"101\" \"102\" \"103\" \"104\" \"105\"\n\n\nWhen we print the rownames, we see that we have numbers from 1-105. When reading in a table into R it is the default behavior how rownames are generated. As a general rule, if you want o have other rownames, these must be unique.\n\n\n2.2.4.2 Adding new columns to Dataframes\nBelow is a very basic way to add a new column (we name it newColumn) and fill all rows with the word comment\n\n#expand a dataframe, functions data.frame or cbind (or see below)\ngrowth_data$newColumn &lt;- \"comment\"\n\n#check if that worked\nhead(growth_data)\n\n\n  \n\n\n\nThere are more sophisticated ways to add columns based on conditions or even merge dataframes. Some of these we will discuss later.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data objects</span>"
    ]
  },
  {
    "objectID": "code/data_types.html#check-the-structure-of-our-data",
    "href": "code/data_types.html#check-the-structure-of-our-data",
    "title": "2  Data objects",
    "section": "2.3 Check the structure of our data",
    "text": "2.3 Check the structure of our data\nIf we read in our own data, we should check as what type of class our table is stored. We have several ways to do this:\n\nclass() = determines as what kind of object is stored\nstr() = display the internal structure of an R object.\n\n\n#check what kind of data we have:\nclass(growth_data)\n\n[1] \"data.frame\"\n\n\n\n#check how are different parts of our data stored?\nstr(growth_data)\n\n'data.frame':   105 obs. of  6 variables:\n $ SampleID   : chr  \"noP\" \"noP\" \"noP\" \"noP\" ...\n $ Nutrient   : chr  \"noP\" \"noP\" \"noP\" \"noP\" ...\n $ Condition  : chr  \"MgCl\" \"MgCl\" \"MgCl\" \"MgCl\" ...\n $ FW_shoot_mg: num  10.26 6.52 12.17 11.37 9.8 ...\n $ Rootlength : num  5.93 5.74 6.83 6.74 6.74 ...\n $ newColumn  : chr  \"comment\" \"comment\" \"comment\" \"comment\" ...\n\n\nWe see that\n\nour data is stored in a dataframe\nthat the data stored in different formats, i.e. numeric and characters\nour data contains 105 observations and 6 variables",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data objects</span>"
    ]
  },
  {
    "objectID": "code/data_types.html#factors",
    "href": "code/data_types.html#factors",
    "title": "2  Data objects",
    "section": "2.4 Factors",
    "text": "2.4 Factors\nFactors are data objects that are used to represent categorical data and store it in its different levels. They are an important class for statistical analysis and for plotting. Factors are stored as integers, and have labels associated with these unique integers. Once created, factors can only contain a pre-defined set values, known as levels. By default, R always sorts levels in alphabetical order.\n\nfactor() allows us to create our own factor\n\n\n#lets make a vector\nNutrients &lt;- c(\"P\", \"P\", \"noP\", \"noP\")\n\n#lets make our own simple factor\nNutrients_factor &lt;- factor(Nutrients)\n\n#lets compare the vector and factor we generated\nNutrients\n\n[1] \"P\"   \"P\"   \"noP\" \"noP\"\n\nNutrients_factor\n\n[1] P   P   noP noP\nLevels: P noP\n\n\nWhen we check our factor, we see that R assigns one level to P and another level to noP. We can also see, that R sorts the levels in an alphabetical way, i.e. first we have noP then P, even though in the initial code we first had P before noP.\nNotice: This looks different in the rendered HTML were we first have P and then noP for whatever reason.\n\n2.4.1 Checking the behaviour of factors\nNow, lets check how factors behave.\n\nlevels() = only prints the levels of a given factor. We can also run this on any column of our dataframe.\nnlevels() = check how many levels we have.\nWhile factors look (and often behave) like character vectors, they are actually integers under the hood, and you need to be careful when treating them like strings. We can test this by looking at what type of object we generated.\n\n\n#only print the levels\nlevels(Nutrients_factor)\n\n[1] \"P\"   \"noP\"\n\n\n\n#check how many levels we have\nnlevels(Nutrients_factor)\n\n[1] 2\n\n\n\n#what class do we have\nclass(Nutrients_factor)\n\n[1] \"factor\"\n\ntypeof(Nutrients_factor)\n\n[1] \"integer\"\n\n\n\n\n2.4.2 Ordering factor levels\nFor some things, the order of things might matter and then we need to order the factors ourselves.\n\n#check our levels\nlevels(Nutrients_factor)\n\n[1] \"P\"   \"noP\"\n\n\n\n#reorder levels\nNutrients_factor_reordered &lt;- factor(Nutrients_factor, levels = c(\"P\", \"noP\"))\n\n#check our levels\nlevels(Nutrients_factor_reordered)\n\n[1] \"P\"   \"noP\"\n\n\n\n\n2.4.3 Converting factors\nSometimes you need to explicitly convert factors to either text or numbers. Or numbers to characters, etc. To do this, you use the functions as.character() or as.numeric().\n\n#convert our factor to a character\nNutrients_characters &lt;- as.character(Nutrients_factor)\nNutrients_characters\n\n[1] \"P\"   \"P\"   \"noP\" \"noP\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data objects</span>"
    ]
  },
  {
    "objectID": "code/data_transformations.html",
    "href": "code/data_transformations.html",
    "title": "3  Data transformations",
    "section": "",
    "text": "3.1 Dealing with NAs in our data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformations</span>"
    ]
  },
  {
    "objectID": "code/data_transformations.html#dealing-with-nas-in-our-data",
    "href": "code/data_transformations.html#dealing-with-nas-in-our-data",
    "title": "3  Data transformations",
    "section": "",
    "text": "3.1.1 Removing NAs\nNAs are generated when our data contains a missing value. This can become problematic for certain computations and we can decide to remove all NAs.\nThe function to do this is is.na.\n\n#create a vector that includes an NA\ny &lt;- c(1,2,3,NA,5)\n\n#check whether we have NAs\nis.na(y)\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n\n\n#remove NAs from our data\ny[!is.na(y)]\n\n[1] 1 2 3 5\n\n\n\n!= is “not equal to.”\nThe function is.na(z) gives a logical vector of the same size as z with value TRUE if and only if the corresponding element in z is NA.\nI.e. in this example we have FALSE FALSE FALSE TRUE FALSE\nWhen using y[!is.na(y)], we retain the columns were is.na is False\n\n\n3.1.1.1 Replacing NAs with something else\nAnother option might be to replace a NA with a 0 (or whatever else makes sense in a given context)\n\n#create a vector that includes an NA\nx &lt;- c(1,2,3,NA,5)\n\n#check whether we have NAs\nis.na(x)\n\n[1] FALSE FALSE FALSE  TRUE FALSE\n\n#remove NAs from our data\nx[is.na(x)] &lt;- 0\n\n#check data\nx\n\n[1] 1 2 3 0 5\n\n\nNotice, that here we use a similar syntax compared to before. Now we do\n\nFind the NAs (I.e. in this example we have FALSE FALSE FALSE TRUE FALSE)\nIf NA is TRUE then replace it with a 0\n\n\n\n\n3.1.2 Replacing NAs in our dataframe\nRemember, in the beginning we said that their are NAs in our timecourse data. Let’s have a look at this data and find the rows that contain no values.\n\n#check in which rows we have NAs inside the root length measurements\nwhich(is.na(timecourse$Rootlength)) \n\n  [1]  29  30 233 234 235 236 237 238 239 240 268 269 270 330 360 374 375 376\n [19] 377 378 379 380 381 382 383 384 385 386 387 388 389 390 402 403 404 405\n [37] 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 444 445 446\n [55] 447 448 449 450 475 476 477 478 479 480 492 493 494 495 496 497 498 499\n [73] 500 515 516 517 518 519 520 533 534 535 536 537 538 539 540 550 551 552\n [91] 553 554 555 556 557 558 559 560 574 575 605\n\n\n\n#check a row with a NA value\ntimecourse[29,]\n\n\n  \n\n\n\n\n#remove rows that contain NAs\ntimecourse_noNA &lt;- timecourse[!is.na(timecourse$Rootlength), ]\n\n#check if that worked\nwhich(is.na(timecourse_noNA$Rootlength)) \n\ninteger(0)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformations</span>"
    ]
  },
  {
    "objectID": "code/data_transformations.html#subsetting-our-data",
    "href": "code/data_transformations.html#subsetting-our-data",
    "title": "3  Data transformations",
    "section": "3.2 Subsetting our data",
    "text": "3.2 Subsetting our data\nWe already have seen important ways to subset data:\n\nUse of the index by using the square brackets\n\n\n#subsetting rows and columns using the index\ngrowth_data[1:3,2:4]\n\n\n  \n\n\n\n\nUse of operators\n\n\n#subset using operators (only print rows if the Nutrient column equals P)\nP_data &lt;- growth_data[growth_data$Nutrient == \"P\", ]\nhead(P_data)\n\n\n  \n\n\n\nNow we want to look at some other examples:\n\n3.2.1 grep and grepl\nOftentimes you may need to filter a data set based on a partial character string that is beyond the scope of comparison operators.\nR provides such functions (grep and grepl) that match character patterns in specified vector. While both of these functions find patterns, they return different output types based on those patterns.\n\ngrep returns numeric values that correspond to the indexed locations of the patterns\ngrepl returns a logical vector in which ‘TRUE’ represents a pattern match.\n\nIn our growth data, we only want to print measurements of our controls (i.e. MgCL treatments).\n\n#find the row index values with MgCL treatments using grep\ngrep(\"MgCl\", growth_data$Condition)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 53 54 55 56 57 58 59 60 61 62 63 64\n[26] 65 66 67\n\n\n\n#use grepl to search for MgCL treatments, returning FALSE/TRUE statements for each row of our dataframe\n#with \"TRUE\" representing matched patterns\ngrepl(\"Strain\", growth_data$Condition)\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [13] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [25]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [37]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [49]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n [73]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [85]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n [97]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nNow lets use this to actually filter our data table for a pattern.\n\n3.2.1.1 Filter usign grep\n\n#use grep\nfilter_for_value &lt;-timecourse_noNA[grep(\"MgCl\", timecourse_noNA$Condition),]\n\n#check the first rows of our data\nhead(filter_for_value)\n\n\n  \n\n\n#check the dimensions of the original dataframe\ndim(timecourse_noNA)\n\n[1] 526   5\n\n#check the dimensions of our new dataframe\ndim(filter_for_value)\n\n[1] 235   5\n\n\n\n\n3.2.1.2 Filter usign grepl\n\nfilter_for_value &lt;-timecourse_noNA[grepl(\"MgC\", timecourse_noNA$Condition),]\n\n#check the first rows of our data\nhead(filter_for_value)\n\n\n  \n\n\n#check the dimensions of the original dataframe\ndim(timecourse_noNA)\n\n[1] 526   5\n\n#check the dimensions of our new dataframe\ndim(filter_for_value)\n\n[1] 235   5\n\n\n\n\n\n3.2.2 Discard matching columns\n\n#filter data set based on values that do not match the specified pattern (by using the ! symbol)\nfilter_for_not_a_value &lt;- timecourse_noNA[!grepl(\"MgCl\", timecourse_noNA$Condition),]\n\n#view dataframe\nhead(filter_for_not_a_value)\n\n\n  \n\n\n#check the dimensions of the original dataframe\ndim(timecourse_noNA)\n\n[1] 526   5\n\n#check the dimensions of our new dataframe\ndim(filter_for_not_a_value)\n\n[1] 291   5\n\n\nOther comments:\n\nUsing regular expressions (programming symbol pattern) will increase their functionality\nSpecified patterns are case sensitive (‘t’ does not equal ‘T’)\nAny matching pattern will be returned despite the context in which that pattern is located (i.e., grep(‘the’, data) with return matches for ‘the’, ‘theme’, ‘heather’, ‘breathe’, and so on. This is where regular expressions are useful for specifying where in a string the pattern should appear.\n\n\n\n3.2.3 Using regular expressions\nA regular expression (regex or regexp for short) is a special text string for describing a search pattern. You can think of regular expressions as wildcards on steroids. You are probably familiar with wildcard notations such as *.txt to find all text files in a file manager.\nRegular expressions are explained in the AWK and General notebook. But just to give an example lets just grep Strains that have a 3 letter number\nIf you want to know more, see this cheat sheet here\n\nfilter_3letters &lt;- growth_data[grepl(\"[0-9]{3}\", growth_data$Condition),]\n\n#check the structure of our data\nhead(filter_3letters)\n\n\n  \n\n\n#check the dimensions of the original dataframe\ndim(timecourse_noNA)\n\n[1] 526   5\n\n#check the dimensions of our new dataframe\ndim(filter_3letters)\n\n[1] 49  5\n\n\nHere, [0-9] searches for every number from 0-9 and we look for three numbers.\n\n\n3.2.4 Levels and subsetting\nOne important thing with subsetting is that the levels are still kept. So with the command above we remove every row that is not Strain101 and Strain230. However, the levels are still kept. Let’s check this:\n\nlevels(filter_3letters$Condition)\n\n[1] \"MgCl\"      \"Strain101\" \"Strain230\" \"Strain28\" \n\n\nSo we see that MgCl and Strain28 are still in the levels even if they do not occur in our table itself. Sometimes when working with subsetted dataframes, i.e. when doing stats or plotting, this can interfere with our analysis. Here, it is useful to drop empty levels.\n\nfilter_3letters_clean &lt;- droplevels(filter_3letters)\nlevels(filter_3letters_clean$Condition)\n\n[1] \"Strain101\" \"Strain230\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformations</span>"
    ]
  },
  {
    "objectID": "code/data_transformations.html#add-new-columns-to-our-data-and-combining-values-in-different-columns",
    "href": "code/data_transformations.html#add-new-columns-to-our-data-and-combining-values-in-different-columns",
    "title": "3  Data transformations",
    "section": "3.3 Add new columns to our data and combining values in different columns",
    "text": "3.3 Add new columns to our data and combining values in different columns\nWe can also add new columns into original table, i.e. if we want to not show the fresh weight in mg but in g.\nBelow you can see that if we have numerical data in a column, we can use normal math operators (like +,-,/)\n\n#convert mg to g\ngrowth_data$FW_shoot_g &lt;- growth_data$FW_shoot_mg/10\nhead(growth_data)\n\n\n  \n\n\n\n\n#we can also round our data\ngrowth_data$FW_shoot_g &lt;- round(growth_data$FW_shoot_mg/10, digits = 2)\nhead(growth_data)\n\n\n  \n\n\n\nWe can also add (or substract, etc …) values from different columns. I.e. here we could calculate the ratios.\n\n#we can also do math with the values in two columns, i.e. if we want to calculate the ration between root length and fresh weight\ngrowth_data$ratio &lt;- growth_data$Rootlength/growth_data$FW_shoot_mg\nhead(growth_data)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data transformations</span>"
    ]
  },
  {
    "objectID": "code/control_structures.html",
    "href": "code/control_structures.html",
    "title": "4  Control Structures",
    "section": "",
    "text": "4.1 Loops\nControl structures in R allow you to control the flow of execution of a series of R expressions. Basically, control structures allow you to put some ‘logic’ into your R code, rather than just always executing the same R code every time.\nSometimes it is necessary to repeat a calculation multiple times, e.g. calculate the sum of each row of a matrix. You can use for loops to do this.\nLets assume a simple matrix with 5 rows and 3 columns. How would we generate the sum of each row?\nWe could do so, by calculating the sum step-by-step:\n#build a dataframe\nm &lt;- matrix(1:15, 5)\nm\n\n     [,1] [,2] [,3]\n[1,]    1    6   11\n[2,]    2    7   12\n[3,]    3    8   13\n[4,]    4    9   14\n[5,]    5   10   15\n#sum rows without a loop --&gt; sum row 1\nsum(m[1, ])\n\n[1] 18\n#sum rows without a loop --&gt; sum row 2, ...\nsum(m[2, ])\n\n[1] 21\nHowever, you will quickly see that this becomes quite tedious. So lets do this via a loop, in which we:\n#run a loop to get the sum for all five rows\nfor (i in 1:5) {\nprint(sum(m[i, ]))\n}\n\n[1] 18\n[1] 21\n[1] 24\n[1] 27\n[1] 30\nHow would we store our results in a new dataframe and do not just print them to the screen? To do this, we:\n#store the results, Note that here, the variable results had to be created before as an empty vector.\nresults &lt;- c()\nfor (i in 1:5) {\nresults[i] &lt;- sum(m[i, ])\n}\n\nresults\n\n[1] 18 21 24 27 30\nVery often, there are some R packages or functions that are faster than loops.\nThe apply() function is such an example. apply() applies a function, i.e. sum, across a matrix.\nHowever, since loops are also a very useful feature in bash or python it is useful to understand their general concept.\n#way to do the same using the apply function (faster than loops)\nresults2 &lt;- apply(m, 1, sum)\nresults2\n\n[1] 18 21 24 27 30\nApply takes the following arguments:\nActually, there is a family of apply functions, depending on the object you pass as an input, and/or the object you want as output. You can read a brief tutorial under this link.\nTwo other examples are sapply and lapply, which work on lists.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "code/control_structures.html#loops",
    "href": "code/control_structures.html#loops",
    "title": "4  Control Structures",
    "section": "",
    "text": "define that we want to loop through rows 1 to 5 (1:5)\nfor (i in 1:5) –&gt; we say that we want to run a for loop, in which we name our variable i\n{} –&gt; defines the operation we want to loop through\nin our case we want to sum a specific row (rows 1 through 5)\nso in i we store the numbers 1,2,3,4 and 5 and then run through the sum functions 5x\n\n\n\n\ndefine a variable (named results) in which we store an empty vector with c(). We need this empty vector to have something to store our results in while running the loop.\nstart the for loop and define i as before\nrun the sum as before but now store the results for each iteration in results\n\n\n\n\n\n\n\nOur input, the matrix,\nThe dimension of the matrix on which the function should be applied ((1 means rows and 2 means columns))\n\napply(data, 1, mean) = apply mean on each row\napply(data, 2, mean) = apply mean on each column\n\nThe function we want to use. Here, the function sum is applied to each row of m.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "code/control_structures.html#if-else",
    "href": "code/control_structures.html#if-else",
    "title": "4  Control Structures",
    "section": "4.2 if-else",
    "text": "4.2 if-else\nOne can also create a decision making structure in R. A decision making structure has at least one condition to be evaluated together with a statement or statements to be evaluated if the condition is TRUE, and optionally, other statements to be executed if the condition is FALSE, as we can see in the figure.\nThe test_expression has to be logical, i.e., it has to be a expression that, when evaluated, is either TRUE or FALSE. The logical operators listed above can be used to construct them. For example, we can use an if-else statement to check if a number is positive or negative,\n\n#store a random number\nx &lt;- -5\n\n#write a loop and ask if our number is positive or negative\nif (x &gt; 0) {\nprint(\"Positive number\")\n} else if (x == 0) {\nprint(\"Number is zero\")\n} else {\nprint(\"Negative number\")\n}\n\n[1] \"Negative number\"\n\n\nNote that in the example there was an else if. In that way we can check more than 2 conditions.\nThis of course is a very simplistic example. But if-else statements can be useful if we want to deal with larger dataframes, i.e. our growth data.\nSpecifically, we want to:\n\nCreate a new column, with the name category\nIf a value in our Root length column is equal to or smaller than 10, we want to say this category is small.\nIf that is not the case, we want to say it is large\n\n\n#apply ifelse\ngrowth_data$category &lt;- ifelse(growth_data$Rootlength&lt;=10.0, \"small\", \"large\")\n\n#check the structure of our data\nkable(growth_data) %&gt;%\n  kable_styling() %&gt;%\n  scroll_box(width = \"700px\", height = \"400px\")\n\n\n\n\n\nSampleID\nNutrient\nCondition\nFW_shoot_mg\nRootlength\ncategory\n\n\n\n\nnoP\nnoP\nMgCl\n10.26\n5.931015\nsmall\n\n\nnoP\nnoP\nMgCl\n6.52\n5.743447\nsmall\n\n\nnoP\nnoP\nMgCl\n12.17\n6.834720\nsmall\n\n\nnoP\nnoP\nMgCl\n11.37\n6.742735\nsmall\n\n\nnoP\nnoP\nMgCl\n9.80\n6.736886\nsmall\n\n\nnoP\nnoP\nMgCl\n3.75\n4.236349\nsmall\n\n\nnoP\nnoP\nMgCl\n5.38\n4.753485\nsmall\n\n\nnoP\nnoP\nMgCl\n4.53\n5.532333\nsmall\n\n\nnoP\nnoP\nMgCl\n7.75\n5.484364\nsmall\n\n\nnoP\nnoP\nMgCl\n8.64\n5.963254\nsmall\n\n\nnoP\nnoP\nMgCl\n10.36\n5.359044\nsmall\n\n\nnoP\nnoP\nMgCl\n7.69\n5.725348\nsmall\n\n\nnoP\nnoP\nMgCl\n8.57\n6.424601\nsmall\n\n\nnoP_101\nnoP\nStrain101\n10.49\n7.143667\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.91\n7.669841\nsmall\n\n\nnoP_101\nnoP\nStrain101\n9.32\n7.807710\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.76\n7.508370\nsmall\n\n\nnoP_101\nnoP\nStrain101\n5.99\n6.607630\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.26\n7.269267\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.61\n7.973207\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.56\n7.399504\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.90\n6.717792\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.69\n6.721007\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.14\n7.070333\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.07\n5.947965\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.19\n6.393722\nsmall\n\n\nnoP_230\nnoP\nStrain230\n4.96\n7.166174\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.20\n7.515659\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.97\n7.250036\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.32\n7.134681\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.45\n6.917319\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.03\n6.120089\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.70\n7.665526\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.04\n7.809111\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.22\n6.601296\nsmall\n\n\nnoP_230\nnoP\nStrain230\n3.99\n6.524710\nsmall\n\n\nnoP_230\nnoP\nStrain230\n4.85\n8.197116\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.63\n6.160052\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.27\n4.720711\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.51\n6.917185\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.46\n4.384756\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.91\n6.069185\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.40\n7.113879\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.36\n5.428766\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.74\n6.694142\nsmall\n\n\nnoP_28\nnoP\nStrain28\n4.15\n5.270298\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.60\n6.811773\nsmall\n\n\nnoP_28\nnoP\nStrain28\n5.41\n5.106644\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.30\n7.413519\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.93\n7.112385\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.44\n7.428674\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.85\n6.372659\nsmall\n\n\nP\nP\nMgCl\n32.42\n11.286793\nlarge\n\n\nP\nP\nMgCl\n21.03\n10.456630\nlarge\n\n\nP\nP\nMgCl\n18.35\n11.106341\nlarge\n\n\nP\nP\nMgCl\n21.04\n10.816896\nlarge\n\n\nP\nP\nMgCl\n16.61\n10.608252\nlarge\n\n\nP\nP\nMgCl\n25.79\n7.121587\nsmall\n\n\nP\nP\nMgCl\n31.00\n9.165891\nsmall\n\n\nP\nP\nMgCl\n36.13\n11.053978\nlarge\n\n\nP\nP\nMgCl\n17.50\n8.271196\nsmall\n\n\nP\nP\nMgCl\n21.42\n8.649225\nsmall\n\n\nP\nP\nMgCl\n19.60\n10.313985\nlarge\n\n\nP\nP\nMgCl\n11.62\n8.098859\nsmall\n\n\nP\nP\nMgCl\n18.76\n10.061778\nlarge\n\n\nP\nP\nMgCl\n21.55\n11.048822\nlarge\n\n\nP\nP\nMgCl\n19.05\n9.741622\nsmall\n\n\nP_101\nP\nStrain101\n20.91\n12.119304\nlarge\n\n\nP_101\nP\nStrain101\n23.48\n12.057252\nlarge\n\n\nP_101\nP\nStrain101\n17.47\n12.064659\nlarge\n\n\nP_101\nP\nStrain101\n24.49\n13.576118\nlarge\n\n\nP_101\nP\nStrain101\n25.70\n10.983965\nlarge\n\n\nP_101\nP\nStrain101\n28.24\n12.935397\nlarge\n\n\nP_101\nP\nStrain101\n17.70\n11.921333\nlarge\n\n\nP_101\nP\nStrain101\n32.90\n13.030630\nlarge\n\n\nP_101\nP\nStrain101\n22.80\n12.644756\nlarge\n\n\nP_101\nP\nStrain101\n32.47\n14.715830\nlarge\n\n\nP_101\nP\nStrain101\n22.05\n13.186593\nlarge\n\n\nP_101\nP\nStrain101\n23.47\n13.513763\nlarge\n\n\nP_230\nP\nStrain230\n23.46\n10.981978\nlarge\n\n\nP_230\nP\nStrain230\n22.93\n12.563616\nlarge\n\n\nP_230\nP\nStrain230\n17.08\n12.174456\nlarge\n\n\nP_230\nP\nStrain230\n15.95\n13.151797\nlarge\n\n\nP_230\nP\nStrain230\n15.03\n12.072456\nlarge\n\n\nP_230\nP\nStrain230\n13.00\n10.692603\nlarge\n\n\nP_230\nP\nStrain230\n18.30\n12.236482\nlarge\n\n\nP_230\nP\nStrain230\n17.80\n11.792879\nlarge\n\n\nP_230\nP\nStrain230\n17.43\n11.914695\nlarge\n\n\nP_230\nP\nStrain230\n14.93\n11.281731\nlarge\n\n\nP_230\nP\nStrain230\n22.75\n11.502507\nlarge\n\n\nP_230\nP\nStrain230\n37.90\n13.170210\nlarge\n\n\nP_230\nP\nStrain230\n13.27\n10.055399\nlarge\n\n\nP_28\nP\nStrain28\n37.14\n11.908378\nlarge\n\n\nP_28\nP\nStrain28\n39.39\n12.612785\nlarge\n\n\nP_28\nP\nStrain28\n28.27\n12.434356\nlarge\n\n\nP_28\nP\nStrain28\n29.50\n12.559904\nlarge\n\n\nP_28\nP\nStrain28\n27.29\n11.585637\nlarge\n\n\nP_28\nP\nStrain28\n22.82\n11.925326\nlarge\n\n\nP_28\nP\nStrain28\n25.05\n12.831222\nlarge\n\n\nP_28\nP\nStrain28\n17.48\n11.644037\nlarge\n\n\nP_28\nP\nStrain28\n15.85\n11.900193\nlarge\n\n\nP_28\nP\nStrain28\n9.54\n10.698752\nlarge\n\n\nP_28\nP\nStrain28\n27.91\n11.668794\nlarge\n\n\nP_28\nP\nStrain28\n26.63\n12.555404\nlarge\n\n\nP_28\nP\nStrain28\n29.96\n11.771277\nlarge\n\n\n\n\n\n\n\nSo the function works like this:\nifelse(our_test, value_to_return_if_test_is_true, value_to_return_if_test_is_false)\nWe can also combine different statements with the & (AND) or | (OR) symbol. I.e. we only send things in the big category if the roots are longer than 10cm AND the shoot weight is larger than 15mg\n\n#apply ifelse\ngrowth_data$category &lt;- ifelse(growth_data$Rootlength&gt;10 & growth_data$FW_shoot_mg&gt;15, \"large\", \"small\")\n\n#check the structure of our data\nkable(growth_data) %&gt;%\n  kable_styling() %&gt;%\n  scroll_box(width = \"700px\", height = \"400px\")\n\n\n\n\n\nSampleID\nNutrient\nCondition\nFW_shoot_mg\nRootlength\ncategory\n\n\n\n\nnoP\nnoP\nMgCl\n10.26\n5.931015\nsmall\n\n\nnoP\nnoP\nMgCl\n6.52\n5.743447\nsmall\n\n\nnoP\nnoP\nMgCl\n12.17\n6.834720\nsmall\n\n\nnoP\nnoP\nMgCl\n11.37\n6.742735\nsmall\n\n\nnoP\nnoP\nMgCl\n9.80\n6.736886\nsmall\n\n\nnoP\nnoP\nMgCl\n3.75\n4.236349\nsmall\n\n\nnoP\nnoP\nMgCl\n5.38\n4.753485\nsmall\n\n\nnoP\nnoP\nMgCl\n4.53\n5.532333\nsmall\n\n\nnoP\nnoP\nMgCl\n7.75\n5.484364\nsmall\n\n\nnoP\nnoP\nMgCl\n8.64\n5.963254\nsmall\n\n\nnoP\nnoP\nMgCl\n10.36\n5.359044\nsmall\n\n\nnoP\nnoP\nMgCl\n7.69\n5.725348\nsmall\n\n\nnoP\nnoP\nMgCl\n8.57\n6.424601\nsmall\n\n\nnoP_101\nnoP\nStrain101\n10.49\n7.143667\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.91\n7.669841\nsmall\n\n\nnoP_101\nnoP\nStrain101\n9.32\n7.807710\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.76\n7.508370\nsmall\n\n\nnoP_101\nnoP\nStrain101\n5.99\n6.607630\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.26\n7.269267\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.61\n7.973207\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.56\n7.399504\nsmall\n\n\nnoP_101\nnoP\nStrain101\n7.90\n6.717792\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.69\n6.721007\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.14\n7.070333\nsmall\n\n\nnoP_101\nnoP\nStrain101\n6.07\n5.947965\nsmall\n\n\nnoP_101\nnoP\nStrain101\n8.19\n6.393722\nsmall\n\n\nnoP_230\nnoP\nStrain230\n4.96\n7.166174\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.20\n7.515659\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.97\n7.250036\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.32\n7.134681\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.45\n6.917319\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.03\n6.120089\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.70\n7.665526\nsmall\n\n\nnoP_230\nnoP\nStrain230\n6.04\n7.809111\nsmall\n\n\nnoP_230\nnoP\nStrain230\n5.22\n6.601296\nsmall\n\n\nnoP_230\nnoP\nStrain230\n3.99\n6.524710\nsmall\n\n\nnoP_230\nnoP\nStrain230\n4.85\n8.197116\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.63\n6.160052\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.27\n4.720711\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.51\n6.917185\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.46\n4.384756\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.91\n6.069185\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.40\n7.113879\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.36\n5.428766\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.74\n6.694142\nsmall\n\n\nnoP_28\nnoP\nStrain28\n4.15\n5.270298\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.60\n6.811773\nsmall\n\n\nnoP_28\nnoP\nStrain28\n5.41\n5.106644\nsmall\n\n\nnoP_28\nnoP\nStrain28\n8.30\n7.413519\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.93\n7.112385\nsmall\n\n\nnoP_28\nnoP\nStrain28\n9.44\n7.428674\nsmall\n\n\nnoP_28\nnoP\nStrain28\n7.85\n6.372659\nsmall\n\n\nP\nP\nMgCl\n32.42\n11.286793\nlarge\n\n\nP\nP\nMgCl\n21.03\n10.456630\nlarge\n\n\nP\nP\nMgCl\n18.35\n11.106341\nlarge\n\n\nP\nP\nMgCl\n21.04\n10.816896\nlarge\n\n\nP\nP\nMgCl\n16.61\n10.608252\nlarge\n\n\nP\nP\nMgCl\n25.79\n7.121587\nsmall\n\n\nP\nP\nMgCl\n31.00\n9.165891\nsmall\n\n\nP\nP\nMgCl\n36.13\n11.053978\nlarge\n\n\nP\nP\nMgCl\n17.50\n8.271196\nsmall\n\n\nP\nP\nMgCl\n21.42\n8.649225\nsmall\n\n\nP\nP\nMgCl\n19.60\n10.313985\nlarge\n\n\nP\nP\nMgCl\n11.62\n8.098859\nsmall\n\n\nP\nP\nMgCl\n18.76\n10.061778\nlarge\n\n\nP\nP\nMgCl\n21.55\n11.048822\nlarge\n\n\nP\nP\nMgCl\n19.05\n9.741622\nsmall\n\n\nP_101\nP\nStrain101\n20.91\n12.119304\nlarge\n\n\nP_101\nP\nStrain101\n23.48\n12.057252\nlarge\n\n\nP_101\nP\nStrain101\n17.47\n12.064659\nlarge\n\n\nP_101\nP\nStrain101\n24.49\n13.576118\nlarge\n\n\nP_101\nP\nStrain101\n25.70\n10.983965\nlarge\n\n\nP_101\nP\nStrain101\n28.24\n12.935397\nlarge\n\n\nP_101\nP\nStrain101\n17.70\n11.921333\nlarge\n\n\nP_101\nP\nStrain101\n32.90\n13.030630\nlarge\n\n\nP_101\nP\nStrain101\n22.80\n12.644756\nlarge\n\n\nP_101\nP\nStrain101\n32.47\n14.715830\nlarge\n\n\nP_101\nP\nStrain101\n22.05\n13.186593\nlarge\n\n\nP_101\nP\nStrain101\n23.47\n13.513763\nlarge\n\n\nP_230\nP\nStrain230\n23.46\n10.981978\nlarge\n\n\nP_230\nP\nStrain230\n22.93\n12.563616\nlarge\n\n\nP_230\nP\nStrain230\n17.08\n12.174456\nlarge\n\n\nP_230\nP\nStrain230\n15.95\n13.151797\nlarge\n\n\nP_230\nP\nStrain230\n15.03\n12.072456\nlarge\n\n\nP_230\nP\nStrain230\n13.00\n10.692603\nsmall\n\n\nP_230\nP\nStrain230\n18.30\n12.236482\nlarge\n\n\nP_230\nP\nStrain230\n17.80\n11.792879\nlarge\n\n\nP_230\nP\nStrain230\n17.43\n11.914695\nlarge\n\n\nP_230\nP\nStrain230\n14.93\n11.281731\nsmall\n\n\nP_230\nP\nStrain230\n22.75\n11.502507\nlarge\n\n\nP_230\nP\nStrain230\n37.90\n13.170210\nlarge\n\n\nP_230\nP\nStrain230\n13.27\n10.055399\nsmall\n\n\nP_28\nP\nStrain28\n37.14\n11.908378\nlarge\n\n\nP_28\nP\nStrain28\n39.39\n12.612785\nlarge\n\n\nP_28\nP\nStrain28\n28.27\n12.434356\nlarge\n\n\nP_28\nP\nStrain28\n29.50\n12.559904\nlarge\n\n\nP_28\nP\nStrain28\n27.29\n11.585637\nlarge\n\n\nP_28\nP\nStrain28\n22.82\n11.925326\nlarge\n\n\nP_28\nP\nStrain28\n25.05\n12.831222\nlarge\n\n\nP_28\nP\nStrain28\n17.48\n11.644037\nlarge\n\n\nP_28\nP\nStrain28\n15.85\n11.900193\nlarge\n\n\nP_28\nP\nStrain28\n9.54\n10.698752\nsmall\n\n\nP_28\nP\nStrain28\n27.91\n11.668794\nlarge\n\n\nP_28\nP\nStrain28\n26.63\n12.555404\nlarge\n\n\nP_28\nP\nStrain28\n29.96\n11.771277\nlarge",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Control Structures</span>"
    ]
  },
  {
    "objectID": "code/stats.html",
    "href": "code/stats.html",
    "title": "5  Statistics in R",
    "section": "",
    "text": "5.1 Summary stats\nA lot of helpful information that that was used here was inspired by a more detailed site that can be found here\nAnd please take note, that the writer of this tutorial is no statistician and if you spot issues feel free to let me know!\nTo do some basic stats we use the nutrient growth data set, which you find in the R_exercises folder.\n#get the menas of our root length\nmean(growth_data$Rootlength)\n\n[1] 9.046117\n#return summary stats for the root length\nsummary(growth_data$Rootlength)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.236   6.721   8.099   9.046  11.793  14.716\nWe can also summarize data of several columns\n#return summary stats for the root length\nsummary(growth_data[,c(\"Rootlength\", \"FW_shoot_mg\")])\n\n   Rootlength      FW_shoot_mg   \n Min.   : 4.236   Min.   : 3.75  \n 1st Qu.: 6.721   1st Qu.: 7.69  \n Median : 8.099   Median :11.62  \n Mean   : 9.046   Mean   :15.23  \n 3rd Qu.:11.793   3rd Qu.:22.05  \n Max.   :14.716   Max.   :39.39\nWe can also run summary() on our complete dataframe.\n#run summary on all our data\nsummary(growth_data)\n\n   SampleID           Nutrient          Condition          FW_shoot_mg   \n Length:105         Length:105         Length:105         Min.   : 3.75  \n Class :character   Class :character   Class :character   1st Qu.: 7.69  \n Mode  :character   Mode  :character   Mode  :character   Median :11.62  \n                                                          Mean   :15.23  \n                                                          3rd Qu.:22.05  \n                                                          Max.   :39.39  \n   Rootlength    \n Min.   : 4.236  \n 1st Qu.: 6.721  \n Median : 8.099  \n Mean   : 9.046  \n 3rd Qu.:11.793  \n Max.   :14.716\nThis way we do not only get summary stats for our values, but also we get some counts on how many measurements we have for different conditions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#summary-stats",
    "href": "code/stats.html#summary-stats",
    "title": "5  Statistics in R",
    "section": "",
    "text": "means() = print the mean of a certain column\nsummary()= print the mean, median, max, min, … of a certain column.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#the-table-command",
    "href": "code/stats.html#the-table-command",
    "title": "5  Statistics in R",
    "section": "5.2 The table command",
    "text": "5.2 The table command\nThe function table builds a contingency table of the counts at each factor level, or combinations of factor levels. This is quite useful to count the number of data points with certain metadata associated. So for example for our genome data we can ask how many measurements we made for each condition.\n\n#summarize how many measurements we have for each treatment\ntable(growth_data$SampleID)\n\n\n    noP noP_101 noP_230  noP_28       P   P_101   P_230    P_28 \n     13      13      11      15      15      12      13      13 \n\n\nHere, we see that we have a slightly different number of measurements for each condition and timepoint. For this tutorial we can ignore them, but this might be relevant if we have huge differences for some statistical analyses. This approach allows you to for larger datasets to easily check for samples that might be outliers in terms of measurements per sample.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#the-ddply-command",
    "href": "code/stats.html#the-ddply-command",
    "title": "5  Statistics in R",
    "section": "5.3 The ddply command",
    "text": "5.3 The ddply command\nThe table command can get rather slow and there are some useful packages to speed up things and run more complicated mathematical operations. One example is the ddply() function of the plyr package. A useful feature of ddply is that this tool stores the output as a dataframe instead of a table.\nBelow we see examples were we summarize the data for the root length across different nutrient conditions. I.e. we do not want to have the mean for all root lengths but we want to see if roots have different lengths under low and high P conditions.\n\n#load our package\nlibrary(plyr)\n\n#calculate the mean root length across our Sample IDs\ngrowth_data_summarized &lt;- ddply(growth_data, .(Nutrient), summarize, Mean_RootLength = mean(Rootlength))\n\n#view data\nhead(growth_data_summarized)\n\n\n  \n\n\n\nThe structure of the command is as follows:\nddply(Input_Data, .(Colum_we_want_to_sum_arcoss), summarize, New_Column_name = mean(Column_we_want_to_calc_the_mean_for))\nWe can also summarize the data combining different conditions (i.e. nutrient and condition).\n\n#Summarize our data across Nutrients and Conditions\ngrowth_data_summarized &lt;- ddply(growth_data, .(Nutrient, Condition), summarize, Mean_RootLength = mean(Rootlength))\n\n#view data\nhead(growth_data_summarized)\n\n\n  \n\n\n\nWe can also calculate the mean, sd and se in one line of code\n\n#and we can use even fancier functions (i.e. get the se and sd), check the plyr package for more details\ngrowth_data_summarized &lt;- ddply(growth_data, .(Nutrient, Condition), summarize, RootLength = mean(Rootlength), sd = sd (Rootlength), se = sd(Rootlength) / sqrt((length(Rootlength))))\n\n#view data\nhead(growth_data_summarized)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#tidyr",
    "href": "code/stats.html#tidyr",
    "title": "5  Statistics in R",
    "section": "5.4 tidyr",
    "text": "5.4 tidyr\nTydir is another package to summarize data but also to transform data. For now we will just discuss the basics to summarize data but we will try to add an extended section on this package later.\nYou notice here that the syntax is a bit unusual and we use the %&gt;% symbol (a so-called forward pipe operator). This symbol is commonly used in the dplyr and tidyr packages. This function passes the left hand side of the operator to the first argument of the right hand side of the operator.\nIn the following example, the a subset of the growth_data data (only 3 columns, not the whole dataframe) gets passed to count()\nNew functions:\n\ncount() = A function of the dplyr package. Here, we count the unique protein IDs grouped by BinID and gene (i.e. roughly equivalent to the columns we want to keep)\nsummarize() creates new data frame into one (or more) rows for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified.\nmean() = calculate the arithmetic mean.\n\n\n#read in package\nlibrary(tidyverse)\n\n\n#count how many measurements we have per conditions\ngrowth_data %&gt;% count(Condition, sort = FALSE)\n\n\n  \n\n\n\n\n#count how many measurements we have per nutrient and conditions\ngrowth_data %&gt;% count(Nutrient, Condition, sort = FALSE)\n\n\n  \n\n\n\n\n#get more comprehensive data stats and summarize for the whole dataset\ngrowth_data %&gt;% summarise(\n          count = n(),\n          mean_root = mean(Rootlength, na.rm = TRUE))\n\n\n  \n\n\n\nGood things about tydr are:\n\nit is extremely fast, so is important for dealing with larger datasets\nwe can combine several commands by using the pipe\n\nI.e. below we can see that we first group the input data and then summarized the group data.\n\n#get more comprehensive data stats and summarize and grouping for the different conditions\ngrowth_data %&gt;% \n    group_by(Nutrient, Condition) %&gt;%  \n    summarise(\n          count = n(),\n          mean_root = mean(Rootlength, na.rm = TRUE) ,.groups = 'drop')\n\n\n  \n\n\n\nWe can also do other stats than just calculating the mean:\n\n#get more comprehensive data stats and summarize and grouping for the different conditions\ngrowth_data %&gt;% \n    group_by(Nutrient, Condition) %&gt;%  \n    summarise(\n          count = n(),\n          mean_root = mean(Rootlength, na.rm = TRUE),\n          sd_root = sd(Rootlength),.groups = 'drop')\n\n\n  \n\n\n\nOther useful summary functions:\n\nmean(x): sum of x divided by the length\nmedian(x): 50% of x is above and 50% is below\nsd(x): standard deviation\nIQR(x): interquartile range (robust equivalent of sd when outliers are present in the data)\nmad(x): median absolute deviation (robust equivalent of sd when outliers are present in the data)\nmin(x): minimum value of x\nmax(x): maximum value of x\nquantile(x, 0.25): 25% of x is below this value\nfirst(x): equivalent to x[1]\nnth(x, 2): equivalent to n&lt;-2; x[n]\nlast(x): equivalent to x[length(x)]\nn(x): the number of elements in x\nsum(!is.na(x)): count non-missing values\nn_distinct(x): count the number of unique value\nsum(x &gt; 10): count the number of elements where x &gt; 10\nmean(y == 0): proportion of elements where y = 0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#more-stats-tapply",
    "href": "code/stats.html#more-stats-tapply",
    "title": "5  Statistics in R",
    "section": "5.5 More stats: tapply",
    "text": "5.5 More stats: tapply\nTapply is a base R function and allows to apply a function to each cell of a ragged array, that is to each (non-empty) group of values given by a unique combination of the levels of certain factors. It can be used as an alternative to ddply.\nSuppose now we want to estimate the mean root length for each growth condition. Notice, how we can vary the index?\n\n#index = factors we want to select\ntapply(X = growth_data$Rootlength, INDEX = growth_data$Nutrient, FUN = mean,na.rm = TRUE)\n\n      noP         P \n 6.530845 11.513931 \n\n\n\n#same but for two-way tables (this is not so useful here, but might be handy when you have different conditions for the same organism or a timecourse)\ntapply(growth_data$Rootlength, INDEX = list(growth_data$Nutrient, growth_data$Condition),FUN = mean, na.rm = TRUE)\n\n        MgCl Strain101 Strain230  Strain28\nnoP 5.805198  7.094616  7.172883  6.200309\nP   9.853457 12.729133 11.814678 12.007390",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#linear-models",
    "href": "code/stats.html#linear-models",
    "title": "5  Statistics in R",
    "section": "5.6 Linear models",
    "text": "5.6 Linear models\n\n5.6.1 Basics\nIt is very simple to investigate linear relationships among variables in R. We want to estimate how a quantitative dependent variable changes according to the levels of one or more categorical independent variables. In the command below, the linear relationship between Rootlength (the dependent variable, i.e. the one we’re trying to predict) and FW_shoot_mg (the independent variable or the predictor) is calculated.\nWe need to use the function summary to see the results of that command; coef extracts the best-fit coefficients, anova performs an analysis of variance; there are many other extractor functions.\nIn this case lets work with the data were we do not have to deal with the different time points to simplify things.\n\n#read in data were we have several measurements\ngrowth_data &lt;- read.table(\"../data/Growth_Data.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\n\n#is there a correlation between freshweight and root length?\nlinearmodel &lt;- lm(Rootlength ~ FW_shoot_mg, data = growth_data)\nlinearmodel\n\n\nCall:\nlm(formula = Rootlength ~ FW_shoot_mg, data = growth_data)\n\nCoefficients:\n(Intercept)  FW_shoot_mg  \n     5.2912       0.2465  \n\n\n\n#let's extract the entire t-table\nsummary(linearmodel) \n\n\nCall:\nlm(formula = Rootlength ~ FW_shoot_mg, data = growth_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5263 -0.9978 -0.0181  1.0094  3.9292 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  5.29124    0.30469   17.37   &lt;2e-16 ***\nFW_shoot_mg  0.24648    0.01712   14.40   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.615 on 103 degrees of freedom\nMultiple R-squared:  0.6681,    Adjusted R-squared:  0.6649 \nF-statistic: 207.4 on 1 and 103 DF,  p-value: &lt; 2.2e-16\n\n\nHere one of the values is the model p-Value (bottom last line) and the p-Value of individual predictor variables (extreme right column under ‘Coefficients’). The p-Values are very important because, we can consider a linear model to be statistically significant only when both these p-Values are less that the pre-determined statistical significance level, which is ideally 0.05. This is visually interpreted by the significance stars at the end of the row. The more the stars beside the variable’s p-Value, the more significant the variable.\n\nResiduals: The section summarizes the residuals, the error between the prediction of the model and the actual results. Smaller residuals are better.\nCoefficients: For each variable and the intercept, a weight is produced and that weight has other attributes like the standard error, a t-test value and significance.\nEstimate: This is the weight given to the variable. In the simple regression case (one variable plus the intercept), for every increase in root length, the model predicts an increase of 0.24.\nStd. Error: Tells you how precisely was the estimate measured. It’s really only useful for calculating the t-value.\nt-value and Pr(&gt;[t]): The t-value is calculated by taking the coefficient divided by the Std. Error. It is then used to test whether or not the coefficient is significantly different from zero. If it isn’t significant, then the coefficient really isn’t adding anything to the model and could be dropped or investigated further. Pr(&gt;|t|) is the significance level.\n\nPerformance Measures:\nThree sets of measurements are provided.\n\nResidual Standard Error: This is the standard deviation of the residuals. Smaller is better.\nMultiple / Adjusted R-Square: For one variable, the distinction doesn’t really matter. R-squared shows the amount of variance explained by the model. Adjusted R-Square takes into account the number of variables and is most useful for multiple-regression.\nF-Statistic: The F-test checks if at least one variable’s weight is significantly different than zero. This is a global test to help asses a model. If the p-value is not significant (e.g. greater than 0.05) than your model is essentially not doing anything.\n\nWe also can just print parts of the data:\n\n#print only the coefficients \ncoef(summary(linearmodel))\n\n             Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept) 5.2912436 0.30469198 17.36588 2.278273e-32\nFW_shoot_mg 0.2464783 0.01711628 14.40023 2.039703e-26\n\n\n\n#print only the anova stats\nanova(linearmodel)\n\n\n  \n\n\n\n\n#plot add the best line to a plot\nwith(growth_data, plot(Rootlength ~ FW_shoot_mg, col = 2))\nabline(linearmodel)\n\n\n\n\n\n\n\n\nIf we look at the stats and the p value we see a nice correlation but also that we have two distinct clusters as well as more spread in the cluster that is more to the right. These clusters likely are the two different nutrient conditions and sometimes it might make sense to separate data to get a clearer picture. Something else to consider is to ask whether the data is normally distributed and based on that what statistical test to choose.\n\n\n5.6.2 Analysing residuals\nAnyone can fit a linear model in R. The real test is analyzing the residuals (the error or the difference between actual and predicted results).\nThere are four things we are looking for when analyzing residuals.\n\nThe mean of the errors is zero (and the sum of the errors is zero)\nThe distribution of the errors are normal.\nAll of the errors are independent.\nVariance of errors is constant (Homoscedastic)\n\nIn R, you pull out the residuals by referencing the model and then the resid variable inside the model. Using the simple linear regression model (simple.fit) we’ll plot a few graphs to help illustrate any problems with the model.\nBelow some examples:\n\nsimple.fit &lt;- linearmodel\n\nlayout(matrix(c(1,1,2,3),2,2,byrow=T))\n\n#Rootlength x Residuals Plot\nplot(simple.fit$resid~growth_data$Rootlength[order(growth_data$Rootlength)],\n main=\"Rootlength x Residuals\\nfor Simple Regression\",\n xlab=\"Marketing Rootlength\", ylab=\"Residuals\")\nabline(h=0,lty=2)\n\n#Histogram of Residuals\nhist(simple.fit$resid, main=\"Histogram of Residuals\",\n ylab=\"Residuals\")\n\n#Q-Q Plot\nqqnorm(simple.fit$resid)\nqqline(simple.fit$resid)\n\n\n\n\n\n\n\n\nThe histogram and QQ-plot are the ways to visually evaluate if the residual fit a normal distribution.\n\nIf the histogram looks like a bell-curve it might be normally distributed.\nIf the QQ-plot has the vast majority of points on or very near the line, the residuals may be normally distributed.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#normal-distribution",
    "href": "code/stats.html#normal-distribution",
    "title": "5  Statistics in R",
    "section": "5.7 Normal distribution",
    "text": "5.7 Normal distribution\n\n5.7.1 Visualize our data via density plots\nThere are different ways to visualize this, one example is ggdensity of the ggpubr package.\n\nlibrary(\"ggpubr\")\n\n\nAttaching package: 'ggpubr'\n\n\nThe following object is masked from 'package:plyr':\n\n    mutate\n\n#is the data for my different variables normally distributed\nggdensity(growth_data$Rootlength)\n\n\n\n\n\n\n\n\nWe see nicely that we have two tails that likely represent the two nutrient conditions. To test this, we can simply subset the data as we have done before.\n\nggdensity(growth_data, x = \"Rootlength\",\n   add = \"mean\", rug = TRUE,\n   color = \"Nutrient\", palette = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\n\n\n\nNo we see that indeed the tool tails we see are seem to be due to our two nutrient conditions.\n\n\n5.7.2 Visualize our data via Q-Q plots\nAnother way to represent data is in a Q-Q plot: Q-Q plot (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. A 45-degree reference line is also plotted.\n\n#plot all data\nggqqplot(growth_data$Rootlength)\n\n\n\n\n\n\n\n\n\n#plot by group\nggqqplot(growth_data, x = \"Rootlength\",\n         color = \"Nutrient\",  palette = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\n\n\n\nAgain, here we see that our data for the indivdual growth conditions fit quite nicely into normal distribution.\n\n\n5.7.3 Test for normality\n\n#for all data\nshapiro.test(growth_data$Rootlength)\n\n\n    Shapiro-Wilk normality test\n\ndata:  growth_data$Rootlength\nW = 0.91773, p-value = 6.744e-06\n\n\n\n#separate nutrient conditions\nnoP_data &lt;- growth_data[growth_data$Nutrient == \"noP\", ]\n\n#test for noP only\nshapiro.test(noP_data$Rootlength)\n\n\n    Shapiro-Wilk normality test\n\ndata:  noP_data$Rootlength\nW = 0.96403, p-value = 0.1171\n\n\nWe can use ddplyr and the dlookr package for doing a group-wise comparison\n\nlibrary(dplyr)\nlibrary(dlookr)\n\nWarning: package 'dlookr' was built under R version 4.4.3\n\n\nRegistered S3 methods overwritten by 'dlookr':\n  method          from  \n  plot.transform  scales\n  print.transform scales\n\n\n\nAttaching package: 'dlookr'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nThe following object is masked from 'package:base':\n\n    transform\n\ngrowth_data %&gt;%\n  group_by(Nutrient) %&gt;%\n  normality()\n\n\n  \n\n\n\nThe shapiro.test tests the NULL hypothesis that the samples came from a Normal distribution. This means that if your p-value &lt;= 0.05, then you would reject the NULL hypothesis that the samples came from a normal distribution.\nFrom the output, the p-value &lt; 0.05 for our complete dataset implies that the distribution of the data is significantly different from normal distribution. In other words, we can not assume the normality. However, we expect quite some differences dependent on the growth pattern and once we only look at our low P data we see that our indeed is normally distributed.\nNotice: Shapiro works only for sample sizes between 3-5000 numbers since when you feed it more data, the chances of the null hypothesis being rejected becomes larger. An alternative is the Anderson-Darling test that however has a similar problem with the Shapiro Wilk test. For large samples, you are most likely to reject the null hypothesis, so be aware of this.\n\nlibrary(nortest)\nad.test(noP_data$Rootlength)\n\n\n    Anderson-Darling normality test\n\ndata:  noP_data$Rootlength\nA = 0.58838, p-value = 0.1187",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#anova",
    "href": "code/stats.html#anova",
    "title": "5  Statistics in R",
    "section": "5.8 ANOVA",
    "text": "5.8 ANOVA\nWhen we visualize the data, we see that there is a difference between the nutrient conditions but we want to know whether it is significant and more importantly, whether there is also a difference based on our treatments with different strains of microbes.\n\n#lets visually compare our data with ggpubr again\nlibrary(\"ggpubr\")\n\nggboxplot(growth_data, x = \"Condition\", y = \"Rootlength\", color = \"Nutrient\",\n          palette = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\n\n\n\n\n# We want to know whether root length depends on nutrient treatment\naov &lt;- aov(Rootlength ~ Nutrient, data = growth_data)\nsummary(aov)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)    \nNutrient      1  651.8   651.8     425 &lt;2e-16 ***\nResiduals   103  157.9     1.5                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere, we see that there are significant differences based on our nutrient treatments. Now lets see how we can look at both the nutrient treatment and growth conditions.\n\n# We want to know if root length depends on condition and nutrient\naov &lt;- aov(Rootlength ~ Nutrient + Condition, data = growth_data)\nsummary(aov)\n\n             Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nNutrient      1  651.8   651.8  712.58  &lt; 2e-16 ***\nCondition     3   66.5    22.2   24.23 7.27e-12 ***\nResiduals   100   91.5     0.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFrom the ANOVA table we can conclude that both nutrient condition and treatment are statistically significant. Nutrient treatment is the most significant factor variable.\nNot the above fitted model is called additive model. It makes an assumption that the two factor variables are independent. If you think that these two variables might interact to create an synergistic effect, replace the plus symbol (+) by an asterisk (*), as follows.\n\n# Two-way ANOVA with interaction effect\n\n# These two calls are equivalent\naov &lt;- aov(Rootlength ~ Nutrient * Condition, data = growth_data)\naov &lt;- aov(Rootlength ~ Nutrient + Condition + Nutrient:Condition, data = growth_data)\n\n#summarize the aov\nsummary(aov)\n\n                   Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nNutrient            1  651.8   651.8 817.131  &lt; 2e-16 ***\nCondition           3   66.5    22.2  27.780 4.72e-13 ***\nNutrient:Condition  3   14.1     4.7   5.891 0.000976 ***\nResiduals          97   77.4     0.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIt can be seen that the two main effects (Nutrient and Condition) are statistically significant, as well as their interaction.\nNote that, in the situation where the interaction is not significant you should use the additive model.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#tukey",
    "href": "code/stats.html#tukey",
    "title": "5  Statistics in R",
    "section": "5.9 TUKEY",
    "text": "5.9 TUKEY\nIn ANOVA test, a significant p-value indicates that some of the group means are different, but we don’t know which pairs of groups are different. It’s possible to perform multiple pairwise-comparison, to determine if the mean difference between specific pairs of group are statistically significant.\nAs the ANOVA test is significant, we can compute Tukey HSD (Tukey Honest Significant Differences). Tukey test is a single-step multiple comparison procedure and statistical test. It is a post-hoc analysis, what means that it is used in conjunction with an ANOVA.\n\n#test with anova\naov &lt;- aov(Rootlength ~ Nutrient * Condition, data = growth_data)\n\n#run tukey\nTukeyHSD(aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Rootlength ~ Nutrient * Condition, data = growth_data)\n\n$Nutrient\n          diff      lwr      upr p adj\nP-noP 4.983086 4.637105 5.329067     0\n\n$Condition\n                          diff        lwr        upr     p adj\nStrain101-MgCl       2.1029052  1.4604930  2.7453173 0.0000000\nStrain230-MgCl       1.6836191  1.0341749  2.3330633 0.0000000\nStrain28-MgCl        1.2784796  0.6545138  1.9024455 0.0000034\nStrain230-Strain101 -0.4192861 -1.0864726  0.2479004 0.3597470\nStrain28-Strain101  -0.8244256 -1.4668377 -0.1820134 0.0061445\nStrain28-Strain230  -0.4051395 -1.0545837  0.2443048 0.3663501\n\n$`Nutrient:Condition`\n                                  diff        lwr        upr     p adj\nP:MgCl-noP:MgCl              4.0482585  2.9997859  5.0967311 0.0000000\nnoP:Strain101-noP:MgCl       1.2894180  0.2041458  2.3746903 0.0087961\nP:Strain101-noP:MgCl         6.9239348  5.8162834  8.0315861 0.0000000\nnoP:Strain230-noP:MgCl       1.3676850  0.2341551  2.5012149 0.0073003\nP:Strain230-noP:MgCl         6.0094793  4.9242070  7.0947515 0.0000000\nnoP:Strain28-noP:MgCl        0.3951101 -0.6533625  1.4435827 0.9391499\nP:Strain28-noP:MgCl          6.2021911  5.1169189  7.2874633 0.0000000\nnoP:Strain101-P:MgCl        -2.7588405 -3.8073131 -1.7103679 0.0000000\nP:Strain101-P:MgCl           2.8756763  1.8040558  3.9472967 0.0000000\nnoP:Strain230-P:MgCl        -2.6805735 -3.7789218 -1.5822252 0.0000000\nP:Strain230-P:MgCl           1.9612207  0.9127482  3.0096933 0.0000023\nnoP:Strain28-P:MgCl         -3.6531484 -4.6634819 -2.6428149 0.0000000\nP:Strain28-P:MgCl            2.1539326  1.1054600  3.2024052 0.0000002\nP:Strain101-noP:Strain101    5.6345168  4.5268654  6.7421681 0.0000000\nnoP:Strain230-noP:Strain101  0.0782670 -1.0552629  1.2117969 0.9999989\nP:Strain230-noP:Strain101    4.7200613  3.6347890  5.8053335 0.0000000\nnoP:Strain28-noP:Strain101  -0.8943079 -1.9427805  0.1541647 0.1537008\nP:Strain28-noP:Strain101     4.9127731  3.8275008  5.9980453 0.0000000\nnoP:Strain230-P:Strain101   -5.5562498 -6.7112241 -4.4012755 0.0000000\nP:Strain230-P:Strain101     -0.9144555 -2.0221069  0.1931958 0.1845494\nnoP:Strain28-P:Strain101    -6.5288247 -7.6004451 -5.4572042 0.0000000\nP:Strain28-P:Strain101      -0.7217437 -1.8293950  0.3859077 0.4749256\nP:Strain230-noP:Strain230    4.6417943  3.5082644  5.7753242 0.0000000\nnoP:Strain28-noP:Strain230  -0.9725749 -2.0709232  0.1257734 0.1223122\nP:Strain28-noP:Strain230     4.8345061  3.7009762  5.9680360 0.0000000\nnoP:Strain28-P:Strain230    -5.6143692 -6.6628417 -4.5658966 0.0000000\nP:Strain28-P:Strain230       0.1927118 -0.8925604  1.2779841 0.9993212\nP:Strain28-noP:Strain28      5.8070810  4.7586084  6.8555536 0.0000000\n\n\nWe can see that most differences are significant, with the exception of Strain28, which in most cases does not show an effect.\nFor some representations it is useful to plot significant letters. We can do this using some extra packages as follows:\n\n#load library\nlibrary(agricolae)\n\nWarning: package 'agricolae' was built under R version 4.4.3\n\n\n\nAttaching package: 'agricolae'\n\n\nThe following objects are masked from 'package:dlookr':\n\n    kurtosis, skewness\n\n#separate nutrient conditions\nnoP_data &lt;- growth_data[growth_data$Nutrient == \"noP\", ]\n\n#run an anova\naov_noP &lt;- aov(Rootlength ~ Condition, data = noP_data)\n\n#run test\nHSD.test(aov_noP,\"Condition\", group=TRUE,console=TRUE)\n\n\nStudy: aov_noP ~ \"Condition\"\n\nHSD Test for Rootlength \n\nMean Square Error:  0.606883 \n\nCondition,  means\n\n          Rootlength       std  r        se      Min      Max      Q25      Q50\nMgCl        5.805198 0.7738124 13 0.2160632 4.236348 6.834720 5.484364 5.743447\nStrain101   7.094616 0.5939804 13 0.2160632 5.947965 7.973207 6.717792 7.143667\nStrain230   7.172883 0.6117203 11 0.2348855 6.120089 8.197116 6.759308 7.166174\nStrain28    6.200309 0.9988989 15 0.2011439 4.384756 7.428674 5.349532 6.372659\n               Q75\nMgCl      6.424601\nStrain101 7.508370\nStrain230 7.590593\nStrain28  7.014785\n\nAlpha: 0.05 ; DF Error: 48 \nCritical Value of Studentized Range: 3.763749 \n\nGroups according to probability of means differences and alpha level( 0.05 )\n\nTreatments with the same letter are not significantly different.\n\n          Rootlength groups\nStrain230   7.172883      a\nStrain101   7.094616      a\nStrain28    6.200309      b\nMgCl        5.805198      b",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#check-the-homogeneity-of-variances",
    "href": "code/stats.html#check-the-homogeneity-of-variances",
    "title": "5  Statistics in R",
    "section": "5.10 Check the homogeneity of variances",
    "text": "5.10 Check the homogeneity of variances\nThe residuals versus fits plot is used to check the homogeneity of variances. In the plot below, there is no evident relationships between residuals and fitted values (the mean of each groups), which is good. So, we can assume the homogeneity of variances. Only a few points (41, 58 and 77 are detected as outliers, which can severely normality and homogeneity of variance. It can be useful to remove outliers to meet the test assumptions.)\n\n#check for homogeneity\nplot(aov, 1)\n\n\n\n\n\n\n\n#Use the Levene’s test to check the homogeneity of variances. \nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nleveneTest(Rootlength ~ Nutrient * Condition, data = growth_data)\n\n\n  \n\n\n\nFrom the output above we can see that the p-value is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance across groups is statistically significantly different. Therefore, we can assume the homogeneity of variances in the different treatment groups.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/stats.html#check-for-normality-v2",
    "href": "code/stats.html#check-for-normality-v2",
    "title": "5  Statistics in R",
    "section": "5.11 Check for normality v2",
    "text": "5.11 Check for normality v2\nNormality plot of the residuals. In the plot below, the quantiles of the residuals are plotted against the quantiles of the normal distribution. A 45-degree reference line is also plotted. The normal probability plot of residuals is used to verify the assumption that the residuals are normally distributed.\nThe normal probability plot of the residuals should approximately follow a straight line. which we can see below. Again, we see the points marked as potential outliers.\n\n## plot\nplot(aov, 2)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistics in R</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html",
    "href": "code/plotting_basics.html",
    "title": "6  Basic plotting",
    "section": "",
    "text": "6.1 Using base R",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html#using-base-r",
    "href": "code/plotting_basics.html#using-base-r",
    "title": "6  Basic plotting",
    "section": "",
    "text": "6.1.1 Scatter plots\nThe examples below are part of base R, i.e. we can plot without using any packages. However, there are some nice packages that let you control a lot of parameters, which are good to learn for more sophisticates plots.\nPlotting in base R is simple, we just need to define, what we plot against the x- and y-axis.\n\n# lets plot our root length against our shoot weight\nx &lt;- growth_data$FW_shoot_mg\ny &lt;- growth_data$Rootlength\n\nplot(x, y)\n\n\n\n\n\n\n\n\nNow, lets add some more axis labels to make it more informative and lets startt the plot at 0:\n\n# lets plot our root length against our shoot weight\nx &lt;- growth_data$FW_shoot_mg\ny &lt;- growth_data$Rootlength\n\nplot(x, y, xlab = \"Shoot_weight_mg\", ylab = \"Rootlength_cm\", ylim = c(0, 15), xlim = c(0, 50))\n\n\n\n\n\n\n\n\nA useful thing to know is that you can add plots together, i.e. we can add a regression line:\n\n#lets do the stats running a linear model (lm)\nlm(growth_data$Rootlength ~ growth_data$FW_shoot_mg)\n\n\nCall:\nlm(formula = growth_data$Rootlength ~ growth_data$FW_shoot_mg)\n\nCoefficients:\n            (Intercept)  growth_data$FW_shoot_mg  \n                 5.2912                   0.2465  \n\n\nHere, the intercept is 5.2912 and the slope is 0.2465 .\n\n# lets plot our root length against our shoot weight\nx &lt;- growth_data$FW_shoot_mg\ny &lt;- growth_data$Rootlength\n\n#plot\nplot(x, y, xlab = \"Shoot_weight_mg\", ylab = \"Rootlength_cm\", ylim = c(0, 15), xlim = c(0, 50))\n\n#add the info from ln (both lines of code do the same thing)\nabline(lm(growth_data$Rootlength ~ growth_data$FW_shoot_mg))\n\n\n\n\n\n\n\n\nWe can even add the stats, but therefore we need to prepare the stats a bit better:\n\n#to stats\nmodl = lm(growth_data$Rootlength ~ growth_data$FW_shoot_mg)\n\n#get summary\nmodsum = summary(modl)\n\n#get R2\nr2 = modsum$adj.r.squared\n\n#look at the coefficients\nmodsum$coefficients\n\n                         Estimate Std. Error  t value     Pr(&gt;|t|)\n(Intercept)             5.2912436 0.30469198 17.36588 2.278273e-32\ngrowth_data$FW_shoot_mg 0.2464783 0.01711628 14.40023 2.039703e-26\n\n#get the p-value (its in the coefficient table, in the 2nd row and 4th column)\nmy.p = modsum$coefficients[2,4]\n\nNow we can plot this:\n\n#add a label, in which we store the text we want to add\nmylabel = bquote(italic(R)^2 == .(format(r2, digits = 3)))\n\n#plot\nplot(x, y, xlab = \"Shoot_weight_mg\", ylab = \"Rootlength_cm\", ylim = c(0, 15), xlim = c(0, 50))\n\n#add the info from ln (both lines of code do the same thing)\nabline(lm(growth_data$Rootlength ~ growth_data$FW_shoot_mg))\n\n#add the text\ntext(x = 45, y =14, labels = mylabel)\n\n\n\n\n\n\n\n\nIf we want to add the other value, it gets a bit more complicated esp. if we want to have first the R2 and then, in a new line, the p-value.\nFor this, lets first prepare a new label\n\n#make an empty vecotr\nrp = vector('expression',2)\nrp\n\nexpression(NULL, NULL)\n\n#add our two values into the vector\nrp[1] = substitute(expression(italic(R)^2 == MYVALUE), \n        list(MYVALUE = format(r2,dig=3)))[2]\n\nrp[2] = substitute(expression(italic(p) == MYOTHERVALUE), \n        list(MYOTHERVALUE = format(my.p, digits = 2)))[2]\n\nrp\n\nexpression(italic(R)^2 == \"0.665\", italic(p) == \"2e-26\")\n\n\nLets plot this:\n\n#plot\nplot(x, y, xlab = \"Shoot_weight_mg\", ylab = \"Rootlength_cm\", ylim = c(0, 15), xlim = c(0, 50))\n\n#add the info from ln (both lines of code do the same thing)\nabline(lm(growth_data$Rootlength ~ growth_data$FW_shoot_mg))\n\n#add the text as a legend and remove the border with bty\nlegend(\"topright\", legend = rp, bty = 'n')\n\n\n\n\n\n\n\n\n\n\n6.1.2 Lineplots\nNow, lets work with our time course data to draw some line plots. I.e. lineplots are ideal if we have measurements over time.\nLets first summarize our time course data to make it easier to plot.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:plyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n\n\nThe following object is masked from 'package:kableExtra':\n\n    group_rows\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n#first filter to only print P data, then summarize the data by condition and timepoint and calculate the mean\ntimecourse_summary &lt;- timecourse_noNA %&gt;% \n    filter(Nutrient == \"P\")  %&gt;% \n    group_by(Condition, Timepoint) %&gt;%  \n    summarise(mean_root = mean(Rootlength))\n\n`summarise()` has grouped output by 'Condition'. You can override using the\n`.groups` argument.\n\nhead(timecourse_summary)\n\n\n  \n\n\n#split the data into our two categories\ntimecourse_summary_Control &lt;- timecourse_summary[timecourse_summary$Condition == 'MgCl',]\ntimecourse_summary_350 &lt;- timecourse_summary[timecourse_summary$Condition == '350',]\n\nUseful comments:\n\ntype= It controls the type (p for points, l for lines, b for both,&lt;80&gt;).\npch= integer [0,25]. Controls the plot symbol.\nlog= It causes the x axis x, y axis y or both xy to be logarithmic.\nxlab=, ylab= string, labels for the x and y axis, respectively.\nxlim=, ylim= length 2 vector, x-axis, y-axis limits.\nmain= string, title of the plot.\ncol = hexadecimal or string, colour of the points/lines.\n\n\nx &lt;- 0:5\ny &lt;- timecourse_summary_Control$mean_root\n\nplot(x, y, type = \"b\", pch = 19, xlab = \"Timepoints\", ylab = \"Rootlength (cm)\", col = \"#7700BB\", main = \"Growth measurements\")\n\n\n\n\n\n\n\n\nplot() always overwrites the content for the current graphics window.\nTo add elements to an existing plot, one can use points, lines, abline, text, &lt;80&gt; We can also add a legend to the plot.\nIn the previous graph eith out growth measurements let us add the root growth of our microbe treatment.\n\nx &lt;- 0:5\ny &lt;- timecourse_summary_Control$mean_root\nz &lt;- timecourse_summary_350$mean_root\n\nplot(x, y, type = \"b\", pch = 19, xlab = \"Timepoints\", ylab = \"Rootlength (cm)\",col = \"#7700BB\", ylim = c(0, 15), main = \"Growth measurements\")\nlines(x, z, type = \"b\", col = \"#5555DD\")\nlegend(\"topright\", c(\"control\", \"microbe\"), col = c(\"#7700BB\", \"#5555DD\"),pch = c(19, 1))\n\n\n\n\n\n\n\n\nWe can see nicely, that our roots grow longer past the 3rd timepoint.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html#info-on-using-par",
    "href": "code/plotting_basics.html#info-on-using-par",
    "title": "6  Basic plotting",
    "section": "6.2 info on using par",
    "text": "6.2 info on using par\nTo change graphical parameters globally you can use par. R allows for n &lt;97&gt; m figures in a single page, by adjusting the parameter mfrow:\n\nmfrow = c(3, 1) –&gt; we have 3 plots distributed across 3 rows and one column\npar(mai = c(2, 0.82, 0.82, 0.42)) –&gt; sets the bottom, left, top and right margins respectively of the plot region in number of lines of text. If we change the margins it is recommended to reset them to the default after plotting with par(mai = c(1.02, 0.82, 0.82, 0.42)).\n\n\npar(mfrow = c(n, m)) # n: number of figures in rows, m: ... in columns.\nplot(x1, y1)\nplot(x1, y2)\n...\nplot(xn, ym)\n\n#save a file\npng(\"../output_examples/filename.png\")\nplot(x, y)\ndev.off()\n\nIn the above code chunk, you first open a png file, then plot directly to that file, and finally explicitly close the plotting device with dev.off(). Thus, you do not see the plot on the graphics window. The Cairo package is supposed to be superior to these basic plotting functions, but it does not come with the base installation of R, therefore you will have to install it to try it out (if you are interested, or at a later time).\n\n6.2.1 Printing our results using par\nNow lets generate a png file plot.png containing three plots in three different rows.\n\nThe data for our control treatment\nThe data for our microbe treatment\nThe data combined in one plot\n\n\nx &lt;- 0:5\ncontrol &lt;- timecourse_summary_Control$mean_root\nMicrobe &lt;- timecourse_summary_350$mean_root\n\n#define what we want to print\npng(\"../output_examples/filename2.png\", width = 240, height = 480)\n\n#define how we want to order our 3 plots into rows and columns\npar(mfrow = c(3, 1)) \n\n#build plot1\nplot(x, control, type = \"b\", pch = 19, xlab = \"Timepoints\", ylab = \"Rootlength (cm)\",col = \"#7700BB\", main = \"Growth measurements\")\n\n#build plot2\nplot(x, Microbe, type = \"b\", pch = 19, xlab = \"Timepoints\", ylab = \"Rootlength (cm)\",col = \"#5555DD\", main = \"Growth measurements\")\n\n#build plot3\nplot(x, control, type = \"b\", pch = 19, xlab = \"Timepoints\", ylab = \"Rootlength (cm)\",col = \"#7700BB\", ylim = c(0, 15), main = \"Growth measurements\")\nlines(x, Microbe, type = \"b\", col = \"#5555DD\")\nlegend(\"topright\", c(\"control\", \"microbe\"), col = c(\"#7700BB\", \"#5555DD\"),pch = c(19, 1))\n\n#closes the specified plot\ndev.off()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html#histograms",
    "href": "code/plotting_basics.html#histograms",
    "title": "6  Basic plotting",
    "section": "6.3 Histograms",
    "text": "6.3 Histograms\nA histogram shows the frequency of data values in equally sized intervals. Density plots are an alternative, but because of the smoothing between data points, histograms provide a more &lt;80&gt;&lt;98&gt;natural&lt;80&gt;&lt;99&gt; look at your data. If you are interested in how to make a density plot, look at the help page of density.\nAs an example, lets plot the distribution of our root length measurements across our data.\n\nhist(growth_data[, \"Rootlength\"], cex = 0.6, main = \"Data distribution\", breaks = 10, density = 100, col = \"lightblue\", border = \"darkblue\", xlab = \"Rootlength\", labels =T)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html#boxplots",
    "href": "code/plotting_basics.html#boxplots",
    "title": "6  Basic plotting",
    "section": "6.4 Boxplots",
    "text": "6.4 Boxplots\nBoxplots represent a compact summary of a data vector in graphical form.\nAs we&lt;80&gt;&lt;99&gt;ve already seen above, the function summary returns summary statistics on the command line: the minimum, first quartile, mean, median, third quartile and the maximum.\nThe boxplot displays these values graphically (except the mean) as follows:\n\nthe thick line in the middle of the box represents the median,\nthe lower bound of the box the first quartile and the upper bound the third quartile. Thus, 50% of the data are within the range of the box.\nThe whiskers (thin lines below and above the box) represent the minimum and maximum.\nPoints more extreme than the min. and max. are considered outliers and the help page describes how they are defined.\n\nWe will first make a boxplot of all measurements and then check for differences between the two nutrient conditions.. Play around with the parameters and add colors and labels.\n\n# all data\nboxplot(growth_data$Rootlength, cex = 0.8,  ylab = \"Root length (cm)\")\n\n\n\n\n\n\n\n\n\n# data by nutrient condition\nboxplot(growth_data$Rootlength ~ growth_data$Nutrient, las = 2, cex = 0.8, ylab = \"Root length (cm)\")\n\n\n\n\n\n\n\n\n\n# data by nutrient and growth condition\nboxplot(growth_data$Rootlength ~ growth_data$Nutrient * growth_data$Condition, las = 2, cex = 0.8, ylab = \"Root length (cm)\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/plotting_basics.html#ggplot2",
    "href": "code/plotting_basics.html#ggplot2",
    "title": "6  Basic plotting",
    "section": "6.5 Ggplot2",
    "text": "6.5 Ggplot2\nGplot2 is a system for declaratively creating graphics, based on The Grammar of Graphics. You provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.\nDetailed info can be found here: https://ggplot2.tidyverse.org\nOne important difference to basic plots is that argument can be given in separate blocks that are separated by a +\n\n6.5.0.1 Start with a basic bargraph\n\nlibrary(ggplot2)\n\n#make a bargraph\nmyplot &lt;-\n  ggplot(growth_data, aes(x =Nutrient, y = Rootlength)) +  #here we provide the dimensions of our plot\n  geom_bar(stat=\"identity\")                                   #here, we say what kind of plot we want \n\nmyplot\n\n\n\n\n\n\n\n\nWe see that the default behavior is to sum everything, which is not what we want. Luckily switching different graph types is very quick\n\n#make a boxplot instead of bargrpah\nmyplot &lt;-\n  ggplot(growth_data, aes(x =Nutrient, y = Rootlength)) +  \n  geom_boxplot()                                   \n\nmyplot\n\n\n\n\n\n\n\n\n\n#do a histogram\nmyplot &lt;-\n  ggplot(growth_data, aes(Rootlength)) +  \n  geom_histogram()                                   \n\nmyplot\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe only thing we might want to watch out for is that depending on what data we plot the astethics might need to be adopted. I.e. for a histogram there is no need to provide a x and y value, but we only need to define for what data we want to plot a histogram.\nAnother useful feature is to add colors by groupings, i.e. nutrient conditions, using the fill option.\n\nmyplot &lt;-\n  ggplot(growth_data, aes(x =Nutrient, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()                                   \n\nmyplot\n\n\n\n\n\n\n\n\n\n\n6.5.0.2 Prettify\nBy default the basic design of a ggplot2 is not ready for publication but we can control every aspects to make it look nicer. A cheat sheet for all the options can be found here\n\nmyplot &lt;-\n  ggplot(growth_data, aes(x =Nutrient, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()  +                                 \n  scale_fill_manual(values=c(\"black\", \"grey\")) +                                          #add some other colors\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 16)) +                               #make the axis start at 0 \n  theme_bw() +                                                                            #remove the grey background\n  ylab(\"Root length (cm)\") +                                                              #change the label for the y-axis\n  xlab(\"\") +                                                                              #remove the label for the x axis\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),           #modify the grid lines\n        panel.background = element_blank(), axis.line = element_line(colour = \"black\")) +\n  theme(legend.position=\"right\",                                                          #move the legend around\n        axis.text.x=element_text(angle=45,hjust = 1, size=12))                            #control size and orientation of the axis labels\n\nmyplot\n\n\n\n\n\n\n\n\n\n\n6.5.0.3 Sort data\nBy default most programs sort alpha in an alphabetical way. We can reorder this using vectors (which we can write ourselves or use a mapping file to create them)\n\n#reorder the nutrient levels in our factors\ngrowth_data$Nutrient2 &lt;-  factor(growth_data$Nutrient, levels = c(\"P\", \"noP\")) \n\n#plot in our new order\nmyplot &lt;-\n  ggplot(growth_data, aes(x =Nutrient2, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()\n\nmyplot\n\n\n\n\n\n\n\n\n\n\n6.5.0.4 Printing data\nWith pdf() we tell R that we want to print something to our computer. Inside the function we can define the name of the pdf to generate, the size and other things. After adding the plot we want to print it is important to run dev.off() in order to tell R to stop the “printing mode” and go back to the default mode.\n\n#lets first generate two plots\nmyplot_root &lt;-\n  ggplot(growth_data, aes(x =Nutrient2, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()\n\nmyplot_shoot &lt;-\n  ggplot(growth_data, aes(x =Nutrient2, y = FW_shoot_mg, fill = Nutrient)) +  \n  geom_boxplot()\n\n#plot one graph\npdf(\"../output_examples/Plot_root_length.pdf\", width=3, height=3, family  = \"Times\")\nmyplot_root\ndev.off()\n\nquartz_off_screen \n                2 \n\n\n\n\n6.5.0.5 Combining and printing multiple plots\nThe ggpubr package is nice to combine multiple plots onto one plot. Some more information on this package can be found here\nHow it works:\n\nFirst list the plots we want to print\nthe labels argument allows us to add labels\nthe ncol and nrow arguments allow us to control how many plots go into a row and a column\n\n\n#load package\nlibrary(ggpubr)\n\n\nAttaching package: 'ggpubr'\n\n\nThe following object is masked from 'package:plyr':\n\n    mutate\n\n#view how ggarrange deals with two plots\nggarrange(myplot_root, myplot_shoot, \n          labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1)\n\n\n\n\n\n\n\n\n\n#we can also plot two graphs and print them in one pdf\npdf(\"../output_examples/Two_plots.pdf\", width=3, height=3, family  = \"Times\")\nggarrange(myplot_root, myplot_shoot, \n          labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1)\ndev.off()\n\nquartz_off_screen \n                2 \n\n\n\n\n6.5.0.6 Sorting data v2\nIf we have multiple conditions, i.e. nutrient conditions and other treatments there are several ways to plot these\n\nPlot them side by side and color by nutrient conditions.\n\n\n#pdf(\"Plot_root_length.pdf\", width=3, height=3, family  = \"Times\")\n  ggplot(growth_data, aes(x =SampleID, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()\n\n\n\n\n\n\n\n#dev.off()\n\n\nChange the order.\n\nNow, here the order is not nice, but as mentioned we can use mapping files to sort our data. Lets try.\n\n#lets check how our mapping file looked like\nkable((mapping_file), format='markdown')\n\n\n\n\n\nSampleID\nNutrient\nCondition\n\n\n\n\n1\nnoP\nnoP\nMgCl\n\n\n14\nnoP_101\nnoP\nStrain101\n\n\n27\nnoP_230\nnoP\nStrain230\n\n\n38\nnoP_28\nnoP\nStrain28\n\n\n53\nP\nP\nMgCl\n\n\n68\nP_101\nP\nStrain101\n\n\n80\nP_230\nP\nStrain230\n\n\n93\nP_28\nP\nStrain28\n\n\n\n\n\nWe can use this simpler table to define how we want to resort our growth data. First, lets reorder the metadata first by nutrient and then condition:\n\n#lets sort the file first conditon an the nutrient (in reverse order, by using the rev() function )\nmapping_file &lt;- mapping_file[with(mapping_file, order(Condition, rev(Nutrient))), ]\n\n#check whether we like how things are ordered (look at the order of the first line)\nmapping_file$SampleID\n\n[1] \"noP\"     \"P\"       \"noP_101\" \"P_101\"   \"noP_230\" \"P_230\"   \"noP_28\" \n[8] \"P_28\"   \n\n\nNow, we can use the order of this file to re-order our larger dataframe with the growth data.\n\n#reorder the levels of our growth data using the mapping file\ngrowth_data$SampleID2 &lt;-  factor(growth_data$SampleID, levels = as.character(mapping_file$SampleID)) \nhead(growth_data)\n\n\n  \n\n\n#plot (for now lets do this side by side)\n  ggplot(growth_data, aes(x =SampleID2, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n6.5.0.7 Bargraphs with error bars\nFor bargraphs we can also make them nice looking with errorbars, however, the values for the mean, sd and so one ideally should be listed in a summary table.\nLuckily we have learned before how we can use ddply to create such a table again and then blot it:\n\n#summarize\ngrowth_data_summarized &lt;- ddply(growth_data, .(SampleID, Nutrient), summarize, RootLength = mean(Rootlength), sd = sd (Rootlength), se = sd(Rootlength) / sqrt((length(Rootlength))))\n\n#order levels\ngrowth_data_summarized$SampleID2 &lt;-  factor(growth_data_summarized$SampleID, levels = as.character(mapping_file$SampleID)) \n\n#plot\n  ggplot(growth_data_summarized, aes(x=SampleID2, y=RootLength, fill=Nutrient)) + \n  geom_bar(stat=\"identity\", color=\"black\", \n           position=position_dodge()) +\n  geom_errorbar(aes(ymin=RootLength-sd, ymax=RootLength+sd), width=.2,\n                 position=position_dodge(.9)) \n\n\n\n\n\n\n\n\n\n\n6.5.0.8 Faceting data\nSometimes, we might to plot data into separate plots. This can be done in ggplot with one extra command. Facetting can do this for you.\nOptions: - Scales “free” tells ggplot that the scales can be different between plots. I.e. axis height. - ncol = allows to control the dimensions of the plot\n\n#plot horizontal\n  ggplot(growth_data, aes(x =SampleID2, y = Rootlength, fill = Nutrient)) +  \n  geom_boxplot() +\n  facet_wrap(. ~ Nutrient, scales = \"free\", ncol = 2)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Basic plotting</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html",
    "href": "code/parsing_output_from_annotations.html",
    "title": "7  Working with annotation data",
    "section": "",
    "text": "7.1 Load essential packages\nAs mentioned in the beginning section, if working with genomes we often have large lists of proteins and their annotations, often from different databases.\nHere, we might be interested in condensing this information for each genome or for each phylum etc . OR we want to merge our data with other tables that are ordered differently. We might also want to plot the data to compare the presence absence levels of different genomes. This section with discuss how to do this in a step by step manner.\n# | warning: false\n\nlibrary(\"ggplot2\")\nlibrary(\"plyr\")\nlibrary(\"dplyr\")\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:plyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(\"grid\")\nlibrary(\"gplots\")\n\n\nAttaching package: 'gplots'\n\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\nlibrary(\"gridExtra\")\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nlibrary(\"multcomp\")\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\nlibrary(\"reshape2\")\nlibrary(\"RColorBrewer\")\nlibrary('tidyr')\n\n\nAttaching package: 'tidyr'\n\n\nThe following object is masked from 'package:reshape2':\n\n    smiths\n\nlibrary('tidyverse')\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.2 --\n\n\nv tibble  3.1.8     v stringr 1.4.1\nv readr   2.1.2     v forcats 0.5.2\nv purrr   0.3.4     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::arrange()     masks plyr::arrange()\nx gridExtra::combine() masks dplyr::combine()\nx purrr::compact()     masks plyr::compact()\nx dplyr::count()       masks plyr::count()\nx dplyr::failwith()    masks plyr::failwith()\nx dplyr::filter()      masks stats::filter()\nx dplyr::id()          masks plyr::id()\nx dplyr::lag()         masks stats::lag()\nx dplyr::mutate()      masks plyr::mutate()\nx dplyr::rename()      masks plyr::rename()\nx MASS::select()       masks dplyr::select()\nx dplyr::summarise()   masks plyr::summarise()\nx dplyr::summarize()   masks plyr::summarize()\n\nlibrary(data.table)\n\n\nAttaching package: 'data.table'\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\nThe following objects are masked from 'package:reshape2':\n\n    dcast, melt\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#deal-with-the-mapping-file-for-our-genomes",
    "href": "code/parsing_output_from_annotations.html#deal-with-the-mapping-file-for-our-genomes",
    "title": "7  Working with annotation data",
    "section": "7.2 Deal with the mapping file for our genomes",
    "text": "7.2 Deal with the mapping file for our genomes\n\n7.2.1 Load mapping file\nmapping file = a table that has the metadata for our genomes. In this specific example it lists our 46 DPANN genomes into clusters based on their phylogenetic placement.\nWe later want to summarize our data by individual bins and the phylogenetic clusters defined in the mapping file.\nNotice: We can also sort our mapping file beforehand and use this order to order our tables, graph, etc…\n\n#read in the mapping file\ndesign &lt;- read.table(\"../data/mapping.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\n\n#check the structure of the mapping file\nhead(design)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#clean-mapping-file",
    "href": "code/parsing_output_from_annotations.html#clean-mapping-file",
    "title": "7  Working with annotation data",
    "section": "7.3 Clean mapping file",
    "text": "7.3 Clean mapping file\nHere, we want to add an extra column that summarizes how many genomes are in each phylogenetic cluster.\nFirst lets summarize how many bins we have for each cluster:\n\nddply() = summarize our data by counting the number of bins we have in each cluster\norder() = next, we order our data based on the clusters with the greater number of bins\n\n\n#add a new column that links the BinID and the taxonomic cluster\ndesign$NewName2 &lt;-paste(design$BinID, design$Cluster, sep = \"-\")\nhead(design)\n\n\n  \n\n\n\n\n#transform mapping file and summarize how many genomes we have/cluster\nNumber_of_taxa &lt;- ddply(design, .(Cluster), summarize, NrGenomes = length(Cluster))\n\n#order our data\nNumber_of_taxa &lt;- Number_of_taxa[order(Number_of_taxa$NrGenomes, decreasing = TRUE),] \n\n#view data\nhead(Number_of_taxa)\n\n\n  \n\n\n\nNext, add this information into our original mapping file:\n\npaste() = paste together different columns. With sep we can control what delimiter we want to use when combining info\n\n\n#add a new column with the cluster count info into mapping file (then it can be added as a label into figures)\ndesign_2 &lt;- merge(design, Number_of_taxa, by = \"Cluster\" )\n\n#view wether all went fine\nhead(design_2)\n\n\n  \n\n\n\nNext, let’s merge all relevant into one column using paste() again:\n\n#generate a new column into the mapping file that links the cluster name with the number of genomes of clusters in each cluster\ndesign_2$ClusterName &lt;- paste(design_2$Cluster, \" (\", design_2$NrGenomes, \")\", sep = \"\")\n\n#view data\nhead(design_2)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#generate-lists-to-order-dataframes",
    "href": "code/parsing_output_from_annotations.html#generate-lists-to-order-dataframes",
    "title": "7  Working with annotation data",
    "section": "7.4 Generate lists to order dataframes",
    "text": "7.4 Generate lists to order dataframes\nThe default behaviour of a lot of R functions is to order data alphabetically but this is not what we might want. I.e. we want to order by different columns or simply order by the initial order in our mapping file. To do this it is useful to have vectors that are order our bins, clusters, etc… like we want them.\nIn this example the mapping file was ordered like this\n\nThe basal group\nGroups from an older dataset (marine and aquifer)\ntwo black sea clades\n\nLets first check, whether our new mapping file still has that order\n\n#check the old data\ndesign$Cluster\n\n [1] \"Basal\"   \"Basal\"   \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Marine\" \n [8] \"Marine\"  \"Marine\"  \"Marine\"  \"Marine\"  \"Marine\"  \"Clade1\"  \"Clade1\" \n[15] \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\" \n[22] \"Clade1\"  \"Clade1\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[29] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[36] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[43] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n\n#check the new data\ndesign_2$Cluster\n\n [1] \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Basal\"   \"Basal\"   \"Clade1\" \n [8] \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\" \n[15] \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[22] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[29] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[36] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Marine\"  \"Marine\" \n[43] \"Marine\"  \"Marine\"  \"Marine\"  \"Marine\" \n\n\nIf we check the individual factors, we can see that the new dataframe is order by alphabet. Since this is not what we want, lets correct this\n\nmatch(design_2$BinID, design$BinID) = We check what positions in design_2 match with design. Here, the first argument are the values to be matched and the second are the values to be matched against.\norder() = we reorder our dataframe based on the results from match()\n\n\n#reorder our old dataframe by the original one\ndesign_2 &lt;- design_2[ order(match(design_2$BinID, design$BinID)), ]\n\n#check, if the basal clade is now in the correct order\ndesign_2$Cluster\n\n [1] \"Basal\"   \"Basal\"   \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Aquifer\" \"Marine\" \n [8] \"Marine\"  \"Marine\"  \"Marine\"  \"Marine\"  \"Marine\"  \"Clade1\"  \"Clade1\" \n[15] \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\"  \"Clade1\" \n[22] \"Clade1\"  \"Clade1\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[29] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[36] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n[43] \"Clade2\"  \"Clade2\"  \"Clade2\"  \"Clade2\" \n\n\nNow, that the basal clade is in the first position, lets make vectors of the bins and clusters in order this we use:\n\nunique() = we use unique on all ClusterNames in our mapping file. That way instead of having repeated names, we only have the unique ones\nas.character() = we make sure that our R object we generated is a character (so has words).\n\n\n#make a list to order our bins\nBin_order &lt;- as.character(unique(design_2$BinID))\nBin_order\n\n [1] \"NIOZ132_cc_b51_2\"   \"NIOZ134_mx_b281_2\"  \"SRR2090153_bin1042\"\n [4] \"SRR2090153_bin461\"  \"SRR2090159_bin1129\" \"SRR2090159_bin1288\"\n [7] \"GCA_002494525\"      \"GCA_002495465\"      \"GCA_002501985\"     \n[10] \"SRR4028224_bin17\"   \"SRR5007147_bin71\"   \"U_76725\"           \n[13] \"NIOZ124_cc_b247_2\"  \"NIOZ125_mb_b254_2\"  \"NIOZ129_mb_b262_2\" \n[16] \"NIOZ126_mb_b401_2\"  \"NIOZ122_mb_b319_2\"  \"NIOZ134_mb_b41_2\"  \n[19] \"NIOZ132_mb_b282_2\"  \"NIOZ127_mb_b161_2\"  \"NIOZ123_bs_b5_2\"   \n[22] \"NIOZ121_cc_b94_2\"   \"NIOZ136_cc_b15_2\"   \"GCA_002502135\"     \n[25] \"NIOZ134_mb_b293_2\"  \"NIOZ132_mb_b260_2\"  \"NIOZ126_mb_b137_2\" \n[28] \"NIOZ129_mb_b254_2\"  \"NIOZ127_mb_b282_2\"  \"NIOZ122_mb_b305_2\" \n[31] \"NIOZ136_mb_b335_2\"  \"NIOZ132_mb_b198_2\"  \"NIOZ136_mb_b104_2\" \n[34] \"NIOZ125_mb_b178_2\"  \"NIOZ121_mb_b48_2\"   \"NIOZ134_cc_b149_2\" \n[37] \"NIOZ134_mb_b361_2\"  \"NIOZ136_mb_b226_2\"  \"NIOZ123_bs_b392_2\" \n[40] \"NIOZ124_mb_b130_2\"  \"NIOZ132_cc_b149_2\"  \"NIOZ125_cc_b75_2\"  \n[43] \"NIOZ132_mx_b314_2\"  \"NIOZ120_mb_b229_2\"  \"NIOZ126_mb_b304_2\" \n[46] \"NIOZ119_mb_b5_2\"   \n\n#make cluster order\nCluster_order &lt;- as.character(unique(design_2$ClusterName))\nCluster_order\n\n[1] \"Basal (2)\"   \"Aquifer (4)\" \"Marine (6)\"  \"Clade1 (11)\" \"Clade2 (23)\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#deal-with-mapping-files-for-the-annotations",
    "href": "code/parsing_output_from_annotations.html#deal-with-mapping-files-for-the-annotations",
    "title": "7  Working with annotation data",
    "section": "7.5 Deal with mapping files for the annotations",
    "text": "7.5 Deal with mapping files for the annotations\nThe mapping files (Arcog_mapping and Metabolism_file_KEGG) that are provided with this tutorial give extra information and order our KO and arCOG annotations. Genes_of_interest is a list of key metabolic genes we want to look at more closely.\n\n7.5.1 Load and view the tables\n\n#general mapping file for arcog IDs\nArcog_mapping &lt;- read.table(\"../data/ar14_arCOGdef19.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\nhead(Arcog_mapping)\n\n\n  \n\n\n#pathway mapping file\nMetabolism_file_KEGG &lt;- read.table(\"../data/Metabolism_Table_KO_Apr2020.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\nhead(Metabolism_file_KEGG)\n\n\n  \n\n\n#load the genes of interest\nGenes_of_interest &lt;- read.table(\"../data/Genes_of_interest.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\nhead(Arcog_mapping)\n\n\n  \n\n\n\n\n\n7.5.2 Make a vector to order our genes of interest\n\nWe use unique() to remove any duplicate gene names\narrange() can be used to order our dataframe by more than one column.\n\nYou notice here that the syntax for arrange() is a bit unusual and we use the %&gt;% symbol (a so-called forward pipe operator). This symbol is commonly used in the dplyr and tidyr packages which are extremely useful to summarize data. This function passes the left hand side of the operator to the first argument of the right hand side of the operator. In the following example, the data frame Genes_of_interest gets passed to arrange()\n\n#order metabolic genes\nGenes_Metabolism_order_temp &lt;- Genes_of_interest %&gt;% arrange(Order, Order2)\n\n#make a unique vector for our genes of interest\nGenes_Metabolism_order &lt;- as.character(unique(Genes_Metabolism_order_temp$Gene))\nGenes_Metabolism_order\n\n  [1] \"HmgB\"                     \"HmgA\"                    \n  [3] \"MvK\"                      \"M3k\"                     \n  [5] \"M3P5K\"                    \"mvaD\"                    \n  [7] \"Ipk\"                      \"GFPS\"                    \n  [9] \"EgsA\"                     \"GGGP_synthase\"           \n [11] \"UbiA\"                     \"GGR\"                     \n [13] \"CarS\"                     \"PgsA\"                    \n [15] \"ASS\"                      \"Asd\"                     \n [17] \"Pol-B1\"                   \"Pol-B2\"                  \n [19] \"Pol-B3\"                   \"PolB-casposon-associated\"\n [21] \"PolD_small\"               \"PolD_large\"              \n [23] \"Pol4\"                     \"PolX\"                    \n [25] \"Orc1\"                     \"SSB/RPA1\"                \n [27] \"RPA2\"                     \"RPA3\"                    \n [29] \"GinS\"                     \"PriS\"                    \n [31] \"PriL\"                     \"DnaG\"                    \n [33] \"Lig \"                     \"LigN\"                    \n [35] \"Pcn1\"                     \"RfcS\"                    \n [37] \"RfcL\"                     \"FEN1\"                    \n [39] \"RnhA\"                     \"RnhB\"                    \n [41] \"MCM2\"                     \"MPH1\"                    \n [43] \"BRR2\"                     \"MUS81\"                   \n [45] \"SrmB\"                     \"Dna2\"                    \n [47] \"TopA\"                     \"GyrA\"                    \n [49] \"GyrB\"                     \"Rgy\"                     \n [51] \"TopB\"                     \"Top6A\"                   \n [53] \"Top6B\"                    \"RecJ/Cdc45\"              \n [55] \"SbcC\"                     \"SbcD\"                    \n [57] \"NurA\"                     \"Nth\"                     \n [59] \"Nfo\"                      \"Nfi\"                     \n [61] \"NucS\"                     \"XthA\"                    \n [63] \"DinG\"                     \"SSO0112\"                 \n [65] \"HerA\"                     \"RadA\"                    \n [67] \"RadB\"                     \"Udg1 \"                   \n [69] \"AlkD\"                     \"Ogt\"                     \n [71] \"Ogg\"                      \"hjc\"                     \n [73] \"UvrA\"                     \"UvrB\"                    \n [75] \"UvrC\"                     \"MthTI\"                   \n [77] \"MthZI\"                    \"MjaII\"                   \n [79] \"MjaIII\"                   \"MjaV\"                    \n [81] \"Dcm\"                      \"DNA_met\"                 \n [83] \"HmfAB\"                    \"HmvA\"                    \n [85] \"ScpA\"                     \"ScpB\"                    \n [87] \"MC1\"                      \"Smc\"                     \n [89] \"Alba1\"                    \"ELP3\"                    \n [91] \"FtsZ\"                     \"MinD\"                    \n [93] \"Cren-1\"                   \"actin_like\"              \n [95] \"Rkd1\"                     \"Rkd2\"                    \n [97] \"CetZ1\"                    \"CdvA\"                    \n [99] \"CdvB\"                     \"Vps4\"                    \n[101] \"RpoC/Rpo3\"                \"RpoC/Rpo11\"              \n[103] \"RpoB/Rpo2\"                \"RpoA/Rpo1\"               \n[105] \"Rpo6/RpoZ\"                \"RPB11\"                   \n[107] \"Rpo4\"                     \"RPB5\"                    \n[109] \"RPB7\"                     \"RPB8\"                    \n[111] \"RPB10\"                    \"RPC12\"                   \n[113] \"Rpo13\"                    \"TBP\"                     \n[115] \"TFB\"                      \"TFE\"                     \n[117] \"TFS\"                      \"LysM\"                    \n[119] \"Spt4\"                     \"NusG\"                    \n[121] \"NusA\"                     \"EGD2\"                    \n[123] \"L1\"                       \"L2\"                      \n[125] \"L3\"                       \"L4\"                      \n[127] \"L5\"                       \"L6P\"                     \n[129] \"L7AE\"                     \"L10\"                     \n[131] \"L10AE/L16\"                \"L11\"                     \n[133] \"L12E/L44/L45/RPP1/RPP2\"   \"L13\"                     \n[135] \"L13E\"                     \"L14\"                     \n[137] \"L14E/L6E/L27E\"            \"L15\"                     \n[139] \"L15E\"                     \"L18\"                     \n[141] \"L18E\"                     \"L19E\"                    \n[143] \"L20A\"                     \"L21E\"                    \n[145] \"L22\"                      \"L23\"                     \n[147] \"L24\"                      \"L24E\"                    \n[149] \"L29\"                      \"L30\"                     \n[151] \"L30E\"                     \"L31E\"                    \n[153] \"L32E\"                     \"L34E\"                    \n[155] \"L35AE/L33A\"               \"L37AE/L43A\"              \n[157] \"L37E\"                     \"L38E\"                    \n[159] \"L39E\"                     \"L40E\"                    \n[161] \"L41E\"                     \"L44E\"                    \n[163] \"S2\"                       \"S3\"                      \n[165] \"S3AE\"                     \"S4\"                      \n[167] \"S4E\"                      \"S5\"                      \n[169] \"S6E/S10\"                  \"S7\"                      \n[171] \"S8\"                       \"S8E\"                     \n[173] \"S9\"                       \"S10\"                     \n[175] \"S11\"                      \"S12\"                     \n[177] \"S13\"                      \"S14\"                     \n[179] \"S15P\"                     \"S17\"                     \n[181] \"S17E\"                     \"S19\"                     \n[183] \"S19E\"                     \"S24E\"                    \n[185] \"S25\"                      \"S26\"                     \n[187] \"S27AE\"                    \"S27E\"                    \n[189] \"S28E/S33\"                 \"S30\"                     \n[191] \"PelA\"                     \"RsgA\"                    \n[193] \"HflX\"                     \"AlaS\"                    \n[195] \"ArgS\"                     \"AsnS\"                    \n[197] \"CysS\"                     \"GlnS\"                    \n[199] \"GRS1\"                     \"HisS\"                    \n[201] \"IleS\"                     \"LeuS\"                    \n[203] \"LysS\"                     \"LysU\"                    \n[205] \"MetG\"                     \"PheS\"                    \n[207] \"SerS\"                     \"ProS\"                    \n[209] \"ThrS\"                     \"TrpS\"                    \n[211] \"TyrS\"                     \"ValS\"                    \n[213] \"EIF1A\"                    \"InfB\"                    \n[215] \"SUI1\"                     \"EIF2A\"                   \n[217] \"EIF2B \"                   \"EIF2B-like\"              \n[219] \"EIF2G\"                    \"EIF4A\"                   \n[221] \"EIF5a\"                    \"EIF6\"                    \n[223] \"Tuf\"                      \"EFB1\"                    \n[225] \"FusA\"                     \"eRF1\"                    \n[227] \"Rli1\"                     \"Csl4\"                    \n[229] \"Rrp4\"                     \"Rrp41\"                   \n[231] \"Rrp42\"                    \"Dph2\"                    \n[233] \"Dph5\"                     \"Dph6\"                    \n[235] \"Trm5\"                     \"TYW1\"                    \n[237] \"TYW2\"                     \"TYW3\"                    \n[239] \"EndA\"                     \"Fau1\"                    \n[241] \"LigT\"                     \"Nob1\"                    \n[243] \"RtcB\"                     \"Archaease\"               \n[245] \"RCL1\"                     \"RnjA\"                    \n[247] \"Rnz\"                      \"Rnp1\"                    \n[249] \"Rnp2\"                     \"Rnp3\"                    \n[251] \"Rnp4\"                     \"TgtA\"                    \n[253] \"DnaJ\"                     \"DnaK\"                    \n[255] \"GrpE\"                     \"GroL\"                    \n[257] \"HtpX\"                     \"Hsp16\"                   \n[259] \"Hsp19\"                    \"PsmA\"                    \n[261] \"PRE1\"                     \"Pan1\"                    \n[263] \"Pcm\"                      \"ThsA\"                    \n\n#define a order for metabolic pathways\nPathway_order &lt;- as.character(unique(Genes_of_interest$pathway_2))\nPathway_order\n\n [1] \"DNA_Polymerase\"       \"RFs\"                  \"Helicase\"            \n [4] \"Topoisomerase\"        \"Repair_Recombination\" \"Methylase\"           \n [7] \"Chromatin\"            \"Cell_cycle\"           \"RNA_Polymerase\"      \n[10] \"TFs\"                  \"Transcription\"        \"Ribosome\"            \n[13] \"tRNA_synthetase\"      \"Exosome\"              \"Diphthamide_BS\"      \n[16] \"Wybutosine_BS\"        \"Translation\"          \"Posttranslation\"     \n[19] \"Mevalonate\"           \"Lipids\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#deal-with-annotation-file",
    "href": "code/parsing_output_from_annotations.html#deal-with-annotation-file",
    "title": "7  Working with annotation data",
    "section": "7.6 Deal with annotation file",
    "text": "7.6 Deal with annotation file\n\n7.6.1 Read in table\nYou already here notice that this takes a bit longer and we just work with 46 bins. This is a good reason to keep python in mind as depending on your computer the more memory heavy operations might get challenging. Another alternative would be to run R on the clusters.\n\n#read in data and view it\nInput &lt;- read.table(\"../data/UAP2_Annotation_table_u.txt\", sep=\"\\t\", header=T, fill=TRUE, quote = \"\")\nhead(Input)\n\n\n  \n\n\n\n\n\n7.6.2 Make a mapping file that links all annotation IDs to their descriptions\nWhat we do:\n\nseparate columns we are interested in for each Database of interest, i.e. arCOGs, and remove duplicate rows by using unique()\nchange the column names using colnames(). Here, we want to make sure that all the 6 new objects we generate have the same columns\ncombine our 6 dataframes using rbind(). For this to work we need the same number of columns.\n\nIn theory that would be a nice example for a loop as well, since we do exactly the same thing for 6x.\n\n#generate Description table for all DBs of interest\nArcogs_Description &lt;- unique(Input[,c(\"arcogs\",\"arcogs_Description\" )])\ncolnames(Arcogs_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(Arcogs_Description)), format='markdown')\n\n\n\n\nGene\nDescription\n\n\n\n\narCOG00570\n“Geranylgeranyl_reductase,_flavoprotein”\n\n\n-\n-\n\n\narCOG01358\n2-methylthioadenine_synthetase\n\n\narCOG01169\nEnolase\n\n\narCOG04245\nRibosomal_protein_S2\n\n\narCOG01728\n“Predicted_class_III_extradiol_dioxygenase,_MEMO1_family”\n\n\n\n\nKOs_Description &lt;- Input[,c(\"KO_hmm\",\"Definition\" )]\ncolnames(KOs_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(KOs_Description)), format='markdown')\n\n\n\n\n\n\n\n\nGene\nDescription\n\n\n\n\nK17830\ndigeranylgeranylglycerophospholipid_reductase_[EC:1.3.1.101_1.3.7.11]\n\n\n-\n-\n\n\nK15865\nthreonylcarbamoyladenosine_tRNA_methylthiotransferase_CDKAL1_[EC:2.8.4.5]\n\n\nK01689\nenolase_[EC:4.2.1.11]\n\n\nK02998\nsmall_subunit_ribosomal_protein_SAe\n\n\nK06990\nMEMO1_family_protein\n\n\n\n\nPfam_Description &lt;- unique(Input[,c(\"PFAM_hmm\",\"PFAM_description\" )])\ncolnames(Pfam_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(Pfam_Description)), format='markdown')\n\n\n\n\nGene\nDescription\n\n\n\n\nPF01494\nFAD_binding_domain\n\n\n-\n-\n\n\nPF04055\nRadical_SAM_superfamily\n\n\nPF00113\n“Enolase,_C-terminal_TIM_barrel_domain”\n\n\nPF00318\nRibosomal_protein_S2\n\n\nPF01875\nMemo-like_protein\n\n\n\n\nTIRGR_Description &lt;- unique(Input[,c(\"TIRGR\",\"TIGR_description\" )])\ncolnames(TIRGR_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(TIRGR_Description)), format='markdown')\n\n\n\n\nGene\nDescription\n\n\n\n\nTIGR02032\ngeranylgeranyl_reductase_family\n\n\n-\n-\n\n\nTIGR01578\n“MiaB-like_tRNA_modifying_enzyme,_archaeal-type”\n\n\nTIGR01060\nphosphopyruvate_hydratase\n\n\nTIGR01012\nribosomal_protein_uS2\n\n\nTIGR04336\nAmmeMemoRadiSam_system_protein_B\n\n\n\n\nCazy_Description &lt;- unique(Input[,c(\"CAZy\",\"Description\" )])\ncolnames(Cazy_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(Cazy_Description)), format='markdown')\n\n\n\n\n\n\n\n\n\n\nGene\nDescription\n\n\n\n\n1\n-\n-\n\n\n81\nGH119\n__alpha-amylase_(EC_3.2.1.1)\n\n\n245\nGT4\n“__sucrose_synthase_(EC_2.4.1.13);sucrose-phosphate_synthase(EC_2.4.1.14);alpha-glucosyltransferase(EC_2.4.1.52);lipopolysaccharide_N-acetylglucosaminyltransferase(EC_2.4.1.56);phosphatidylinositol_alpha-mannosyltransferase(EC_2.4.1.57);_GDP-Man:Man1GlcNAc2-PP-dolichol_alpha-1,3-mannosyltransferase(EC_2.4.1.132);_GDP-Man:Man3GlcNAc2-PP-dolichol/Man4GlcNAc2-PP-dolichol_alpha-1,2-mannosyltransferase(EC_2.4.1.131);digalactosyldiacylglycerol_synthase(EC_2.4.1.141);1,2-diacylglycerol_3-glucosyltransferase(EC_2.4.1.157);__diglucosyl_diacylglycerol_synthase_(EC_2.4.1.208);trehalose_phosphorylase(EC_2.4.1.231);_NDP-Glc:alpha-glucose_alpha-glucosyltransferase/alpha,alpha-trehalose_synthase(EC_2.4.1.245);_GDP-Man:Man2GlcNAc2-PP-dolichol_alpha-1,6-mannosyltransferase(EC_2.4.1.257);_UDP-GlcNAc:2-deoxystreptamine_alpha-N-acetylglucosaminyltransferase(EC_2.4.1.283);_UDP-GlcNAc:ribostamycin_alpha-N-acetylglucosaminyltransferase(EC_2.4.1.285);UDP-Gal_alpha-galactosyltransferase(EC_2.4.1.-);UDP-Xyl_alpha-xylosyltransferase(EC_2.4.2.-);UDP-GlcA_alpha-glucuronyltransferase(EC_2.4.1.-);UDP-Glc_alpha-glucosyltransferase(EC_2.4.1.-);_UDP-GalNAc:GalNAc-PP-Und_alpha-1,3-N-acetylgalactosaminyltransferase(EC_2.4.1.306);_UDP-GalNAc:N,N’-diacetylbacillosaminyl-PP-Und_alpha-1,3-N-acetylgalactosaminyltransferase(EC_2.4.1.290);ADP-dependent_alpha-maltose-1-phosphate_synthase(2.4.1.342)”\n\n\n291\nGT2_Glycos_transf_2\n-\n\n\n613\nGT83\n__undecaprenyl_phosphate-alpha-L-Ara4N:4-amino-4-deoxy-beta-L-arabinosyltransferase(EC_2.4.2.43);_dodecaprenyl_phosphate-beta-galacturonic_acid:lipopolysaccharide_core_alpha-galacturonosyl_transferase(EC_2.4.1.-)\n\n\n1357\nGT66\n__dolichyl-diphosphooligosaccharide&lt;83&gt;&lt;80&gt;&lt;9a&gt;&lt;82&gt;&lt;9d&gt;protein_glycotransferase_(EC_2.4.99.18);undecaprenyl-diphosphooligosaccharide&lt;83&gt;&lt;80&gt;&lt;9a&gt;&lt;82&gt;&lt;9d&gt;protein_glycotransferase(EC_2.4.99.19)_\n\n\n\n\nHydDB_Description &lt;- unique(Input[,c(\"Description.1\",\"Description.1\" )])\ncolnames(HydDB_Description) &lt;- c(\"Gene\", \"Description\")\nkable((head(HydDB_Description)), format='markdown')\n\n\n\n\n\nGene\nDescription\n\n\n\n\n1\n-\n-\n\n\n4787\n[FeFe]_Group_A1\n[FeFe]_Group_A1\n\n\n18935\n[NiFe]_Group_4g\n[NiFe]_Group_4g\n\n\n19355\n[NiFe]_Group_3b\n[NiFe]_Group_3b\n\n\n37081\n[FeFe]_Group_C3\n[FeFe]_Group_C3\n\n\n\n\n#make a file with a description of all the ids for each search\nAll_Genes_Description &lt;- rbind(Arcogs_Description,KOs_Description,Pfam_Description,TIRGR_Description, Cazy_Description, HydDB_Description)\n\n\n\n7.6.3 Parse table to make it easier to work with it\nHere we:\n\nSubset the data for the columns we are interested in. Esp. for larger dataframes this will make the operations a bit quicker. For very large dataframes, i.e. 5000 genomes, it might be better to switch to python\nConvert data from wide to long format\nClean factors. After subsetting often factors are not removed, we clean them up in that step\n\nInfo:\nConverting a wide to a long dataframe\n\nWide dataframe: The Input data in this example is considered as a wide dataframe. I.e. all the gene IDs we are interested in are spread out into different columns\nLong dataframe: The gene IDs we are interested in are found all in the same column. Important, most R functions work with long dataframes.\n\n\n#print the column names to subset our datatable\ncolnames(Input)\n\n [1] \"accession\"          \"BinID\"              \"TaxString\"         \n [4] \"NewContigID\"        \"OldContigId\"        \"ContigIdMerge\"     \n [7] \"ContigNewLength\"    \"GC\"                 \"ProteinID\"         \n[10] \"ProteinGC\"          \"ProteinLength\"      \"Prokka\"            \n[13] \"arcogs\"             \"arcogs_geneID\"      \"arcogs_Description\"\n[16] \"Pathway\"            \"arcogs_evalue\"      \"KO_hmm\"            \n[19] \"e_value\"            \"bit_score\"          \"bit_score_cutoff\"  \n[22] \"Definition\"         \"confidence\"         \"PFAM_hmm\"          \n[25] \"PFAM_description\"   \"Pfam_Evalue\"        \"TIRGR\"             \n[28] \"TIGR_description\"   \"EC\"                 \"TIGR_Evalue\"       \n[31] \"CAZy\"               \"CAZy_evalue\"        \"Description\"       \n[34] \"TDBD_ID\"            \"TPDB_evalue\"        \"HydDB\"             \n[37] \"Description.1\"      \"HydDB_evalue\"       \"PFAM\"              \n[40] \"PFAMdescription\"    \"IPR\"                \"IPRdescription\"    \n[43] \"TopHit\"             \"E_value\"            \"PecID\"             \n[46] \"TaxID\"              \"TaxString.1\"       \n\n#only keep the columns we actually want to work with\nInput_subset = Input[,c('BinID','accession','arcogs','KO_hmm','PFAM_hmm','TIRGR','CAZy','Description.1' )]\nkable((head(Input_subset)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBinID\naccession\narcogs\nKO_hmm\nPFAM_hmm\nTIRGR\nCAZy\nDescription.1\n\n\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00010\narCOG00570\nK17830\nPF01494\nTIGR02032\n-\n-\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00020\n-\n-\n-\n-\n-\n-\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00030\narCOG01358\nK15865\nPF04055\nTIGR01578\n-\n-\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00040\narCOG01169\nK01689\nPF00113\nTIGR01060\n-\n-\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00050\narCOG04245\nK02998\nPF00318\nTIGR01012\n-\n-\n\n\nNIOZ119_mb_b5_2\nNIOZ119_mb_b5_2-PJFDGLDN_00060\narCOG01728\nK06990\nPF01875\nTIGR04336\n-\n-\n\n\n\n\n#convert dataframe from wide to long\nInput_long &lt;- reshape2::melt(Input_subset,  id=c(\"accession\",\"BinID\"))\n\n#give informative headers\ncolnames(Input_long) &lt;- c(\"accession\", \"BinID\", \"DB\", \"gene\")\n\n#clean factors, to remove issues when counting\nInput_long$gene &lt;- as.factor(Input_long$gene)\nkable((head(Input_long)), format='markdown')\n\n\n\n\naccession\nBinID\nDB\ngene\n\n\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00010\nNIOZ119_mb_b5_2\narcogs\narCOG00570\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00020\nNIOZ119_mb_b5_2\narcogs\n-\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00030\nNIOZ119_mb_b5_2\narcogs\narCOG01358\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00040\nNIOZ119_mb_b5_2\narcogs\narCOG01169\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00050\nNIOZ119_mb_b5_2\narcogs\narCOG04245\n\n\nNIOZ119_mb_b5_2-PJFDGLDN_00060\nNIOZ119_mb_b5_2\narcogs\narCOG01728",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#make-count-tables",
    "href": "code/parsing_output_from_annotations.html#make-count-tables",
    "title": "7  Working with annotation data",
    "section": "7.7 Make count tables",
    "text": "7.7 Make count tables\n\n7.7.1 Generate a count table for our genomes of interest\nNow we want to count, how often does a genome (i.e. NIOZ134_mb_b41_2) have a gene. I.e. how often do we want arCOG00570, arCOG01358, …\n\n7.7.1.0.1 Do this via a loop (not executed, just an example)\nNotice:\nSince we run this chunk with , eval = FALSE we can still see the code but it is not executed. This is done because some computations take some time, which we do not want to spend, but I still want to show the code to give some alternative examples.\n\n#count the number of proteins for each genome of interest\ny &lt;- c()\nfor (i in Bin_order) {\n  x &lt;-  table(subset(Input_long, BinID %in% paste(i))$gene)\n  y &lt;- cbind (y,x)\n}\n\n#clean-up the table\nCounts_Table_loop &lt;- y\ncolnames(Counts_Table_loop) &lt;- Bin_order\nCounts_Table_loop &lt;- as.data.frame(Counts_Table_loop)\nkable((head(Counts_Table_loop)), format='markdown')\n\n#the '-' (=not identified genes) is also counted and listed in the first column and removed at this step\nCounts_Table_loop &lt;- Counts_Table_loop[-1,]\nkable((head(Counts_Table_loop)), format='markdown')\n\n\n\n7.7.1.0.2 Do this via ddply ((not executed, just an example))\nNew functions:\n\nspread() = converts our long to a wide dataframe by using the BinIDs as new column names, the count table as values to populate our dataframe and with missing values we print a 0.\n\n\n#count data and clean header\nCounts_Table_long &lt;- ddply(Input_long, .(BinID, gene), summarize, GeneCount = length(gene))\ncolnames(Counts_Table_long) &lt;- c(\"BinID\", \"geneID\", \"count\")\nkable((head(Counts_Table_long)), format='markdown')\n\n#transform to wide format, with fill = 0 instead of a NA we add a 0\nCounts_Table_wide &lt;- spread(Counts_Table_long, BinID, count, fill = 0 )\n\n#view data\nkable((head(Counts_Table_wide)), format='markdown')\n\n\n\n7.7.1.0.3 Do this via tidyr (usually a bit faster than ddplyr, which is why we use this way)\nHere, we use the %&gt;% symbol again: In the following example, the a subset of the Input_long data (only 3 columns, not the whole dataframe) gets passed to count()\nNew functions:\n\ncount() = A function of the dplyr package. Here, we count the unique protein IDs grouped by BinID and gene (i.e. roughly equivalent to the columns we want to keep)\n\n\n#count data and clean header\nCounts_Table_long &lt;- Input_long[,c('accession', 'BinID','gene')] %&gt;% count(BinID, gene, sort = FALSE)\ncolnames(Counts_Table_long) &lt;- c(\"BinID\", \"geneID\", \"count\")\nkable((head(Counts_Table_long)), format='markdown')\n\n\n\n\nBinID\ngeneID\ncount\n\n\n\n\nGCA_002494525\n-\n2350\n\n\nGCA_002494525\nGT2_Glyco_tranf_2_3\n1\n\n\nGCA_002494525\nGT2_Glycos_transf_2\n2\n\n\nGCA_002494525\nGT4\n2\n\n\nGCA_002494525\nGT66\n1\n\n\nGCA_002494525\nGT83\n1\n\n\n\n\n\nWhen viewing the data we also see that proteins with no annotations are counted (the minus symbol), since we do not care about this at this stage, lets remove everything with a minus symbol\n\n#delete rows with a minus symbol\nCounts_Table_long &lt;- Counts_Table_long[Counts_Table_long$geneID!= \"-\", ]\n\n#clean factors\nCounts_Table_long$geneID &lt;- factor(Counts_Table_long$geneID)\n\n#view data\nkable((head(Counts_Table_long)), format='markdown')\n\n\n\n\n\nBinID\ngeneID\ncount\n\n\n\n\n2\nGCA_002494525\nGT2_Glyco_tranf_2_3\n1\n\n\n3\nGCA_002494525\nGT2_Glycos_transf_2\n2\n\n\n4\nGCA_002494525\nGT4\n2\n\n\n5\nGCA_002494525\nGT66\n1\n\n\n6\nGCA_002494525\nGT83\n1\n\n\n7\nGCA_002494525\nK00012\n1\n\n\n\n\n\nNow, we can convert the long to a wide table, since this format is a bit easier to read in excel later.\n\n#transform to wide format, with fill = 0 instead of a NA we add a 0\nCounts_Table_wide &lt;- spread(Counts_Table_long, BinID, count, fill = 0 )\nkable((head(Counts_Table_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneID\nGCA_002494525\nGCA_002495465\nGCA_002501985\nGCA_002502135\nNIOZ119_mb_b5_2\nNIOZ120_mb_b229_2\nNIOZ121_cc_b94_2\nNIOZ121_mb_b48_2\nNIOZ122_mb_b305_2\nNIOZ122_mb_b319_2\nNIOZ123_bs_b392_2\nNIOZ123_bs_b5_2\nNIOZ124_cc_b247_2\nNIOZ124_mb_b130_2\nNIOZ125_cc_b75_2\nNIOZ125_mb_b178_2\nNIOZ125_mb_b254_2\nNIOZ126_mb_b137_2\nNIOZ126_mb_b304_2\nNIOZ126_mb_b401_2\nNIOZ127_mb_b161_2\nNIOZ127_mb_b282_2\nNIOZ129_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ132_cc_b149_2\nNIOZ132_cc_b51_2\nNIOZ132_mb_b198_2\nNIOZ132_mb_b260_2\nNIOZ132_mb_b282_2\nNIOZ132_mx_b314_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b293_2\nNIOZ134_mb_b361_2\nNIOZ134_mb_b41_2\nNIOZ134_mx_b281_2\nNIOZ136_cc_b15_2\nNIOZ136_mb_b104_2\nNIOZ136_mb_b226_2\nNIOZ136_mb_b335_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\n\n\n\n\nCBM44\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCE4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH119\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n\n\nGH130\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH95\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n\n\n\n\n\nAlso, we want our geneIDs to be the new rownames and we do this by using the rownames() functions. We do this since some functions do not like to have characters in their dataframe.\n\n#change the rownames\nrownames(Counts_Table_wide) &lt;- Counts_Table_wide$geneID\n\n#view data\nkable((head(Counts_Table_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneID\nGCA_002494525\nGCA_002495465\nGCA_002501985\nGCA_002502135\nNIOZ119_mb_b5_2\nNIOZ120_mb_b229_2\nNIOZ121_cc_b94_2\nNIOZ121_mb_b48_2\nNIOZ122_mb_b305_2\nNIOZ122_mb_b319_2\nNIOZ123_bs_b392_2\nNIOZ123_bs_b5_2\nNIOZ124_cc_b247_2\nNIOZ124_mb_b130_2\nNIOZ125_cc_b75_2\nNIOZ125_mb_b178_2\nNIOZ125_mb_b254_2\nNIOZ126_mb_b137_2\nNIOZ126_mb_b304_2\nNIOZ126_mb_b401_2\nNIOZ127_mb_b161_2\nNIOZ127_mb_b282_2\nNIOZ129_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ132_cc_b149_2\nNIOZ132_cc_b51_2\nNIOZ132_mb_b198_2\nNIOZ132_mb_b260_2\nNIOZ132_mb_b282_2\nNIOZ132_mx_b314_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b293_2\nNIOZ134_mb_b361_2\nNIOZ134_mb_b41_2\nNIOZ134_mx_b281_2\nNIOZ136_cc_b15_2\nNIOZ136_mb_b104_2\nNIOZ136_mb_b226_2\nNIOZ136_mb_b335_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\n\n\n\n\nCBM44\nCBM44\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCE4\nCE4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH119\nGH119\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n\n\nGH130\nGH130\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH95\nGH95\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\nGT2_Glyco_tranf_2_3\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n\n\n\n\n\nWhen we change the rownames and view the data, we see that the geneID is now both in the rownames as well as the first column. Since that is a bit messy, we next remove the first column.\n\n#delete the first column\nCounts_Table_wide &lt;- Counts_Table_wide[,-1]\nkable((head(Counts_Table_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGCA_002494525\nGCA_002495465\nGCA_002501985\nGCA_002502135\nNIOZ119_mb_b5_2\nNIOZ120_mb_b229_2\nNIOZ121_cc_b94_2\nNIOZ121_mb_b48_2\nNIOZ122_mb_b305_2\nNIOZ122_mb_b319_2\nNIOZ123_bs_b392_2\nNIOZ123_bs_b5_2\nNIOZ124_cc_b247_2\nNIOZ124_mb_b130_2\nNIOZ125_cc_b75_2\nNIOZ125_mb_b178_2\nNIOZ125_mb_b254_2\nNIOZ126_mb_b137_2\nNIOZ126_mb_b304_2\nNIOZ126_mb_b401_2\nNIOZ127_mb_b161_2\nNIOZ127_mb_b282_2\nNIOZ129_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ132_cc_b149_2\nNIOZ132_cc_b51_2\nNIOZ132_mb_b198_2\nNIOZ132_mb_b260_2\nNIOZ132_mb_b282_2\nNIOZ132_mx_b314_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b293_2\nNIOZ134_mb_b361_2\nNIOZ134_mb_b41_2\nNIOZ134_mx_b281_2\nNIOZ136_cc_b15_2\nNIOZ136_mb_b104_2\nNIOZ136_mb_b226_2\nNIOZ136_mb_b335_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\n\n\n\n\nCBM44\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCE4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH119\n0\n0\n0\n1\n1\n1\n0\n1\n0\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n\n\nGH130\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH95\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n\n\n\n\n\n\n#order our data so that the bins start first with the bins from the basal group\nCounts_Table_wide &lt;- Counts_Table_wide[,Bin_order]\n\n#view data\nkable((head(Counts_Table_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNIOZ132_cc_b51_2\nNIOZ134_mx_b281_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nGCA_002494525\nGCA_002495465\nGCA_002501985\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\nNIOZ124_cc_b247_2\nNIOZ125_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ126_mb_b401_2\nNIOZ122_mb_b319_2\nNIOZ134_mb_b41_2\nNIOZ132_mb_b282_2\nNIOZ127_mb_b161_2\nNIOZ123_bs_b5_2\nNIOZ121_cc_b94_2\nNIOZ136_cc_b15_2\nGCA_002502135\nNIOZ134_mb_b293_2\nNIOZ132_mb_b260_2\nNIOZ126_mb_b137_2\nNIOZ129_mb_b254_2\nNIOZ127_mb_b282_2\nNIOZ122_mb_b305_2\nNIOZ136_mb_b335_2\nNIOZ132_mb_b198_2\nNIOZ136_mb_b104_2\nNIOZ125_mb_b178_2\nNIOZ121_mb_b48_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b361_2\nNIOZ136_mb_b226_2\nNIOZ123_bs_b392_2\nNIOZ124_mb_b130_2\nNIOZ132_cc_b149_2\nNIOZ125_cc_b75_2\nNIOZ132_mx_b314_2\nNIOZ120_mb_b229_2\nNIOZ126_mb_b304_2\nNIOZ119_mb_b5_2\n\n\n\n\nCBM44\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nCE4\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH119\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n1\n0\n1\n0\n0\n1\n1\n0\n0\n1\n1\n0\n0\n1\n1\n1\n0\n1\n\n\nGH130\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGH95\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n\nIf you run these three examples yourself, take not how different the speed is.\n\n\n\n7.7.2 Generate a count table for our clusters of interest\nSame as above, but now we want to know for our 4 aquifer genomes, how many have Gene Xx and show this as percent. I.e. if 1/4 genomes have a gene, then 25% have it.\nFirst, lets merge in our taxa info into our count table, we need this to summarize our data by clusters.\n\n#merge the count table with mapping file to add in the taxa info (might take a while depending on size)\nCounts_Table_long_Tax &lt;- merge(Counts_Table_long, design_2[,c(\"BinID\", \"ClusterName\", \"NrGenomes\")], by = \"BinID\")\nkable((head(Counts_Table_long_Tax)), format='markdown')\n\n\n\n\nBinID\ngeneID\ncount\nClusterName\nNrGenomes\n\n\n\n\nGCA_002494525\nGT2_Glyco_tranf_2_3\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT2_Glycos_transf_2\n2\nMarine (6)\n6\n\n\nGCA_002494525\nGT4\n2\nMarine (6)\n6\n\n\nGCA_002494525\nGT66\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT83\n1\nMarine (6)\n6\n\n\nGCA_002494525\nK00012\n1\nMarine (6)\n6\n\n\n\n\n\nNext, whenever we have a value higher than one, we replace it with 1. That way we deal with our data like it is a presence/absence data. I.e. 0 = no genes present & 1 = gene present\n\n#convert counts to presence/absence matrix (just using 0/1) (this is needed to calculate the percentage across clusters)\nCounts_Table_long_Tax$count[Counts_Table_long_Tax$count &gt; 1] &lt;- 1\nkable((head(Counts_Table_long_Tax)), format='markdown')\n\n\n\n\nBinID\ngeneID\ncount\nClusterName\nNrGenomes\n\n\n\n\nGCA_002494525\nGT2_Glyco_tranf_2_3\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT2_Glycos_transf_2\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT4\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT66\n1\nMarine (6)\n6\n\n\nGCA_002494525\nGT83\n1\nMarine (6)\n6\n\n\nGCA_002494525\nK00012\n1\nMarine (6)\n6\n\n\n\n\n\nNow, we can use tidyr to count of how many genomes in a cluster have a gene.\n\n#count data and clean header\nCounts_Table_long_Tax_sum &lt;- Counts_Table_long_Tax[,c('ClusterName', 'geneID','NrGenomes', 'count')] %&gt;% count(ClusterName, geneID, NrGenomes, sort = FALSE)\ncolnames(Counts_Table_long_Tax_sum) &lt;- c(\"ClusterName\", \"geneID\", \"NrGenomes\", \"quantity\")\nkable((head(Counts_Table_long_Tax_sum)), format='markdown')\n\n\n\n\nClusterName\ngeneID\nNrGenomes\nquantity\n\n\n\n\nAquifer (4)\nGT2_Glycos_transf_2\n4\n4\n\n\nAquifer (4)\nGT4\n4\n3\n\n\nAquifer (4)\nGT66\n4\n2\n\n\nAquifer (4)\nGT83\n4\n3\n\n\nAquifer (4)\nK00003\n4\n2\n\n\nAquifer (4)\nK00008\n4\n3\n\n\n\n\n\nNext, we want to calculate the percentage. I.e. in the first example, we have 4 aquifer genomes, two of which [FeFe]_Group_C3 (=50%).\n\n#calculate of the percentage to answer of the total genomes per cluster how many have a certain gene\n#notice: if running for your own data check here that your percentage makes sense. I.e. we do not want values above 100\nCounts_Table_long_Tax_sum$percentage &lt;- round(Counts_Table_long_Tax_sum$quantity/Counts_Table_long_Tax_sum$NrGenomes*100, digits = 0)\nkable((head(Counts_Table_long_Tax_sum)), format='markdown')\n\n\n\n\nClusterName\ngeneID\nNrGenomes\nquantity\npercentage\n\n\n\n\nAquifer (4)\nGT2_Glycos_transf_2\n4\n4\n100\n\n\nAquifer (4)\nGT4\n4\n3\n75\n\n\nAquifer (4)\nGT66\n4\n2\n50\n\n\nAquifer (4)\nGT83\n4\n3\n75\n\n\nAquifer (4)\nK00003\n4\n2\n50\n\n\nAquifer (4)\nK00008\n4\n3\n75\n\n\n\n\n\nFor printing this, we want to convert our long to a wide table by using spread(). Also, we want our geneIDs to be the new rownames and we do this by using the rownames() functions. We do this since some functions do not like to have characters in their dataframe.\n\n#convert long to wide format and clean table (i.e. place the rownames)\nCounts_Table_long_Tax_sum_wide &lt;- spread(Counts_Table_long_Tax_sum[,c(\"geneID\", \"ClusterName\", \"percentage\")], ClusterName, percentage)\n\n#change the rownames\nrownames(Counts_Table_long_Tax_sum_wide) &lt;- Counts_Table_long_Tax_sum_wide$geneID\n\n#view data\nkable((head(Counts_Table_long_Tax_sum_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneID\nAquifer (4)\nBasal (2)\nClade1 (11)\nClade2 (23)\nMarine (6)\n\n\n\n\nCBM44\nCBM44\nNA\nNA\n18\nNA\nNA\n\n\nCE4\nCE4\nNA\n50\nNA\nNA\nNA\n\n\nGH119\nGH119\nNA\nNA\nNA\n52\nNA\n\n\nGH130\nGH130\nNA\n50\nNA\nNA\nNA\n\n\nGH95\nGH95\nNA\n50\nNA\nNA\nNA\n\n\nGT2_Glyco_tranf_2_3\nGT2_Glyco_tranf_2_3\nNA\nNA\nNA\nNA\n83\n\n\n\n\n\nWhen we change the rownames and view the data, we see that the geneID is now both in the rownames as well as the first column. Since that is a bit messy, we next remove the first column.\n\n#delete the first column\nCounts_Table_long_Tax_sum_wide &lt;- Counts_Table_long_Tax_sum_wide[,-1]\nkable((head(Counts_Table_long_Tax_sum_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\nAquifer (4)\nBasal (2)\nClade1 (11)\nClade2 (23)\nMarine (6)\n\n\n\n\nCBM44\nNA\nNA\n18\nNA\nNA\n\n\nCE4\nNA\n50\nNA\nNA\nNA\n\n\nGH119\nNA\nNA\nNA\n52\nNA\n\n\nGH130\nNA\n50\nNA\nNA\nNA\n\n\nGH95\nNA\n50\nNA\nNA\nNA\n\n\nGT2_Glyco_tranf_2_3\nNA\nNA\nNA\nNA\n83\n\n\n\n\n\nNow we see that we have NAs for genes that are not present in some of our clades. If we want to do more math then NAs are not helpful and we instead want to have a 0 there instead.\n\n#replace NAs with 0\nCounts_Table_long_Tax_sum_wide[is.na(Counts_Table_long_Tax_sum_wide)] &lt;- 0\nkable((head(Counts_Table_long_Tax_sum_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\nAquifer (4)\nBasal (2)\nClade1 (11)\nClade2 (23)\nMarine (6)\n\n\n\n\nCBM44\n0\n0\n18\n0\n0\n\n\nCE4\n0\n50\n0\n0\n0\n\n\nGH119\n0\n0\n0\n52\n0\n\n\nGH130\n0\n50\n0\n0\n0\n\n\nGH95\n0\n50\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\n0\n0\n0\n0\n83\n\n\n\n\n\nFinally, we want to sort our data, starting with the Basal clade and ending with the Black Sea Clades\n\n#sort by cluster order (defined by the order of the mapping file)\nCounts_Table_long_Tax_sum_wide &lt;- Counts_Table_long_Tax_sum_wide[,Cluster_order]\nkable((head(Counts_Table_long_Tax_sum_wide)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasal (2)\nAquifer (4)\nMarine (6)\nClade1 (11)\nClade2 (23)\n\n\n\n\nCBM44\n0\n0\n0\n18\n0\n\n\nCE4\n50\n0\n0\n0\n0\n\n\nGH119\n0\n0\n0\n0\n52\n\n\nGH130\n50\n0\n0\n0\n0\n\n\nGH95\n50\n0\n0\n0\n0\n\n\nGT2_Glyco_tranf_2_3\n0\n0\n83\n0\n0",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#merge-our-tables-with-the-mapping-data-we-have",
    "href": "code/parsing_output_from_annotations.html#merge-our-tables-with-the-mapping-data-we-have",
    "title": "7  Working with annotation data",
    "section": "7.8 Merge our tables with the mapping data we have",
    "text": "7.8 Merge our tables with the mapping data we have\nNow, that we have our count tables both for the bins as well as for all the clusters, we now want to add some gene description and subset the data based on different categores.\n\n7.8.1 For the bins\n\n7.8.1.1 Add gene descriptions\nRemember above, we made a list of descriptions that links all geneIDs with what is behind all the gene IDs? Now we want to add this info back in in order to print all the counts.\n\n#merge\nCounts_Table_final &lt;- merge(All_Genes_Description, Counts_Table_wide, by.x=\"Gene\", by.y=\"row.names\", all.x = T, sort = F)\nkable((head(Counts_Table_final)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGene\nDescription\nNIOZ132_cc_b51_2\nNIOZ134_mx_b281_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nGCA_002494525\nGCA_002495465\nGCA_002501985\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\nNIOZ124_cc_b247_2\nNIOZ125_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ126_mb_b401_2\nNIOZ122_mb_b319_2\nNIOZ134_mb_b41_2\nNIOZ132_mb_b282_2\nNIOZ127_mb_b161_2\nNIOZ123_bs_b5_2\nNIOZ121_cc_b94_2\nNIOZ136_cc_b15_2\nGCA_002502135\nNIOZ134_mb_b293_2\nNIOZ132_mb_b260_2\nNIOZ126_mb_b137_2\nNIOZ129_mb_b254_2\nNIOZ127_mb_b282_2\nNIOZ122_mb_b305_2\nNIOZ136_mb_b335_2\nNIOZ132_mb_b198_2\nNIOZ136_mb_b104_2\nNIOZ125_mb_b178_2\nNIOZ121_mb_b48_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b361_2\nNIOZ136_mb_b226_2\nNIOZ123_bs_b392_2\nNIOZ124_mb_b130_2\nNIOZ132_cc_b149_2\nNIOZ125_cc_b75_2\nNIOZ132_mx_b314_2\nNIOZ120_mb_b229_2\nNIOZ126_mb_b304_2\nNIOZ119_mb_b5_2\n\n\n\n\narCOG00570\n“Geranylgeranyl_reductase,_flavoprotein”\n2\n4\n3\n1\n3\n2\n1\n1\n1\n1\n1\n1\n2\n3\n3\n3\n2\n3\n3\n3\n3\n2\n1\n1\n2\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n1\n1\n2\n1\n1\n1\n1\n1\n\n\narCOG01358\n2-methylthioadenine_synthetase\n1\n2\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n\n\narCOG01169\nEnolase\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\narCOG04245\nRibosomal_protein_S2\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n\n\narCOG01728\n“Predicted_class_III_extradiol_dioxygenase,_MEMO1_family”\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n2\n1\n1\n0\n0\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n\n\narCOG00546\nmRNA_degradation_ribonuclease_J1/J2\n1\n0\n0\n0\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n2\n0\n1\n0\n1\n1\n0\n1\n1\n0\n1\n\n\n\n\n#print (and beautify elsewhere)\nwrite.table(Counts_Table_final, \"../output_examples/Counts_Table_final.txt\",  sep = \"\\t\", quote = F, row.names = T, na = \"\")\n\n\n\n7.8.1.2 Merging with the arcog_table\n\n#merge\nArcog_Data &lt;- merge(Arcog_mapping, Counts_Table_wide, by.x=\"arcog\", by.y=\"row.names\", all.x = T, sort = F)\nkable((head(Arcog_Data)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\narcog\nPathway\nGeneID\nGene\nCOG\nPFAM\nCD\nTIGR\nNIOZ132_cc_b51_2\nNIOZ134_mx_b281_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nGCA_002494525\nGCA_002495465\nGCA_002501985\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\nNIOZ124_cc_b247_2\nNIOZ125_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ126_mb_b401_2\nNIOZ122_mb_b319_2\nNIOZ134_mb_b41_2\nNIOZ132_mb_b282_2\nNIOZ127_mb_b161_2\nNIOZ123_bs_b5_2\nNIOZ121_cc_b94_2\nNIOZ136_cc_b15_2\nGCA_002502135\nNIOZ134_mb_b293_2\nNIOZ132_mb_b260_2\nNIOZ126_mb_b137_2\nNIOZ129_mb_b254_2\nNIOZ127_mb_b282_2\nNIOZ122_mb_b305_2\nNIOZ136_mb_b335_2\nNIOZ132_mb_b198_2\nNIOZ136_mb_b104_2\nNIOZ125_mb_b178_2\nNIOZ121_mb_b48_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b361_2\nNIOZ136_mb_b226_2\nNIOZ123_bs_b392_2\nNIOZ124_mb_b130_2\nNIOZ132_cc_b149_2\nNIOZ125_cc_b75_2\nNIOZ132_mx_b314_2\nNIOZ120_mb_b229_2\nNIOZ126_mb_b304_2\nNIOZ119_mb_b5_2\n\n\n\n\narCOG00009\nE\nPotE\nAmino acid transporter\nCOG00531\npfam00324\n\nTIGR00909\n2\n4\n1\n1\n1\n1\n2\n1\n2\n1\n1\n1\n3\n3\n2\n1\n3\n3\n3\n3\n2\n1\n0\n1\n1\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n1\n1\n1\n1\n0\n1\n1\n0\n\n\narCOG00014\nG\nRbsK\n“Sugar kinase, ribokinase family”\nCOG00524\npfam00294\ncd01174\nTIGR02152\n1\n2\n1\n2\n1\n2\n2\n2\n2\n2\n2\n2\n2\n3\n2\n2\n2\n3\n2\n2\n2\n2\n2\n3\n1\n2\n2\n3\n2\n4\n2\n2\n2\n2\n3\n2\n2\n3\n2\n4\n1\n2\n2\n2\n2\n1\n\n\narCOG00017\nR\n-\nPredicted transcriptional regulator\nCOG02522\n\n\n\n1\n1\n0\n0\n0\n0\n1\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\narCOG00018\nF\nNnr2\n“NAD(P)H-hydrate repair enzyme Nnr, NAD(P)H-hydrate dehydratase domain”\nCOG00063\n“pfam03853,pfam01256”\ncd01171\n“TIGR00197,TIGR00196”\n1\n1\n1\n0\n1\n0\n1\n1\n1\n2\n2\n0\n1\n1\n1\n1\n1\n1\n0\n2\n1\n2\n1\n2\n1\n1\n1\n1\n1\n1\n1\n1\n0\n1\n1\n2\n0\n2\n1\n1\n1\n0\n0\n1\n0\n0\n\n\narCOG00029\nF\nPyrE\nOrotate phosphoribosyltransferase\nCOG00461\npfam00156\ncd06223\nTIGR00336\n1\n0\n1\n0\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n1\n1\n1\n1\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n1\n\n\narCOG00030\nF\nApt\nAdenine/guanine phosphoribosyltransferase or related PRPP-binding protein\nCOG00503\npfam00156\ncd06223\nTIGR01090\n0\n1\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n2\n2\n1\n2\n1\n2\n2\n2\n2\n1\n2\n0\n2\n2\n1\n0\n1\n1\n0\n1\n\n\n\n\n#print (and beautify elsewhere)\nwrite.table(Arcog_Data, \"../output_examples/ArCOG_Data.txt\",  sep = \"\\t\", quote = F, row.names = T, na = \"\")\n\n\n\n7.8.1.3 Merging with the metabolism metadata file\n\n#merge\nKEGG_Metabolism &lt;- merge(Metabolism_file_KEGG, Counts_Table_wide, by.x=\"KO\", by.y=\"row.names\", all.x = T, sort = F)\nkable((head(KEGG_Metabolism)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKO\nIDs\npathway_A\norder\nGene\nComment.Uniprot.comment\nNIOZ132_cc_b51_2\nNIOZ134_mx_b281_2\nSRR2090153_bin1042\nSRR2090153_bin461\nSRR2090159_bin1129\nSRR2090159_bin1288\nGCA_002494525\nGCA_002495465\nGCA_002501985\nSRR4028224_bin17\nSRR5007147_bin71\nU_76725\nNIOZ124_cc_b247_2\nNIOZ125_mb_b254_2\nNIOZ129_mb_b262_2\nNIOZ126_mb_b401_2\nNIOZ122_mb_b319_2\nNIOZ134_mb_b41_2\nNIOZ132_mb_b282_2\nNIOZ127_mb_b161_2\nNIOZ123_bs_b5_2\nNIOZ121_cc_b94_2\nNIOZ136_cc_b15_2\nGCA_002502135\nNIOZ134_mb_b293_2\nNIOZ132_mb_b260_2\nNIOZ126_mb_b137_2\nNIOZ129_mb_b254_2\nNIOZ127_mb_b282_2\nNIOZ122_mb_b305_2\nNIOZ136_mb_b335_2\nNIOZ132_mb_b198_2\nNIOZ136_mb_b104_2\nNIOZ125_mb_b178_2\nNIOZ121_mb_b48_2\nNIOZ134_cc_b149_2\nNIOZ134_mb_b361_2\nNIOZ136_mb_b226_2\nNIOZ123_bs_b392_2\nNIOZ124_mb_b130_2\nNIOZ132_cc_b149_2\nNIOZ125_cc_b75_2\nNIOZ132_mx_b314_2\nNIOZ120_mb_b229_2\nNIOZ126_mb_b304_2\nNIOZ119_mb_b5_2\n\n\n\n\nK00362\nID14\nNitrogen\nN2\nnirB; nitrite reductase (NADH) large subunit [EC:1.7.1.15]\nDissimilatory\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nTIGR02374\nID15\nNitrogen\nN2\n“NirB, nitrite reductase [NAD(P)H]”\nDissimilatory\n0\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nTIGR02378\nID17\nNitrogen\nN2\n“NirD, nitrite reductase [NAD(P)H]”\nDissimilatory\n0\n1\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nK04748\nID31\nno_pathway\n\nnorQ; nitric oxide reductase NorQ protein\n\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nK00376\nID36\nNitrogen\nN5\nnosZ; nitrous-oxide reductase [EC:1.7.2.4]\n\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nTIGR04246\nID37\nNitrogen\nN5\n“nosZ, nitrous-oxide reductase, Sec-dependent”\n\n0\n0\n0\n0\n0\n0\n1\n1\n0\n1\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n#print\nwrite.table(KEGG_Metabolism, \"../output_examples/KEGG_Metabolism.txt\",  sep = \"\\t\", quote = F, row.names = T, na = \"\")\n\n\n\n\n7.8.2 For the clusters\nThe process works exactly the same as above. So try by yourself if you can merge things ;-).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/parsing_output_from_annotations.html#plot-the-data-for-our-genes-of-interest",
    "href": "code/parsing_output_from_annotations.html#plot-the-data-for-our-genes-of-interest",
    "title": "7  Working with annotation data",
    "section": "7.9 Plot the data for our genes of interest",
    "text": "7.9 Plot the data for our genes of interest\nHere, we are not interested in plotting all genes but just want to plot things that are listed under the lipid pathway.\nSince we are only interested in the Lipid pathway for the genes of interest (the table, among others, also lists genes involved in informational processing), we first need to make a gene list of just the genes we are interested in.\nNew functions:\n\nsubset() = subsets a dataframe. Syntax –&gt; subset(dataframe, column, %in% pattern_we_look_for)\n\n\n#subset genes of interest and clean factors\nGenes_Lipids &lt;- subset(Genes_of_interest, Pathway_1 %in% \"Lipids\")\nGenes_Lipids$Gene &lt;- factor(Genes_Lipids$Gene)\nGenes_Lipids$arcog &lt;- factor(Genes_Lipids$arcog)\n\n#check how many genes we have\ndim(Genes_Lipids)\n\n[1] 16 12\n\nkable((head(Genes_Lipids)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPathway_1\npathway_2\narcog\nxx\nPathway\nGene_short\nGene_name\nComment\nGene\nOrder\nOrder2\nOther\n\n\n\n\n262\nLipids\nMevalonate\narCOG01767\nNA\nI\nHmgB\n3-hydroxy-3-methylglutaryl CoA synthase\nCatalyzes the condensation of acetyl-CoA with acetoacetyl-CoA to form 3-hydroxy-3-methylglutaryl-CoA (HMG-CoA). Functions in the mevalonate (MVA) pathway\nHmgB\nLipid_1\n262\n\n\n\n263\nLipids\nMevalonate\narCOG04260\nNA\nI\nHmgA\n“3-hydroxy-3-methylglutaryl-coenzyme A reductase, HMG-CoA reductase”\nCatalyzes the NADPH-dependent reductive deacylation of (S)-3-hydroxy-3-methylglutaryl-CoA (HMG-CoA) to (R)-mevalonate. Functions in the mevalonate (MVA) pathway\nHmgA\nLipid_1\n263\n\n\n\n264\nLipids\nMevalonate\narCOG01028\nNA\nI\nMvK\nMevalonate kinase\nCatalyzes the phosphorylation of (R)-mevalonate (MVA) to (R)-mevalonate 5-phosphate (MVAP).\nMvK\nLipid_1\n264\n\n\n\n265\nLipids\nMevalonate\nK18689\nNA\nI\nM3k\nMevalonate 3-kinase\nCatalyzes the phosphorylation of mevalonate (MVA) to yield mevalonate-3-phosphate. Functions in an alternative mevalonate pathway\nM3k\nLipid_1\n265\n\n\n\n266\nLipids\nMevalonate\narCOG01967\nNA\nI\nM3P5K\nMevalonate-3-phosphate 5-kinase\n“Phosphorylates mevalonate 3-phosphate to form mevalonate 3,5-bisphosphate. Functions in an alternative mevalonate pathway”\nM3P5K\nLipid_1\n266\n\n\n\n267\nLipids\nMevalonate\narCOG02937\nNA\nI\nmvaD\nDiphosphomevalonate decarboxylase\nCatalyzes the decarboxylation of mevalonate 5-phosphate (MVAP) to isopentenyl phosphate (IP). Functions in the mevalonate (MVA) pathway leading to IPP\nmvaD\nLipid_1\n267\n\n\n\n\n\n\nNext, we want to make sure that the order is ok. In this specific example, we manually defined two columns for ordering (Order and Order2). We sort based on these columns and make a vector to order our genes of interest and our pathways of interest. For the lipid genes we look at the mevalonate pathway and general lipid biosynthesis genes\n\n``length()``` - lets us check the length of a vector, here it allows us to see that we would expect 16 genes\n\n\n#define an order (we arange the dataframe based on two columsn, Order and Order2)\nGenes_Lipids_order_temp &lt;- Genes_Lipids %&gt;% arrange(Order, Order2)\nGenes_Lipids_order &lt;- as.character(unique(Genes_Lipids_order_temp$Gene))\nlength(Genes_Lipids_order)\n\n[1] 16\n\nGenes_Lipids_order\n\n [1] \"HmgB\"          \"HmgA\"          \"MvK\"           \"M3k\"          \n [5] \"M3P5K\"         \"mvaD\"          \"Ipk\"           \"GFPS\"         \n [9] \"EgsA\"          \"GGGP_synthase\" \"UbiA\"          \"GGR\"          \n[13] \"CarS\"          \"PgsA\"          \"ASS\"           \"Asd\"          \n\n#The lipids belong to two different pathways, these 2 pathways we want to show in two separate heatmaps\nLipids_Pathway_order &lt;- as.character(unique(Genes_Lipids$pathway_2))\nLipids_Pathway_order\n\n[1] \"Mevalonate\" \"Lipids\"    \n\n\nNow that we know what genes we are interested in, lets subset our original count table.\n\n#subset our original count table for genes of interest and clean factors\nGenes_Lipids_counts &lt;- subset(Counts_Table_long_Tax_sum, geneID %in% as.character(Genes_Lipids$arcog))\nGenes_Lipids_counts$geneID &lt;- factor(Genes_Lipids_counts$geneID)\n\n#control that all went fine\nlength(unique(Genes_Lipids_counts$geneID))\n\n[1] 15\n\ndim(Genes_Lipids_counts)\n\n[1] 60  5\n\nkable((head(Genes_Lipids_counts)), format='markdown')\n\n\n\n\n\nClusterName\ngeneID\nNrGenomes\nquantity\npercentage\n\n\n\n\n1924\nAquifer (4)\narCOG00476\n4\n4\n100\n\n\n1947\nAquifer (4)\narCOG00570\n4\n4\n100\n\n\n1967\nAquifer (4)\narCOG00670\n4\n3\n75\n\n\n1968\nAquifer (4)\narCOG00671\n4\n4\n100\n\n\n1997\nAquifer (4)\narCOG00860\n4\n3\n75\n\n\n2032\nAquifer (4)\narCOG00982\n4\n3\n75\n\n\n\n\n\nWith length we see that now we just have 15 genes. How can we find out what gene is missing?\n\nsetdiff() = we compare two vectors and print the elements that differ.\n\n\nsetdiff(Genes_Lipids$arcog, Genes_Lipids_counts$geneID)\n\n[1] \"K18689\"\n\n\nWe can see that we miss K18689. If we check our original annotations input, we can see that K18689 does not exist in that table. So we can nout pull information because of that. This gives a good example, why it is important to check your data as we do not know whether this is an issue with the code or what the problem could be.\n\nNow, since our count data does not know that we categorize our different genes into different pathways, lets add this info in with merge()\n\n#add in metadata (from the pathway info)\nKey_Lipids_genes_cluster &lt;- merge(Genes_Lipids_counts, Genes_Lipids, by.x =\"geneID\", by.y = 'arcog' , all.x = T )\nkable((head(Key_Lipids_genes_cluster)), format='markdown')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngeneID\nClusterName\nNrGenomes\nquantity\npercentage\nPathway_1\npathway_2\nxx\nPathway\nGene_short\nGene_name\nComment\nGene\nOrder\nOrder2\nOther\n\n\n\n\narCOG00476\nAquifer (4)\n4\n4\n100\nLipids\nLipids\nNA\nL\nUbiA\ngeranylgeranylglycerol-phosphate geranylgeranyltransferase [EC:2.5.1.42]\nNotice: only the homologs identified in the aquifer MAGs harbor the characteristic DGGGP synthase domain (IPR023547)\nUbiA\nLipid_2\n272\n\n\n\narCOG00476\nBasal (2)\n2\n2\n100\nLipids\nLipids\nNA\nL\nUbiA\ngeranylgeranylglycerol-phosphate geranylgeranyltransferase [EC:2.5.1.42]\nNotice: only the homologs identified in the aquifer MAGs harbor the characteristic DGGGP synthase domain (IPR023547)\nUbiA\nLipid_2\n272\n\n\n\narCOG00476\nClade1 (11)\n11\n11\n100\nLipids\nLipids\nNA\nL\nUbiA\ngeranylgeranylglycerol-phosphate geranylgeranyltransferase [EC:2.5.1.42]\nNotice: only the homologs identified in the aquifer MAGs harbor the characteristic DGGGP synthase domain (IPR023547)\nUbiA\nLipid_2\n272\n\n\n\narCOG00476\nMarine (6)\n6\n6\n100\nLipids\nLipids\nNA\nL\nUbiA\ngeranylgeranylglycerol-phosphate geranylgeranyltransferase [EC:2.5.1.42]\nNotice: only the homologs identified in the aquifer MAGs harbor the characteristic DGGGP synthase domain (IPR023547)\nUbiA\nLipid_2\n272\n\n\n\narCOG00476\nClade2 (23)\n23\n19\n83\nLipids\nLipids\nNA\nL\nUbiA\ngeranylgeranylglycerol-phosphate geranylgeranyltransferase [EC:2.5.1.42]\nNotice: only the homologs identified in the aquifer MAGs harbor the characteristic DGGGP synthase domain (IPR023547)\nUbiA\nLipid_2\n272\n\n\n\narCOG00570\nClade2 (23)\n23\n22\n96\nLipids\nLipids\nNA\nL\nGGR\ndigeranylgeranylglycerophospholipid reductase [EC:1.3.1.101 1.3.7.11]\n“reduction of 2,3-digeranylgeranylglycerophospholipids (unsaturated archaeols) into 2,3-diphytanylglycerophospholipids (saturated archaeols)”\nGGR\nLipid_2\n273\n\n\n\n\n\n\n\n7.9.1 Categorizing data\nThere are different ways to color code data. By default the way we do it, we use a gradual color scale from 0-100%. However, we could also define categories with the ifelse statement we learned before. Here, we define 4 categories (100%, 75-100 and, 33-75 and 0-33%)\n\n#define color code (not used for the current figure, but can be changed)\n#here , we define 3 color levels, which sometimes is useful to show very clear cutoffs\nKey_Lipids_genes_cluster$category &lt;- ifelse(Key_Lipids_genes_cluster$percentage == 100, \"1\",\n                                         ifelse(Key_Lipids_genes_cluster$percentage &gt;= 75, \"0.75\",\n                                                ifelse(Key_Lipids_genes_cluster$percentage &gt;= 33, \"0.33\", \"0\")))\n\n\n\n7.9.2 Order our data\nRemember the annoying thing that R sorts alphabetically? Let’s make sure we ahve the order we want.\n\n#define order for the plot\nKey_Lipids_genes_cluster$ClusterName2 &lt;-  factor(Key_Lipids_genes_cluster$ClusterName, levels = rev(Cluster_order))\nKey_Lipids_genes_cluster$Gene2 &lt;-  factor(Key_Lipids_genes_cluster$Gene, levels = Genes_Lipids_order)\nKey_Lipids_genes_cluster$pathway_2b &lt;-  factor(Key_Lipids_genes_cluster$pathway_2, levels = Lipids_Pathway_order)\n\n\n\n7.9.3 Plotting\nIn the example here, we use a gradual scale. If we would want to use our 4 categories we can use this code #scale_fill_manual(values= c(\"white\", \"blue\", \"blue\", \"dodgerblue\")) and replacing the fill = percentage with fill = category.\n\n#plot\np1_Lipids &lt;- \n  ggplot(Key_Lipids_genes_cluster, aes(x=Gene2, y=ClusterName2)) + \n  geom_tile(aes(fill = percentage)) +\n  geom_hline(yintercept=2.5) +\n  facet_wrap( ~ pathway_2b, nrow = 1, scales='free_x') +\n  scale_fill_distiller(palette = \"Blues\", direction = 1) +\n  theme_bw() +\n  #scale_fill_manual(values= c(\"white\", \"blue\", \"blue\", \"dodgerblue\")) +\n  labs(x=\"\", y=\"\", fill=\"Percentage\") + \n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), \n        axis.line = element_line(colour = \"black\")) +\n  theme(legend.position=\"left\",\n        axis.text.x=element_text(angle=45,vjust = 1, hjust=1, size=8),\n        #axis.text.y=element_blank(),\n        axis.ticks=element_blank(),\n        axis.line=element_blank(),\n        plot.margin=unit(c(0, 0, 0, 0), \"mm\"))\n\np1_Lipids\n\n\n\n\n\n\n\nas.data.frame(levels(Key_Lipids_genes_cluster$ClusterName2))\n\n\n  \n\n\np1_Lipids2 &lt;- \n  ggplot(Key_Lipids_genes_cluster, aes(x=Gene2, y=ClusterName2)) + \n  geom_tile(aes(fill = percentage)) +\n  geom_hline(yintercept=2.5) +\n  facet_wrap( ~ pathway_2b, nrow = 1, scales='free_x') +\n  scale_fill_distiller(palette = \"Blues\", direction = 1) +\n  theme_bw() +\n  #scale_fill_manual(values= c(\"white\", \"blue\", \"blue\", \"dodgerblue\")) +\n  labs(x=\"\", y=\"\", fill=\"Percentage\") + \n  theme(panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(), \n        axis.line = element_line(colour = \"black\")) +\n  theme(legend.position=\"left\",\n        axis.text.x=element_text(angle=45,vjust = 1, hjust=1, size=8),\n        #axis.text.y=element_blank(),\n        axis.ticks=element_blank(),\n        axis.line=element_blank(),\n        plot.margin=unit(c(0, 0, 0, 0), \"mm\"))\n\np1_Lipids2\n\n\n\n\n\n\n\n\nIf we plot with facets we can sometimes have the problem that different genes have different widths. We can correct this behaviour with ggplotGrob.\n\n# convert ggplot object to grob object (used to rescale plot)\ngp_lipid &lt;- ggplotGrob(p1_Lipids2)\n\n# optional: take a look at the grob object's layout\ngtable::gtable_show_layout(gp_lipid)\n\n# get gtable columns corresponding to the facets (5 & 9, in this case)\nfacet.columns &lt;- gp_lipid$layout$l[grepl(\"panel\", gp_lipid$layout$name)]\n\n# get the number of unique x-axis values per facet (1 & 3, in this case)\nx.var &lt;- sapply(ggplot_build(p1_Lipids)$layout$panel_scales_x,\n                function(l) length(l$range$range))\n\n# change the relative widths of the facet columns based on\n# how many unique x-axis values are in each facet\ngp_lipid$widths[facet.columns] &lt;- gp_lipid$widths[facet.columns] * x.var\n\n# plot result\ngrid::grid.draw(gp_lipid)\n\n\n\n\n\n\n\n#print\n#pdf(\"2_Output/Figure_S64.pdf\", paper=\"special\", family=\"sans\",width=8, height=7, useDingbats=FALSE)\n#grid::grid.draw(gp_lipid)\n#dev.off() \n\nIn this example we see that only the aquifer and the basal clade have all required genes for the mevalonate pathway and the lipid pathway that is required to make a key archaeal lipid.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Working with annotation data</span>"
    ]
  },
  {
    "objectID": "code/2_misc.html",
    "href": "code/2_misc.html",
    "title": "8  Miscellaneous",
    "section": "",
    "text": "8.1 Search and replace in markdown\nIf we want to search for the end of the line to, for example, add two spaces (and thus create a linebreak), we can:",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Miscellaneous</span>"
    ]
  },
  {
    "objectID": "code/2_misc.html#search-and-replace-in-markdown",
    "href": "code/2_misc.html#search-and-replace-in-markdown",
    "title": "8  Miscellaneous",
    "section": "",
    "text": "find `(.)$ with Regex selected\nand replace with \\1your_string",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Miscellaneous</span>"
    ]
  },
  {
    "objectID": "code/2_misc.html#print-the-session-info",
    "href": "code/2_misc.html#print-the-session-info",
    "title": "8  Miscellaneous",
    "section": "8.2 Print the session info:",
    "text": "8.2 Print the session info:\nThis prints our session info (used R version, packages, etc) and is very important to store to reproduce our code for others\n\n#|eval: false\nsessionInfo()\n## R version 4.2.1 (2022-06-23)\n## Platform: x86_64-apple-darwin17.0 (64-bit)\n## Running under: macOS Catalina 10.15.7\n## \n## Matrix products: default\n## BLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\n## LAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n## \n## locale:\n## [1] C\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## loaded via a namespace (and not attached):\n##  [1] htmlwidgets_1.5.4 compiler_4.2.1    magrittr_2.0.3    fastmap_1.1.0    \n##  [5] cli_3.4.0         tools_4.2.1       htmltools_0.5.3   stringi_1.7.8    \n##  [9] rmarkdown_2.16    knitr_1.40        stringr_1.4.1     xfun_0.33        \n## [13] digest_0.6.29     jsonlite_1.8.0    rlang_1.0.5       evaluate_0.16\n\n\n8.2.1 Clean-up the working environment\nNotice: At the moment, we do not want to clean up the working directory, therefore, in our documentation we put a # in front of it. If you want to run the code just remove the #\n\n#rm(list = ls())",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Miscellaneous</span>"
    ]
  }
]